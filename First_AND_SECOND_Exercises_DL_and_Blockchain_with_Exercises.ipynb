{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First_AND_SECOND_Exercises_DL and Blockchain with Exercises.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://andersbrownworth.com/blockchain/blockchain\n",
        "\n",
        "Blockchain Visualization Demo from Anders Brownworth"
      ],
      "metadata": {
        "id": "seCZkJ2yR0W-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y93xcaWwkZGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927b80d2-c84d-46fd-fd17-4ad6e30e4818"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "model_path = '/content/gdrive/MyDrive/Colab Notebooks/CSEE5590-AI4Cybersecurity/Lecture_11/'"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "rvRc44Ri-bjf"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTimBCC80cv9"
      },
      "source": [
        "# import torch\n",
        "# from torchvision import datasets, transforms\n",
        "\n",
        "# # Define a transform to normalize the data\n",
        "# transform = transforms.Compose([transforms.ToTensor(),\n",
        "#                                 transforms.Normalize((0.5,), (0.5,))])\n",
        "# # Download and load the training data\n",
        "# trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# # Download and load the test data\n",
        "# testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "# testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVRjR7Zc0cwB"
      },
      "source": [
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDtZYw_M0cwR",
        "outputId": "71e5132d-3b8e-4655-c1a5-e5b53b400a42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Classifier()\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        log_ps = model(images)\n",
        "        loss = criterion(log_ps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    else:\n",
        "        test_loss = 0\n",
        "        accuracy = 0\n",
        "        \n",
        "        # Turn off gradients for validation, saves memory and computations\n",
        "        with torch.no_grad():\n",
        "            for images, labels in testloader:\n",
        "                log_ps = model(images)\n",
        "                test_loss += criterion(log_ps, labels)\n",
        "                \n",
        "                ps = torch.exp(log_ps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "                \n",
        "        train_losses.append(running_loss/len(trainloader))\n",
        "        test_losses.append(test_loss/len(testloader))\n",
        "\n",
        "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5..  Training Loss: 0.342..  Test Loss: 0.164..  Test Accuracy: 0.949\n",
            "Epoch: 2/5..  Training Loss: 0.171..  Test Loss: 0.164..  Test Accuracy: 0.948\n",
            "Epoch: 3/5..  Training Loss: 0.138..  Test Loss: 0.137..  Test Accuracy: 0.958\n",
            "Epoch: 4/5..  Training Loss: 0.118..  Test Loss: 0.132..  Test Accuracy: 0.959\n",
            "Epoch: 5/5..  Training Loss: 0.108..  Test Loss: 0.112..  Test Accuracy: 0.968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rABNbrN7BweK",
        "outputId": "f576d95d-bab7-478e-ae60-d8aa90defe77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_losses, label=\"Train Losses\")\n",
        "plt.plot(test_losses, label=\"Test Losses\")\n",
        "plt.legend()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fda0dd20e90>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), model_path + 'MNIST_model.pth')"
      ],
      "metadata": {
        "id": "u1LHhUTNAAIj"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVWOFzaf0cwX"
      },
      "source": [
        "## Inference\n",
        "\n",
        "Now that the model is trained, we can use it for inference. We've done this before, but now we need to remember to set the model in inference mode with `model.eval()`. You'll also want to turn off autograd with the `torch.no_grad()` context."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier()\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load(model_path + 'MNIST_model.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9waHyRn_40q",
        "outputId": "8f05fd36-adc7-4b1c-b2a6-3be93d56f2e2"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0\n",
        "accuracy = 0\n",
        "\n",
        "# Turn off gradients for validation, saves memory and computations\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        log_ps = model(images)\n",
        "        test_loss += criterion(log_ps, labels)\n",
        "        \n",
        "        ps = torch.exp(log_ps)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "print(\"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTpNBzAwA3vg",
        "outputId": "429cb489-6439-4f16-8981-ddffd5e744a8"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrDhadz-0cwY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "a6b8b3b7-7572-4335-ee46-6ef380490c7f"
      },
      "source": [
        "from random import randint\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "img = images[randint(0, len(images))]\n",
        "\n",
        "# Convert 2D image to 1D vector\n",
        "img = img.view(1, 784)\n",
        "\n",
        "# Calculate the class probabilities (softmax) for img\n",
        "with torch.no_grad():\n",
        "    output = model.forward(img)\n",
        "\n",
        "ps = torch.exp(output)\n",
        "\n",
        "# Plot the image and probabilities\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)"
      ],
      "metadata": {
        "id": "57KLm313PmXc"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Weight Attack"
      ],
      "metadata": {
        "id": "uVzqYCIEFVZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(model_path + 'MNIST_model.pth'))\n",
        "model_weights = model.state_dict()\n",
        "model_layers = list(dict(model.named_modules()).keys())[1:]\n",
        "from copy import deepcopy\n"
      ],
      "metadata": {
        "id": "7l_pxypgFX-8"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trivial/Small Attack - 10 neuron change"
      ],
      "metadata": {
        "id": "iK_Gf6SlJ7-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "No-damage Attack \n",
        "'''\n",
        "model_1 = Classifier()\n",
        "tampered_model_weights = deepcopy(model_weights)\n",
        "tampered_model_weights['fc3.weight'][0][0:10] = 0\n",
        "model_1.load_state_dict(tampered_model_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7xSZeHjJuEK",
        "outputId": "9a896ec4-d6af-4e2a-de3e-514697b2a810"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Small Attack\n",
        "'''\n",
        "model_1 = Classifier()\n",
        "tampered_model_weights = deepcopy(model_weights)\n",
        "tampered_model_weights['fc3.weight'] -= 0.07\n",
        "model_1.load_state_dict(tampered_model_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3cucl_6GvHE",
        "outputId": "2c862bab-4d71-42ad-cb41-2a79895285d0"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        log_ps = model_1(images)   \n",
        "        ps = torch.exp(log_ps)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "print(\"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u_ECW2fKCKZ",
        "outputId": "eec3ed2c-23b7-4ce1-bb03-413089a10966"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Medium Attack - add 0.2 to layer"
      ],
      "metadata": {
        "id": "0vGTdVn7KGuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Medium Attack\n",
        "'''\n",
        "model_2 = Classifier()\n",
        "tampered_model_weights = deepcopy(model_weights)\n",
        "tampered_model_weights['fc3.weight'] += 0.2\n",
        "model_2.load_state_dict(tampered_model_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXqAFxSkGygL",
        "outputId": "50279073-3dc6-4c01-f4a3-ab9248e776ae"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        log_ps = model_2(images)   \n",
        "        ps = torch.exp(log_ps)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "print(\"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbCUcL25KKZp",
        "outputId": "3eca1ae9-0485-49bf-ee51-0b27cdf1a402"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Large Attack - corrupt entire layer"
      ],
      "metadata": {
        "id": "89ARGmiCKL-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Large Attack - corrupt entire layer\n",
        "'''\n",
        "model_3 = Classifier()\n",
        "tampered_model_weights = deepcopy(model_weights)\n",
        "tampered_model_weights['fc3.weight'][0] = torch.rand(tampered_model_weights['fc3.weight'][0].shape)\n",
        "model_3.load_state_dict(tampered_model_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAggc4TYFsZM",
        "outputId": "9c5d9cac-d7a2-461a-bf6b-cd83fd7eda58"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        log_ps = model_3(images)   \n",
        "        ps = torch.exp(log_ps)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "print(\"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzYayxo8KN2J",
        "outputId": "97be5874-87d1-4ca1-e148-309051d4b31e"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test accuracy for each model with various scales of attack\n",
        "with torch.no_grad():\n",
        "    test_losses = [0, 0, 0, 0]\n",
        "    accuracies = [0, 0, 0, 0]  \n",
        "    for images, labels in testloader:\n",
        "        log_ps = model(images)      \n",
        "        ps = torch.exp(log_ps)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracies[0] += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "        log_ps = model_1(images)     \n",
        "        ps = torch.exp(log_ps)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracies[1] += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "        log_ps = model_2(images)     \n",
        "        ps = torch.exp(log_ps)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracies[2] += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "        log_ps = model_3(images) \n",
        "        ps = torch.exp(log_ps)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracies[3] += torch.mean(equals.type(torch.FloatTensor))\n",
        "for accuracy in accuracies:\n",
        "  print(\"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN1rFWbiGJjk",
        "outputId": "90f3fae4-75f1-4c88-cdc3-6bbef2a6e8e9"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.968\n",
            "Test Accuracy: 0.847\n",
            "Test Accuracy: 0.752\n",
            "Test Accuracy: 0.780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Blockchain\n"
      ],
      "metadata": {
        "id": "hin1OOmXBVD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(model_path + 'MNIST_model.pth'))\n",
        "model_weights = model.state_dict()\n",
        "model_layers = list(dict(model.named_modules()).keys())[1:]"
      ],
      "metadata": {
        "id": "lsArtAl0MMwT"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt5GG8oiUfOM",
        "outputId": "c5d6c176-96d0-4ed2-cbc4-c24cd6768f2f"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('fc1.weight',\n",
              "              tensor([[ 0.0329,  0.0086,  0.0243,  ...,  0.0497,  0.0563,  0.0528],\n",
              "                      [-0.0129,  0.0104,  0.0365,  ...,  0.0194,  0.0207,  0.0246],\n",
              "                      [ 0.0081,  0.0136, -0.0052,  ...,  0.0030,  0.0517,  0.0313],\n",
              "                      ...,\n",
              "                      [ 0.0393,  0.0300,  0.0377,  ...,  0.0255,  0.0073,  0.0581],\n",
              "                      [ 0.0441,  0.0390,  0.0418,  ...,  0.0376, -0.0042,  0.0096],\n",
              "                      [ 0.0226,  0.0080,  0.0011,  ..., -0.0116,  0.0461,  0.0215]])),\n",
              "             ('fc1.bias',\n",
              "              tensor([-5.0697e-02, -1.5882e-03, -4.5533e-02, -8.9822e-04, -7.9249e-02,\n",
              "                       3.3151e-03, -3.6789e-02, -1.7230e-02, -5.2123e-02, -2.5209e-02,\n",
              "                       8.5094e-03, -5.6987e-02, -2.2219e-02, -2.8807e-02, -1.7612e-02,\n",
              "                       4.9885e-03, -1.4747e-03, -7.5809e-02,  1.5871e-02, -4.0564e-03,\n",
              "                      -3.7250e-03, -4.6109e-02,  2.5242e-03,  4.4355e-03,  1.0314e-02,\n",
              "                      -7.1663e-02,  9.1916e-03, -3.6697e-02, -3.8919e-02, -3.2340e-02,\n",
              "                      -1.7095e-02, -2.2695e-02, -7.3756e-03, -3.2307e-03, -2.6671e-02,\n",
              "                      -1.4188e-02, -5.8340e-03, -3.8018e-02, -3.0583e-02, -1.8098e-02,\n",
              "                       2.1612e-02, -8.6132e-02, -2.3886e-02, -1.1493e-02, -8.3055e-03,\n",
              "                      -1.7589e-03,  1.1987e-02, -4.2030e-02, -3.9615e-02,  4.4278e-03,\n",
              "                      -1.7534e-02, -2.4694e-02, -2.1543e-02, -3.4609e-02,  2.3570e-02,\n",
              "                       2.6285e-02, -1.3856e-02,  1.1432e-02, -2.7742e-02,  3.2082e-04,\n",
              "                       4.6447e-03,  1.1198e-02, -1.5167e-02, -4.9473e-02, -4.2446e-02,\n",
              "                       5.3062e-02, -6.3078e-02, -2.2603e-02, -1.0497e-02, -4.7284e-03,\n",
              "                      -4.0333e-02,  4.8095e-03, -5.9835e-02,  5.7884e-03, -5.8095e-03,\n",
              "                      -2.4915e-02, -1.1267e-02, -5.3225e-02,  1.0887e-02, -3.1268e-03,\n",
              "                      -2.1667e-02, -5.2839e-02, -3.7480e-02, -2.9252e-02, -1.0288e-02,\n",
              "                       9.7473e-03, -3.4331e-02, -2.6842e-02, -4.7752e-02, -4.4481e-03,\n",
              "                      -5.0411e-02, -1.8064e-02, -2.4959e-02,  3.8707e-02, -2.3788e-02,\n",
              "                      -3.0230e-02, -4.3937e-02, -3.9769e-02, -9.4580e-02,  4.1654e-02,\n",
              "                      -3.5936e-02, -2.1148e-02,  1.7497e-02, -3.1961e-02, -2.3776e-02,\n",
              "                      -3.7282e-02, -1.5092e-02,  9.8810e-03, -3.9213e-02, -3.9942e-02,\n",
              "                      -5.6907e-02, -3.7442e-03, -9.5044e-02, -2.5293e-02, -2.5454e-02,\n",
              "                      -4.7367e-02, -5.1332e-02, -2.0713e-03, -2.7323e-02,  5.7385e-03,\n",
              "                      -1.9152e-02, -3.3860e-02, -4.8206e-02, -3.2334e-03, -5.0366e-02,\n",
              "                      -3.5953e-02,  6.5205e-03, -2.6486e-02,  1.1088e-02, -2.8068e-02,\n",
              "                      -7.4271e-02, -1.1911e-02,  1.2842e-02, -2.5225e-02, -3.1306e-02,\n",
              "                      -1.9759e-02, -3.5803e-03,  2.0227e-03, -2.1660e-02,  1.1208e-02,\n",
              "                      -2.4123e-02,  9.0310e-03, -5.1055e-02, -4.5396e-02, -2.6411e-02,\n",
              "                       1.1292e-02,  1.4030e-02, -3.8358e-02, -3.2809e-02, -1.8572e-02,\n",
              "                       4.8251e-02, -2.9928e-03, -7.2177e-02, -4.8035e-02,  7.6769e-03,\n",
              "                      -6.5365e-02, -3.6413e-02, -1.1881e-02,  1.7021e-02, -1.1635e-02,\n",
              "                      -6.0688e-02, -2.3924e-02, -4.9127e-02, -6.5620e-02, -4.3793e-02,\n",
              "                      -4.4041e-02, -5.9561e-02, -2.9840e-02, -2.5970e-03, -4.9796e-02,\n",
              "                      -1.1559e-02,  7.0239e-03, -3.5945e-02,  1.5993e-02, -4.1892e-02,\n",
              "                      -6.8264e-02,  2.1650e-02, -4.1370e-02,  2.1973e-02, -1.5948e-02,\n",
              "                      -1.0226e-01, -3.7496e-02,  1.7094e-02, -1.0982e-02,  1.5540e-02,\n",
              "                      -5.0556e-02, -2.7001e-02, -2.0114e-02, -5.0169e-02, -2.9489e-02,\n",
              "                      -3.9743e-02, -8.5380e-03, -1.8673e-02, -3.8129e-02, -2.1269e-02,\n",
              "                      -2.5533e-02, -2.1255e-02, -1.3042e-02, -3.3605e-02, -1.3769e-02,\n",
              "                      -2.9272e-02, -2.0493e-02,  6.1399e-03,  3.2051e-02, -2.2862e-02,\n",
              "                      -4.3587e-02, -1.2302e-02, -6.0179e-03, -6.3411e-02, -1.3902e-04,\n",
              "                       6.6006e-03, -6.3300e-02, -8.8990e-03, -4.0236e-03, -5.1070e-02,\n",
              "                      -5.1127e-02, -3.9643e-02, -5.2284e-02, -4.6759e-02, -5.3112e-02,\n",
              "                      -2.7392e-02, -2.9490e-02, -2.2758e-02, -9.5000e-03, -1.2496e-02,\n",
              "                      -3.4707e-02, -1.4716e-02, -1.2888e-02, -1.2930e-03, -5.0056e-02,\n",
              "                      -4.8036e-02, -3.2378e-02, -3.6429e-02, -3.8621e-02, -3.1510e-02,\n",
              "                      -5.1300e-02,  1.4994e-02,  1.2208e-05, -1.4082e-02,  1.7620e-03,\n",
              "                      -4.7165e-02, -3.7629e-02, -3.8766e-02,  9.4560e-03, -1.5576e-02,\n",
              "                      -3.9815e-02,  1.1144e-02,  9.7832e-03, -1.2574e-02, -4.5413e-02,\n",
              "                      -8.2680e-03, -2.0615e-02, -1.7477e-02, -4.7983e-02, -2.5950e-02,\n",
              "                      -4.0306e-02])),\n",
              "             ('fc2.weight',\n",
              "              tensor([[ 0.0700,  0.0577, -0.0515,  ..., -0.0376, -0.0064, -0.0211],\n",
              "                      [ 0.2691,  0.0488, -0.0146,  ...,  0.1431,  0.0142, -0.0360],\n",
              "                      [ 0.1107,  0.0349,  0.0097,  ...,  0.0975, -0.0220,  0.0102],\n",
              "                      ...,\n",
              "                      [-0.0245,  0.0396, -0.0413,  ..., -0.0204, -0.0343,  0.0537],\n",
              "                      [-0.0211,  0.0468, -0.0537,  ..., -0.1140,  0.0065,  0.0199],\n",
              "                      [ 0.1608, -0.0083, -0.0337,  ...,  0.0963, -0.0206,  0.0148]])),\n",
              "             ('fc2.bias',\n",
              "              tensor([-0.0489,  0.1896,  0.1729, -0.1131, -0.1978,  0.0504, -0.0708, -0.1582,\n",
              "                      -0.0030, -0.1288,  0.0108,  0.0125, -0.0415, -0.1031, -0.0630, -0.0025,\n",
              "                      -0.1085, -0.0879, -0.0841,  0.3088,  0.1560,  0.0175, -0.2156, -0.1164,\n",
              "                      -0.1923, -0.0915, -0.1100, -0.0354, -0.2318, -0.0061, -0.0592, -0.1969,\n",
              "                      -0.0775, -0.1088, -0.1204, -0.1337, -0.2263,  0.1045, -0.1049, -0.1794,\n",
              "                      -0.1485, -0.1131, -0.1346, -0.1471,  0.0449,  0.0613,  0.1513, -0.0190,\n",
              "                      -0.0355, -0.1064,  0.2106, -0.1671,  0.0496,  0.0589, -0.1245, -0.1031,\n",
              "                       0.0060, -0.0687, -0.1207, -0.0791,  0.0110, -0.1303,  0.0872, -0.0913,\n",
              "                      -0.0502, -0.1575,  0.0946, -0.0620,  0.0189,  0.0400, -0.0242, -0.2191,\n",
              "                      -0.1293, -0.1497,  0.1555,  0.2938, -0.0674, -0.3190, -0.0629, -0.1634,\n",
              "                      -0.0147, -0.0193, -0.1928, -0.0061, -0.1173, -0.0514, -0.1626, -0.2278,\n",
              "                      -0.0745, -0.0037, -0.0470, -0.0303, -0.1636, -0.1014,  0.1747, -0.0842,\n",
              "                      -0.1578,  0.0232, -0.0125, -0.1983,  0.4642, -0.1431,  0.0178, -0.0420,\n",
              "                      -0.0608, -0.0430, -0.0866,  0.0265, -0.0709,  0.0132,  0.0132, -0.1032,\n",
              "                      -0.0352, -0.0149, -0.2466, -0.0685, -0.1978, -0.0966, -0.0275, -0.2409,\n",
              "                       0.2949, -0.1386,  0.0520, -0.1878, -0.1932, -0.0528, -0.0524,  0.1045])),\n",
              "             ('fc3.weight',\n",
              "              tensor([[-0.0898,  0.0228, -0.0250,  ...,  0.0682, -0.1015, -0.0751],\n",
              "                      [ 0.0142, -0.0617, -0.0568,  ..., -0.0338, -0.0558,  0.0405],\n",
              "                      [-0.1508, -0.0901, -0.0380,  ...,  0.0528,  0.0925, -0.0676],\n",
              "                      ...,\n",
              "                      [ 0.0139,  0.0265, -0.1787,  ...,  0.0430,  0.0435, -0.0926],\n",
              "                      [-0.0654, -0.0217, -0.1451,  ...,  0.0332, -0.0209, -0.1631],\n",
              "                      [ 0.0609, -0.0105, -0.0566,  ...,  0.0403,  0.1513, -0.0428]])),\n",
              "             ('fc3.bias',\n",
              "              tensor([-0.1711, -0.1505, -0.1412,  0.0111, -0.0597,  0.1476, -0.0710, -0.0209,\n",
              "                       0.1606,  0.2981,  0.1772, -0.2506, -0.0747, -0.2264, -0.2045, -0.3326,\n",
              "                      -0.1356, -0.0518, -0.1744, -0.1427, -0.0377,  0.1834,  0.2696,  0.4100,\n",
              "                      -0.2308, -0.2062, -0.0479,  0.0068, -0.1853,  0.1144, -0.1299,  0.1610,\n",
              "                      -0.0101,  0.0754,  0.0926, -0.0319,  0.1107,  0.1191, -0.2281, -0.1523,\n",
              "                      -0.2556, -0.1582, -0.0862, -0.0819, -0.0549,  0.1640, -0.1267, -0.0659,\n",
              "                       0.0778, -0.0852, -0.0334,  0.2512, -0.0555,  0.2768,  0.0982,  0.3895,\n",
              "                       0.1073, -0.1683,  0.0174, -0.0115,  0.2321, -0.3172, -0.1211,  0.0065])),\n",
              "             ('fc4.weight',\n",
              "              tensor([[-3.0591e-02,  3.4098e-02, -1.2472e-02, -8.9146e-03, -9.6389e-02,\n",
              "                       -3.0413e-02, -2.2714e-02, -1.3556e-01,  6.6748e-02, -3.5200e-02,\n",
              "                        1.7505e-01, -3.1370e-01,  1.0929e-01, -1.2965e-01, -2.6508e-01,\n",
              "                       -4.6322e-03, -3.6083e-02,  1.6212e-01, -1.5626e-01,  9.0508e-03,\n",
              "                        5.9090e-02, -1.5017e-01, -7.2761e-02,  1.0360e-01, -4.0878e-02,\n",
              "                       -4.2697e-02, -2.6090e-01, -1.6544e-01, -2.2813e-01, -3.4041e-02,\n",
              "                       -1.9108e-01, -2.0858e-01, -2.4329e-01,  2.5279e-02,  2.4480e-02,\n",
              "                       -1.2921e-01,  6.6503e-03,  1.2826e-01, -1.9499e-01, -1.2286e-01,\n",
              "                       -1.7484e-01,  2.2954e-02, -3.3802e-02,  1.6398e-01, -2.7393e-01,\n",
              "                        4.4774e-02, -9.7249e-02, -2.8936e-02,  3.6314e-02,  1.2736e-01,\n",
              "                       -8.5061e-02, -2.2160e-02, -4.3429e-03,  9.0347e-02, -4.5799e-02,\n",
              "                       -2.9034e-01,  8.9424e-02, -1.3177e-01,  1.3366e-01, -1.0684e-01,\n",
              "                        1.9650e-01,  2.1380e-02, -1.4263e-01, -1.2987e-01],\n",
              "                      [ 8.0527e-02, -6.9936e-04, -1.8440e-01,  1.1717e-01, -3.7756e-01,\n",
              "                       -6.7468e-02, -1.5667e-01, -2.0755e-01, -1.0310e-01,  7.1767e-02,\n",
              "                       -2.0145e-01,  5.0998e-02,  8.0554e-02,  1.2831e-01, -2.6437e-01,\n",
              "                       -3.8163e-01, -2.1519e-01, -1.3688e-01,  1.7053e-01, -9.2981e-03,\n",
              "                       -4.9034e-01,  1.8303e-01, -6.3352e-02, -1.2537e-01, -9.2299e-02,\n",
              "                       -4.9045e-02, -8.7175e-02,  1.0087e-01,  1.2594e-01, -5.7340e-02,\n",
              "                        7.7662e-02,  1.2764e-01, -7.3948e-02,  9.9066e-02, -3.6424e-01,\n",
              "                        1.6530e-01,  4.2991e-02, -3.7876e-04,  1.2653e-01, -9.9515e-02,\n",
              "                       -1.6171e-01, -2.6207e-01,  1.2642e-01, -1.0301e-01, -3.8597e-02,\n",
              "                       -2.5949e-01, -4.0102e-02, -1.6334e-01, -3.1535e-03,  9.5392e-02,\n",
              "                        1.9991e-01, -2.1034e-01, -4.6928e-02,  2.9913e-03, -1.2064e-01,\n",
              "                       -7.1262e-02, -2.4595e-01,  9.1223e-02,  6.6555e-03, -3.2185e-02,\n",
              "                       -4.2523e-02, -1.1373e-01, -4.1103e-02, -2.2379e-02],\n",
              "                      [-2.6639e-02, -4.9905e-02, -1.9280e-01, -8.7954e-02, -2.1338e-01,\n",
              "                        1.7716e-01,  7.3641e-02, -8.6437e-02,  1.7046e-01, -1.2248e-01,\n",
              "                       -7.8791e-02, -2.1608e-01, -4.4691e-02, -5.7541e-02,  6.5678e-02,\n",
              "                       -1.5597e-01, -6.6167e-02,  1.4628e-01, -3.6590e-02, -7.6277e-02,\n",
              "                        7.0731e-02,  1.2854e-01,  3.3084e-03, -2.1850e-01, -4.5549e-01,\n",
              "                       -3.2332e-02,  1.7795e-02,  5.6002e-02, -1.4506e-01,  5.6319e-02,\n",
              "                       -7.7656e-03, -2.1966e-01, -3.4202e-02, -5.8937e-02,  5.5518e-02,\n",
              "                       -8.4144e-02, -8.6981e-02,  7.5757e-02,  1.1461e-01,  1.1005e-02,\n",
              "                       -1.1787e-01, -1.6547e-01,  1.4386e-01, -7.4872e-02,  1.1260e-01,\n",
              "                       -9.3629e-02,  4.8144e-02, -2.4308e-01,  1.8799e-02,  1.2744e-01,\n",
              "                       -2.2816e-01,  4.7110e-02,  5.8897e-02,  9.6572e-02, -4.9287e-02,\n",
              "                       -1.9062e-01, -3.4617e-03,  8.7256e-02,  1.7190e-01,  1.0175e-01,\n",
              "                        9.3590e-02,  4.5341e-02,  2.4749e-02, -8.6945e-03],\n",
              "                      [ 5.9198e-02, -1.4971e-01, -9.7188e-02, -1.2221e-01, -1.5573e-01,\n",
              "                        1.5950e-01,  2.6218e-02,  8.2093e-03, -1.5829e-01, -2.3822e-01,\n",
              "                        1.2463e-01, -1.1859e-01, -7.6052e-02,  1.9792e-02,  9.6583e-02,\n",
              "                       -1.9772e-01, -6.2933e-02,  1.9615e-02,  1.4603e-01,  1.7161e-02,\n",
              "                        3.7421e-02, -8.3916e-02,  9.4765e-02,  6.9403e-02, -1.7282e-01,\n",
              "                       -4.0344e-03, -3.3327e-01, -8.5024e-02,  3.8942e-02, -5.6872e-02,\n",
              "                       -9.1727e-02,  1.1133e-02, -1.5001e-01, -2.1141e-02, -1.0731e-01,\n",
              "                       -9.3394e-02, -1.5909e-02,  7.1904e-02,  1.6437e-01, -5.1592e-02,\n",
              "                       -2.1686e-01,  9.9757e-02, -2.0598e-02, -2.8799e-01,  1.4090e-01,\n",
              "                       -1.1475e-02, -2.2539e-01, -6.3897e-02,  1.4890e-01,  6.4978e-02,\n",
              "                       -5.7421e-02, -6.9976e-02,  7.4733e-02,  1.9975e-01, -1.3631e-01,\n",
              "                        1.2692e-01,  2.9700e-02, -1.4718e-02,  5.1793e-03, -2.9027e-02,\n",
              "                       -1.5312e-01,  2.0889e-02, -1.6939e-01, -4.4671e-02],\n",
              "                      [ 1.3601e-02,  3.4387e-02, -1.3839e-01,  1.3523e-01, -2.2648e-01,\n",
              "                       -1.1276e-01, -5.7338e-02, -6.2247e-02,  1.3348e-01, -5.2199e-03,\n",
              "                        8.8016e-02, -5.2034e-02, -8.9455e-02,  9.6045e-03, -1.6267e-01,\n",
              "                       -1.0997e-01, -1.5902e-01, -9.8831e-02,  3.3417e-02, -1.3838e-02,\n",
              "                        6.3099e-02,  3.4767e-02, -1.9705e-01,  4.2852e-03, -2.5631e-01,\n",
              "                        2.1715e-02,  1.4374e-02, -2.6716e-02,  3.3939e-03, -2.1987e-01,\n",
              "                       -9.5788e-02,  1.6396e-01,  1.7821e-02,  1.0946e-02,  1.4986e-01,\n",
              "                        9.2288e-02, -1.0144e-01, -1.8618e-02, -1.2044e-04, -1.2222e-01,\n",
              "                       -5.6505e-02, -2.0812e-01, -2.6812e-02, -1.8149e-01,  1.0401e-01,\n",
              "                       -5.4234e-02,  1.8465e-02,  9.2364e-02, -8.0603e-03,  4.0180e-02,\n",
              "                       -3.0521e-02,  9.8548e-02, -2.2265e-01, -1.0132e-01,  1.0515e-01,\n",
              "                        6.8693e-02, -1.8465e-01,  3.3156e-02, -5.4205e-02,  2.1594e-01,\n",
              "                        8.0506e-02, -3.4505e-02, -1.5035e-01,  7.2493e-02],\n",
              "                      [-1.5107e-02, -1.7190e-01, -2.5686e-02, -2.0609e-01,  2.4864e-02,\n",
              "                        6.2660e-03, -1.1918e-01,  2.0434e-02, -9.6026e-02, -4.8028e-02,\n",
              "                       -1.2094e-01, -1.0661e-01, -8.2729e-02,  4.1797e-02, -9.0162e-02,\n",
              "                       -4.6264e-02,  1.8812e-01,  8.3817e-02,  1.1808e-01, -7.0366e-03,\n",
              "                       -5.1755e-02, -4.5842e-02,  8.8472e-02,  7.0996e-03, -1.5127e-01,\n",
              "                        5.1642e-03, -1.2410e-01, -8.3846e-02,  1.4713e-03, -2.3384e-02,\n",
              "                        9.8134e-02,  2.3282e-02,  1.3950e-01, -1.6195e-01,  5.5275e-02,\n",
              "                       -1.8728e-02,  1.5886e-01,  6.4935e-02, -1.1813e-01, -1.1567e-01,\n",
              "                       -1.5507e-01,  1.0447e-01, -2.9090e-02,  4.4763e-03,  9.7352e-02,\n",
              "                        1.1801e-01, -1.3295e-01,  4.4080e-02,  3.5852e-02, -9.3856e-02,\n",
              "                       -2.5354e-03,  1.4111e-02,  8.6333e-04, -1.0574e-01, -7.3117e-02,\n",
              "                        5.2291e-02, -7.2708e-03,  1.1661e-01, -7.5096e-02, -1.6445e-01,\n",
              "                       -9.4599e-02, -1.4393e-01,  9.2639e-02, -1.0104e-01],\n",
              "                      [-9.2999e-02,  3.2939e-02,  7.7569e-02,  1.2329e-01,  6.8271e-02,\n",
              "                       -5.7074e-02, -9.7534e-02,  1.0594e-01, -1.8849e-01,  1.0334e-01,\n",
              "                        1.4596e-01, -1.2874e-01,  1.8499e-02, -2.5217e-01, -3.7181e-01,\n",
              "                       -8.4419e-02,  2.5565e-02, -8.0157e-02, -4.5190e-02,  4.6831e-03,\n",
              "                        8.4701e-03, -2.4271e-02, -1.3587e-01,  1.8156e-01, -2.2558e-01,\n",
              "                       -3.1215e-02, -3.8632e-01, -2.0433e-01, -2.0086e-01, -1.9205e-01,\n",
              "                       -2.1231e-02, -1.4768e-01,  1.3509e-01,  7.8970e-02, -2.7377e-02,\n",
              "                       -3.4304e-02,  1.5141e-01, -1.8696e-01, -9.3842e-02,  8.0565e-02,\n",
              "                       -2.5625e-01, -5.1263e-02,  1.6240e-01, -1.0645e-01, -3.5994e-02,\n",
              "                       -4.1154e-02,  1.9525e-02,  5.6315e-02,  1.8552e-01, -1.0291e-01,\n",
              "                       -4.7442e-03,  2.8336e-02, -5.3458e-02, -2.9615e-01, -7.4837e-02,\n",
              "                       -1.4042e-01, -4.0359e-01, -1.5856e-02, -2.2115e-01,  4.3629e-03,\n",
              "                        7.6001e-02, -1.6410e-01, -5.1871e-02, -8.2789e-02],\n",
              "                      [-1.8239e-03,  3.5877e-02, -4.2871e-02,  9.6933e-02, -6.5738e-02,\n",
              "                       -9.5464e-02, -2.2584e-01, -2.1874e-02, -1.3169e-01, -1.0763e-01,\n",
              "                       -2.9869e-01, -2.4803e-01, -1.0345e-01,  9.4159e-02,  1.2660e-01,\n",
              "                        7.4724e-02, -1.7667e-01, -6.6567e-02,  1.2672e-01, -4.3086e-02,\n",
              "                       -2.6427e-01,  5.4197e-02, -1.8951e-01, -1.4216e-01,  5.9037e-04,\n",
              "                        3.8746e-02,  1.7537e-02,  1.9705e-01, -2.0985e-01, -9.0419e-02,\n",
              "                       -1.9331e-01, -2.6807e-02, -7.3848e-02, -2.4975e-01,  3.3268e-02,\n",
              "                       -8.3329e-02, -9.7251e-02,  2.0017e-02,  2.1676e-01, -1.8951e-01,\n",
              "                       -3.0675e-02,  1.5512e-02,  2.8178e-02,  1.7990e-01, -3.5415e-02,\n",
              "                       -1.8663e-01,  7.4498e-02,  3.1793e-02,  9.6635e-02,  1.7503e-02,\n",
              "                       -6.1472e-02, -1.0570e-01,  4.2936e-02,  7.0300e-02, -8.3744e-02,\n",
              "                        4.0475e-02,  1.2125e-01, -2.5267e-01,  1.1248e-01,  1.2021e-01,\n",
              "                       -2.5559e-01, -1.4190e-01, -2.0342e-02,  1.4038e-01],\n",
              "                      [-1.0926e-01,  3.6893e-03, -6.8264e-03, -3.8456e-02, -1.7640e-01,\n",
              "                        4.7644e-02, -1.5130e-01, -2.5377e-02, -1.0458e-01,  1.5831e-01,\n",
              "                       -1.4367e-01, -2.2789e-01,  5.8957e-03, -1.2621e-01, -1.1740e-01,\n",
              "                       -1.6444e-01, -7.8225e-02, -1.3360e-01, -4.0109e-02,  3.9534e-02,\n",
              "                       -4.8940e-03,  5.0944e-02,  1.0072e-01,  8.4909e-02, -2.0891e-02,\n",
              "                        6.8689e-02, -1.2404e-01,  4.1738e-02, -1.9037e-01, -7.3585e-02,\n",
              "                        1.0875e-01, -1.8278e-02, -4.9892e-02,  1.3167e-01, -7.3981e-02,\n",
              "                        4.9814e-02,  9.5502e-02,  8.7666e-02, -1.1627e-03,  2.6633e-02,\n",
              "                       -9.4880e-01, -1.6348e-01, -2.1192e-01, -4.6418e-02, -2.0423e-01,\n",
              "                        9.1853e-02, -5.0921e-02, -1.3586e-01,  6.1529e-02, -1.6755e-01,\n",
              "                        1.2155e-01,  5.5066e-02, -1.0048e-01,  1.8947e-01,  1.1460e-01,\n",
              "                        1.1254e-01, -3.1178e-03, -3.0175e-03, -1.0087e-01, -8.0817e-03,\n",
              "                        6.3748e-03, -2.3625e-02, -2.9221e-02, -9.4227e-02],\n",
              "                      [-8.8030e-02,  4.4791e-02, -1.4275e-01,  1.2185e-01, -9.9455e-02,\n",
              "                       -1.4812e-01, -2.3699e-01, -7.5080e-02,  1.3385e-01, -9.7905e-02,\n",
              "                        4.7397e-02, -2.7456e-01, -1.4125e-01,  3.6336e-02, -1.3590e-01,\n",
              "                       -8.5423e-02, -5.4281e-02,  1.8237e-01,  5.1911e-02, -1.2305e-01,\n",
              "                       -1.6228e-01, -1.9630e-01, -1.1666e-01,  8.8990e-02, -1.9312e-01,\n",
              "                        7.4491e-03,  1.0965e-01,  3.9147e-02,  4.1901e-02, -3.0227e-01,\n",
              "                       -2.1925e-01,  1.9131e-01, -7.1291e-04, -4.1714e-02,  1.2805e-01,\n",
              "                        6.8660e-02,  3.2590e-02,  2.1558e-02, -6.8939e-02, -2.2284e-01,\n",
              "                       -1.5666e-01,  3.4934e-02, -1.5571e-01, -7.0096e-02,  2.9952e-02,\n",
              "                        5.6766e-02,  2.0466e-02, -1.6385e-02, -2.1642e-01,  1.2343e-01,\n",
              "                        4.2198e-02,  1.4266e-01, -8.6312e-02,  3.5222e-02, -2.8075e-02,\n",
              "                        1.3317e-01,  1.9045e-01, -7.6952e-02,  1.2839e-02, -2.2569e-02,\n",
              "                       -8.7107e-02, -3.2407e-04,  8.0567e-02,  1.5460e-01]])),\n",
              "             ('fc4.bias',\n",
              "              tensor([-0.0511, -0.2006, -0.0133, -0.0142,  0.1217, -0.0243, -0.1196, -0.1175,\n",
              "                       0.5232,  0.0088]))])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFDOc34BBejd",
        "outputId": "1fdfdaeb-d035-4770-b67f-bcbf7ed211d8"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fc1', 'fc2', 'fc3', 'fc4']"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMHWbShKF2KO",
        "outputId": "f61d63bb-3112-4ac4-90df-1936f442fd5c"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('fc1.weight',\n",
              "              tensor([[ 0.0329,  0.0086,  0.0243,  ...,  0.0497,  0.0563,  0.0528],\n",
              "                      [-0.0129,  0.0104,  0.0365,  ...,  0.0194,  0.0207,  0.0246],\n",
              "                      [ 0.0081,  0.0136, -0.0052,  ...,  0.0030,  0.0517,  0.0313],\n",
              "                      ...,\n",
              "                      [ 0.0393,  0.0300,  0.0377,  ...,  0.0255,  0.0073,  0.0581],\n",
              "                      [ 0.0441,  0.0390,  0.0418,  ...,  0.0376, -0.0042,  0.0096],\n",
              "                      [ 0.0226,  0.0080,  0.0011,  ..., -0.0116,  0.0461,  0.0215]])),\n",
              "             ('fc1.bias',\n",
              "              tensor([-5.0697e-02, -1.5882e-03, -4.5533e-02, -8.9822e-04, -7.9249e-02,\n",
              "                       3.3151e-03, -3.6789e-02, -1.7230e-02, -5.2123e-02, -2.5209e-02,\n",
              "                       8.5094e-03, -5.6987e-02, -2.2219e-02, -2.8807e-02, -1.7612e-02,\n",
              "                       4.9885e-03, -1.4747e-03, -7.5809e-02,  1.5871e-02, -4.0564e-03,\n",
              "                      -3.7250e-03, -4.6109e-02,  2.5242e-03,  4.4355e-03,  1.0314e-02,\n",
              "                      -7.1663e-02,  9.1916e-03, -3.6697e-02, -3.8919e-02, -3.2340e-02,\n",
              "                      -1.7095e-02, -2.2695e-02, -7.3756e-03, -3.2307e-03, -2.6671e-02,\n",
              "                      -1.4188e-02, -5.8340e-03, -3.8018e-02, -3.0583e-02, -1.8098e-02,\n",
              "                       2.1612e-02, -8.6132e-02, -2.3886e-02, -1.1493e-02, -8.3055e-03,\n",
              "                      -1.7589e-03,  1.1987e-02, -4.2030e-02, -3.9615e-02,  4.4278e-03,\n",
              "                      -1.7534e-02, -2.4694e-02, -2.1543e-02, -3.4609e-02,  2.3570e-02,\n",
              "                       2.6285e-02, -1.3856e-02,  1.1432e-02, -2.7742e-02,  3.2082e-04,\n",
              "                       4.6447e-03,  1.1198e-02, -1.5167e-02, -4.9473e-02, -4.2446e-02,\n",
              "                       5.3062e-02, -6.3078e-02, -2.2603e-02, -1.0497e-02, -4.7284e-03,\n",
              "                      -4.0333e-02,  4.8095e-03, -5.9835e-02,  5.7884e-03, -5.8095e-03,\n",
              "                      -2.4915e-02, -1.1267e-02, -5.3225e-02,  1.0887e-02, -3.1268e-03,\n",
              "                      -2.1667e-02, -5.2839e-02, -3.7480e-02, -2.9252e-02, -1.0288e-02,\n",
              "                       9.7473e-03, -3.4331e-02, -2.6842e-02, -4.7752e-02, -4.4481e-03,\n",
              "                      -5.0411e-02, -1.8064e-02, -2.4959e-02,  3.8707e-02, -2.3788e-02,\n",
              "                      -3.0230e-02, -4.3937e-02, -3.9769e-02, -9.4580e-02,  4.1654e-02,\n",
              "                      -3.5936e-02, -2.1148e-02,  1.7497e-02, -3.1961e-02, -2.3776e-02,\n",
              "                      -3.7282e-02, -1.5092e-02,  9.8810e-03, -3.9213e-02, -3.9942e-02,\n",
              "                      -5.6907e-02, -3.7442e-03, -9.5044e-02, -2.5293e-02, -2.5454e-02,\n",
              "                      -4.7367e-02, -5.1332e-02, -2.0713e-03, -2.7323e-02,  5.7385e-03,\n",
              "                      -1.9152e-02, -3.3860e-02, -4.8206e-02, -3.2334e-03, -5.0366e-02,\n",
              "                      -3.5953e-02,  6.5205e-03, -2.6486e-02,  1.1088e-02, -2.8068e-02,\n",
              "                      -7.4271e-02, -1.1911e-02,  1.2842e-02, -2.5225e-02, -3.1306e-02,\n",
              "                      -1.9759e-02, -3.5803e-03,  2.0227e-03, -2.1660e-02,  1.1208e-02,\n",
              "                      -2.4123e-02,  9.0310e-03, -5.1055e-02, -4.5396e-02, -2.6411e-02,\n",
              "                       1.1292e-02,  1.4030e-02, -3.8358e-02, -3.2809e-02, -1.8572e-02,\n",
              "                       4.8251e-02, -2.9928e-03, -7.2177e-02, -4.8035e-02,  7.6769e-03,\n",
              "                      -6.5365e-02, -3.6413e-02, -1.1881e-02,  1.7021e-02, -1.1635e-02,\n",
              "                      -6.0688e-02, -2.3924e-02, -4.9127e-02, -6.5620e-02, -4.3793e-02,\n",
              "                      -4.4041e-02, -5.9561e-02, -2.9840e-02, -2.5970e-03, -4.9796e-02,\n",
              "                      -1.1559e-02,  7.0239e-03, -3.5945e-02,  1.5993e-02, -4.1892e-02,\n",
              "                      -6.8264e-02,  2.1650e-02, -4.1370e-02,  2.1973e-02, -1.5948e-02,\n",
              "                      -1.0226e-01, -3.7496e-02,  1.7094e-02, -1.0982e-02,  1.5540e-02,\n",
              "                      -5.0556e-02, -2.7001e-02, -2.0114e-02, -5.0169e-02, -2.9489e-02,\n",
              "                      -3.9743e-02, -8.5380e-03, -1.8673e-02, -3.8129e-02, -2.1269e-02,\n",
              "                      -2.5533e-02, -2.1255e-02, -1.3042e-02, -3.3605e-02, -1.3769e-02,\n",
              "                      -2.9272e-02, -2.0493e-02,  6.1399e-03,  3.2051e-02, -2.2862e-02,\n",
              "                      -4.3587e-02, -1.2302e-02, -6.0179e-03, -6.3411e-02, -1.3902e-04,\n",
              "                       6.6006e-03, -6.3300e-02, -8.8990e-03, -4.0236e-03, -5.1070e-02,\n",
              "                      -5.1127e-02, -3.9643e-02, -5.2284e-02, -4.6759e-02, -5.3112e-02,\n",
              "                      -2.7392e-02, -2.9490e-02, -2.2758e-02, -9.5000e-03, -1.2496e-02,\n",
              "                      -3.4707e-02, -1.4716e-02, -1.2888e-02, -1.2930e-03, -5.0056e-02,\n",
              "                      -4.8036e-02, -3.2378e-02, -3.6429e-02, -3.8621e-02, -3.1510e-02,\n",
              "                      -5.1300e-02,  1.4994e-02,  1.2208e-05, -1.4082e-02,  1.7620e-03,\n",
              "                      -4.7165e-02, -3.7629e-02, -3.8766e-02,  9.4560e-03, -1.5576e-02,\n",
              "                      -3.9815e-02,  1.1144e-02,  9.7832e-03, -1.2574e-02, -4.5413e-02,\n",
              "                      -8.2680e-03, -2.0615e-02, -1.7477e-02, -4.7983e-02, -2.5950e-02,\n",
              "                      -4.0306e-02])),\n",
              "             ('fc2.weight',\n",
              "              tensor([[ 0.0700,  0.0577, -0.0515,  ..., -0.0376, -0.0064, -0.0211],\n",
              "                      [ 0.2691,  0.0488, -0.0146,  ...,  0.1431,  0.0142, -0.0360],\n",
              "                      [ 0.1107,  0.0349,  0.0097,  ...,  0.0975, -0.0220,  0.0102],\n",
              "                      ...,\n",
              "                      [-0.0245,  0.0396, -0.0413,  ..., -0.0204, -0.0343,  0.0537],\n",
              "                      [-0.0211,  0.0468, -0.0537,  ..., -0.1140,  0.0065,  0.0199],\n",
              "                      [ 0.1608, -0.0083, -0.0337,  ...,  0.0963, -0.0206,  0.0148]])),\n",
              "             ('fc2.bias',\n",
              "              tensor([-0.0489,  0.1896,  0.1729, -0.1131, -0.1978,  0.0504, -0.0708, -0.1582,\n",
              "                      -0.0030, -0.1288,  0.0108,  0.0125, -0.0415, -0.1031, -0.0630, -0.0025,\n",
              "                      -0.1085, -0.0879, -0.0841,  0.3088,  0.1560,  0.0175, -0.2156, -0.1164,\n",
              "                      -0.1923, -0.0915, -0.1100, -0.0354, -0.2318, -0.0061, -0.0592, -0.1969,\n",
              "                      -0.0775, -0.1088, -0.1204, -0.1337, -0.2263,  0.1045, -0.1049, -0.1794,\n",
              "                      -0.1485, -0.1131, -0.1346, -0.1471,  0.0449,  0.0613,  0.1513, -0.0190,\n",
              "                      -0.0355, -0.1064,  0.2106, -0.1671,  0.0496,  0.0589, -0.1245, -0.1031,\n",
              "                       0.0060, -0.0687, -0.1207, -0.0791,  0.0110, -0.1303,  0.0872, -0.0913,\n",
              "                      -0.0502, -0.1575,  0.0946, -0.0620,  0.0189,  0.0400, -0.0242, -0.2191,\n",
              "                      -0.1293, -0.1497,  0.1555,  0.2938, -0.0674, -0.3190, -0.0629, -0.1634,\n",
              "                      -0.0147, -0.0193, -0.1928, -0.0061, -0.1173, -0.0514, -0.1626, -0.2278,\n",
              "                      -0.0745, -0.0037, -0.0470, -0.0303, -0.1636, -0.1014,  0.1747, -0.0842,\n",
              "                      -0.1578,  0.0232, -0.0125, -0.1983,  0.4642, -0.1431,  0.0178, -0.0420,\n",
              "                      -0.0608, -0.0430, -0.0866,  0.0265, -0.0709,  0.0132,  0.0132, -0.1032,\n",
              "                      -0.0352, -0.0149, -0.2466, -0.0685, -0.1978, -0.0966, -0.0275, -0.2409,\n",
              "                       0.2949, -0.1386,  0.0520, -0.1878, -0.1932, -0.0528, -0.0524,  0.1045])),\n",
              "             ('fc3.weight',\n",
              "              tensor([[-0.0898,  0.0228, -0.0250,  ...,  0.0682, -0.1015, -0.0751],\n",
              "                      [ 0.0142, -0.0617, -0.0568,  ..., -0.0338, -0.0558,  0.0405],\n",
              "                      [-0.1508, -0.0901, -0.0380,  ...,  0.0528,  0.0925, -0.0676],\n",
              "                      ...,\n",
              "                      [ 0.0139,  0.0265, -0.1787,  ...,  0.0430,  0.0435, -0.0926],\n",
              "                      [-0.0654, -0.0217, -0.1451,  ...,  0.0332, -0.0209, -0.1631],\n",
              "                      [ 0.0609, -0.0105, -0.0566,  ...,  0.0403,  0.1513, -0.0428]])),\n",
              "             ('fc3.bias',\n",
              "              tensor([-0.1711, -0.1505, -0.1412,  0.0111, -0.0597,  0.1476, -0.0710, -0.0209,\n",
              "                       0.1606,  0.2981,  0.1772, -0.2506, -0.0747, -0.2264, -0.2045, -0.3326,\n",
              "                      -0.1356, -0.0518, -0.1744, -0.1427, -0.0377,  0.1834,  0.2696,  0.4100,\n",
              "                      -0.2308, -0.2062, -0.0479,  0.0068, -0.1853,  0.1144, -0.1299,  0.1610,\n",
              "                      -0.0101,  0.0754,  0.0926, -0.0319,  0.1107,  0.1191, -0.2281, -0.1523,\n",
              "                      -0.2556, -0.1582, -0.0862, -0.0819, -0.0549,  0.1640, -0.1267, -0.0659,\n",
              "                       0.0778, -0.0852, -0.0334,  0.2512, -0.0555,  0.2768,  0.0982,  0.3895,\n",
              "                       0.1073, -0.1683,  0.0174, -0.0115,  0.2321, -0.3172, -0.1211,  0.0065])),\n",
              "             ('fc4.weight',\n",
              "              tensor([[-3.0591e-02,  3.4098e-02, -1.2472e-02, -8.9146e-03, -9.6389e-02,\n",
              "                       -3.0413e-02, -2.2714e-02, -1.3556e-01,  6.6748e-02, -3.5200e-02,\n",
              "                        1.7505e-01, -3.1370e-01,  1.0929e-01, -1.2965e-01, -2.6508e-01,\n",
              "                       -4.6322e-03, -3.6083e-02,  1.6212e-01, -1.5626e-01,  9.0508e-03,\n",
              "                        5.9090e-02, -1.5017e-01, -7.2761e-02,  1.0360e-01, -4.0878e-02,\n",
              "                       -4.2697e-02, -2.6090e-01, -1.6544e-01, -2.2813e-01, -3.4041e-02,\n",
              "                       -1.9108e-01, -2.0858e-01, -2.4329e-01,  2.5279e-02,  2.4480e-02,\n",
              "                       -1.2921e-01,  6.6503e-03,  1.2826e-01, -1.9499e-01, -1.2286e-01,\n",
              "                       -1.7484e-01,  2.2954e-02, -3.3802e-02,  1.6398e-01, -2.7393e-01,\n",
              "                        4.4774e-02, -9.7249e-02, -2.8936e-02,  3.6314e-02,  1.2736e-01,\n",
              "                       -8.5061e-02, -2.2160e-02, -4.3429e-03,  9.0347e-02, -4.5799e-02,\n",
              "                       -2.9034e-01,  8.9424e-02, -1.3177e-01,  1.3366e-01, -1.0684e-01,\n",
              "                        1.9650e-01,  2.1380e-02, -1.4263e-01, -1.2987e-01],\n",
              "                      [ 8.0527e-02, -6.9936e-04, -1.8440e-01,  1.1717e-01, -3.7756e-01,\n",
              "                       -6.7468e-02, -1.5667e-01, -2.0755e-01, -1.0310e-01,  7.1767e-02,\n",
              "                       -2.0145e-01,  5.0998e-02,  8.0554e-02,  1.2831e-01, -2.6437e-01,\n",
              "                       -3.8163e-01, -2.1519e-01, -1.3688e-01,  1.7053e-01, -9.2981e-03,\n",
              "                       -4.9034e-01,  1.8303e-01, -6.3352e-02, -1.2537e-01, -9.2299e-02,\n",
              "                       -4.9045e-02, -8.7175e-02,  1.0087e-01,  1.2594e-01, -5.7340e-02,\n",
              "                        7.7662e-02,  1.2764e-01, -7.3948e-02,  9.9066e-02, -3.6424e-01,\n",
              "                        1.6530e-01,  4.2991e-02, -3.7876e-04,  1.2653e-01, -9.9515e-02,\n",
              "                       -1.6171e-01, -2.6207e-01,  1.2642e-01, -1.0301e-01, -3.8597e-02,\n",
              "                       -2.5949e-01, -4.0102e-02, -1.6334e-01, -3.1535e-03,  9.5392e-02,\n",
              "                        1.9991e-01, -2.1034e-01, -4.6928e-02,  2.9913e-03, -1.2064e-01,\n",
              "                       -7.1262e-02, -2.4595e-01,  9.1223e-02,  6.6555e-03, -3.2185e-02,\n",
              "                       -4.2523e-02, -1.1373e-01, -4.1103e-02, -2.2379e-02],\n",
              "                      [-2.6639e-02, -4.9905e-02, -1.9280e-01, -8.7954e-02, -2.1338e-01,\n",
              "                        1.7716e-01,  7.3641e-02, -8.6437e-02,  1.7046e-01, -1.2248e-01,\n",
              "                       -7.8791e-02, -2.1608e-01, -4.4691e-02, -5.7541e-02,  6.5678e-02,\n",
              "                       -1.5597e-01, -6.6167e-02,  1.4628e-01, -3.6590e-02, -7.6277e-02,\n",
              "                        7.0731e-02,  1.2854e-01,  3.3084e-03, -2.1850e-01, -4.5549e-01,\n",
              "                       -3.2332e-02,  1.7795e-02,  5.6002e-02, -1.4506e-01,  5.6319e-02,\n",
              "                       -7.7656e-03, -2.1966e-01, -3.4202e-02, -5.8937e-02,  5.5518e-02,\n",
              "                       -8.4144e-02, -8.6981e-02,  7.5757e-02,  1.1461e-01,  1.1005e-02,\n",
              "                       -1.1787e-01, -1.6547e-01,  1.4386e-01, -7.4872e-02,  1.1260e-01,\n",
              "                       -9.3629e-02,  4.8144e-02, -2.4308e-01,  1.8799e-02,  1.2744e-01,\n",
              "                       -2.2816e-01,  4.7110e-02,  5.8897e-02,  9.6572e-02, -4.9287e-02,\n",
              "                       -1.9062e-01, -3.4617e-03,  8.7256e-02,  1.7190e-01,  1.0175e-01,\n",
              "                        9.3590e-02,  4.5341e-02,  2.4749e-02, -8.6945e-03],\n",
              "                      [ 5.9198e-02, -1.4971e-01, -9.7188e-02, -1.2221e-01, -1.5573e-01,\n",
              "                        1.5950e-01,  2.6218e-02,  8.2093e-03, -1.5829e-01, -2.3822e-01,\n",
              "                        1.2463e-01, -1.1859e-01, -7.6052e-02,  1.9792e-02,  9.6583e-02,\n",
              "                       -1.9772e-01, -6.2933e-02,  1.9615e-02,  1.4603e-01,  1.7161e-02,\n",
              "                        3.7421e-02, -8.3916e-02,  9.4765e-02,  6.9403e-02, -1.7282e-01,\n",
              "                       -4.0344e-03, -3.3327e-01, -8.5024e-02,  3.8942e-02, -5.6872e-02,\n",
              "                       -9.1727e-02,  1.1133e-02, -1.5001e-01, -2.1141e-02, -1.0731e-01,\n",
              "                       -9.3394e-02, -1.5909e-02,  7.1904e-02,  1.6437e-01, -5.1592e-02,\n",
              "                       -2.1686e-01,  9.9757e-02, -2.0598e-02, -2.8799e-01,  1.4090e-01,\n",
              "                       -1.1475e-02, -2.2539e-01, -6.3897e-02,  1.4890e-01,  6.4978e-02,\n",
              "                       -5.7421e-02, -6.9976e-02,  7.4733e-02,  1.9975e-01, -1.3631e-01,\n",
              "                        1.2692e-01,  2.9700e-02, -1.4718e-02,  5.1793e-03, -2.9027e-02,\n",
              "                       -1.5312e-01,  2.0889e-02, -1.6939e-01, -4.4671e-02],\n",
              "                      [ 1.3601e-02,  3.4387e-02, -1.3839e-01,  1.3523e-01, -2.2648e-01,\n",
              "                       -1.1276e-01, -5.7338e-02, -6.2247e-02,  1.3348e-01, -5.2199e-03,\n",
              "                        8.8016e-02, -5.2034e-02, -8.9455e-02,  9.6045e-03, -1.6267e-01,\n",
              "                       -1.0997e-01, -1.5902e-01, -9.8831e-02,  3.3417e-02, -1.3838e-02,\n",
              "                        6.3099e-02,  3.4767e-02, -1.9705e-01,  4.2852e-03, -2.5631e-01,\n",
              "                        2.1715e-02,  1.4374e-02, -2.6716e-02,  3.3939e-03, -2.1987e-01,\n",
              "                       -9.5788e-02,  1.6396e-01,  1.7821e-02,  1.0946e-02,  1.4986e-01,\n",
              "                        9.2288e-02, -1.0144e-01, -1.8618e-02, -1.2044e-04, -1.2222e-01,\n",
              "                       -5.6505e-02, -2.0812e-01, -2.6812e-02, -1.8149e-01,  1.0401e-01,\n",
              "                       -5.4234e-02,  1.8465e-02,  9.2364e-02, -8.0603e-03,  4.0180e-02,\n",
              "                       -3.0521e-02,  9.8548e-02, -2.2265e-01, -1.0132e-01,  1.0515e-01,\n",
              "                        6.8693e-02, -1.8465e-01,  3.3156e-02, -5.4205e-02,  2.1594e-01,\n",
              "                        8.0506e-02, -3.4505e-02, -1.5035e-01,  7.2493e-02],\n",
              "                      [-1.5107e-02, -1.7190e-01, -2.5686e-02, -2.0609e-01,  2.4864e-02,\n",
              "                        6.2660e-03, -1.1918e-01,  2.0434e-02, -9.6026e-02, -4.8028e-02,\n",
              "                       -1.2094e-01, -1.0661e-01, -8.2729e-02,  4.1797e-02, -9.0162e-02,\n",
              "                       -4.6264e-02,  1.8812e-01,  8.3817e-02,  1.1808e-01, -7.0366e-03,\n",
              "                       -5.1755e-02, -4.5842e-02,  8.8472e-02,  7.0996e-03, -1.5127e-01,\n",
              "                        5.1642e-03, -1.2410e-01, -8.3846e-02,  1.4713e-03, -2.3384e-02,\n",
              "                        9.8134e-02,  2.3282e-02,  1.3950e-01, -1.6195e-01,  5.5275e-02,\n",
              "                       -1.8728e-02,  1.5886e-01,  6.4935e-02, -1.1813e-01, -1.1567e-01,\n",
              "                       -1.5507e-01,  1.0447e-01, -2.9090e-02,  4.4763e-03,  9.7352e-02,\n",
              "                        1.1801e-01, -1.3295e-01,  4.4080e-02,  3.5852e-02, -9.3856e-02,\n",
              "                       -2.5354e-03,  1.4111e-02,  8.6333e-04, -1.0574e-01, -7.3117e-02,\n",
              "                        5.2291e-02, -7.2708e-03,  1.1661e-01, -7.5096e-02, -1.6445e-01,\n",
              "                       -9.4599e-02, -1.4393e-01,  9.2639e-02, -1.0104e-01],\n",
              "                      [-9.2999e-02,  3.2939e-02,  7.7569e-02,  1.2329e-01,  6.8271e-02,\n",
              "                       -5.7074e-02, -9.7534e-02,  1.0594e-01, -1.8849e-01,  1.0334e-01,\n",
              "                        1.4596e-01, -1.2874e-01,  1.8499e-02, -2.5217e-01, -3.7181e-01,\n",
              "                       -8.4419e-02,  2.5565e-02, -8.0157e-02, -4.5190e-02,  4.6831e-03,\n",
              "                        8.4701e-03, -2.4271e-02, -1.3587e-01,  1.8156e-01, -2.2558e-01,\n",
              "                       -3.1215e-02, -3.8632e-01, -2.0433e-01, -2.0086e-01, -1.9205e-01,\n",
              "                       -2.1231e-02, -1.4768e-01,  1.3509e-01,  7.8970e-02, -2.7377e-02,\n",
              "                       -3.4304e-02,  1.5141e-01, -1.8696e-01, -9.3842e-02,  8.0565e-02,\n",
              "                       -2.5625e-01, -5.1263e-02,  1.6240e-01, -1.0645e-01, -3.5994e-02,\n",
              "                       -4.1154e-02,  1.9525e-02,  5.6315e-02,  1.8552e-01, -1.0291e-01,\n",
              "                       -4.7442e-03,  2.8336e-02, -5.3458e-02, -2.9615e-01, -7.4837e-02,\n",
              "                       -1.4042e-01, -4.0359e-01, -1.5856e-02, -2.2115e-01,  4.3629e-03,\n",
              "                        7.6001e-02, -1.6410e-01, -5.1871e-02, -8.2789e-02],\n",
              "                      [-1.8239e-03,  3.5877e-02, -4.2871e-02,  9.6933e-02, -6.5738e-02,\n",
              "                       -9.5464e-02, -2.2584e-01, -2.1874e-02, -1.3169e-01, -1.0763e-01,\n",
              "                       -2.9869e-01, -2.4803e-01, -1.0345e-01,  9.4159e-02,  1.2660e-01,\n",
              "                        7.4724e-02, -1.7667e-01, -6.6567e-02,  1.2672e-01, -4.3086e-02,\n",
              "                       -2.6427e-01,  5.4197e-02, -1.8951e-01, -1.4216e-01,  5.9037e-04,\n",
              "                        3.8746e-02,  1.7537e-02,  1.9705e-01, -2.0985e-01, -9.0419e-02,\n",
              "                       -1.9331e-01, -2.6807e-02, -7.3848e-02, -2.4975e-01,  3.3268e-02,\n",
              "                       -8.3329e-02, -9.7251e-02,  2.0017e-02,  2.1676e-01, -1.8951e-01,\n",
              "                       -3.0675e-02,  1.5512e-02,  2.8178e-02,  1.7990e-01, -3.5415e-02,\n",
              "                       -1.8663e-01,  7.4498e-02,  3.1793e-02,  9.6635e-02,  1.7503e-02,\n",
              "                       -6.1472e-02, -1.0570e-01,  4.2936e-02,  7.0300e-02, -8.3744e-02,\n",
              "                        4.0475e-02,  1.2125e-01, -2.5267e-01,  1.1248e-01,  1.2021e-01,\n",
              "                       -2.5559e-01, -1.4190e-01, -2.0342e-02,  1.4038e-01],\n",
              "                      [-1.0926e-01,  3.6893e-03, -6.8264e-03, -3.8456e-02, -1.7640e-01,\n",
              "                        4.7644e-02, -1.5130e-01, -2.5377e-02, -1.0458e-01,  1.5831e-01,\n",
              "                       -1.4367e-01, -2.2789e-01,  5.8957e-03, -1.2621e-01, -1.1740e-01,\n",
              "                       -1.6444e-01, -7.8225e-02, -1.3360e-01, -4.0109e-02,  3.9534e-02,\n",
              "                       -4.8940e-03,  5.0944e-02,  1.0072e-01,  8.4909e-02, -2.0891e-02,\n",
              "                        6.8689e-02, -1.2404e-01,  4.1738e-02, -1.9037e-01, -7.3585e-02,\n",
              "                        1.0875e-01, -1.8278e-02, -4.9892e-02,  1.3167e-01, -7.3981e-02,\n",
              "                        4.9814e-02,  9.5502e-02,  8.7666e-02, -1.1627e-03,  2.6633e-02,\n",
              "                       -9.4880e-01, -1.6348e-01, -2.1192e-01, -4.6418e-02, -2.0423e-01,\n",
              "                        9.1853e-02, -5.0921e-02, -1.3586e-01,  6.1529e-02, -1.6755e-01,\n",
              "                        1.2155e-01,  5.5066e-02, -1.0048e-01,  1.8947e-01,  1.1460e-01,\n",
              "                        1.1254e-01, -3.1178e-03, -3.0175e-03, -1.0087e-01, -8.0817e-03,\n",
              "                        6.3748e-03, -2.3625e-02, -2.9221e-02, -9.4227e-02],\n",
              "                      [-8.8030e-02,  4.4791e-02, -1.4275e-01,  1.2185e-01, -9.9455e-02,\n",
              "                       -1.4812e-01, -2.3699e-01, -7.5080e-02,  1.3385e-01, -9.7905e-02,\n",
              "                        4.7397e-02, -2.7456e-01, -1.4125e-01,  3.6336e-02, -1.3590e-01,\n",
              "                       -8.5423e-02, -5.4281e-02,  1.8237e-01,  5.1911e-02, -1.2305e-01,\n",
              "                       -1.6228e-01, -1.9630e-01, -1.1666e-01,  8.8990e-02, -1.9312e-01,\n",
              "                        7.4491e-03,  1.0965e-01,  3.9147e-02,  4.1901e-02, -3.0227e-01,\n",
              "                       -2.1925e-01,  1.9131e-01, -7.1291e-04, -4.1714e-02,  1.2805e-01,\n",
              "                        6.8660e-02,  3.2590e-02,  2.1558e-02, -6.8939e-02, -2.2284e-01,\n",
              "                       -1.5666e-01,  3.4934e-02, -1.5571e-01, -7.0096e-02,  2.9952e-02,\n",
              "                        5.6766e-02,  2.0466e-02, -1.6385e-02, -2.1642e-01,  1.2343e-01,\n",
              "                        4.2198e-02,  1.4266e-01, -8.6312e-02,  3.5222e-02, -2.8075e-02,\n",
              "                        1.3317e-01,  1.9045e-01, -7.6952e-02,  1.2839e-02, -2.2569e-02,\n",
              "                       -8.7107e-02, -3.2407e-04,  8.0567e-02,  1.5460e-01]])),\n",
              "             ('fc4.bias',\n",
              "              tensor([-0.0511, -0.2006, -0.0133, -0.0142,  0.1217, -0.0243, -0.1196, -0.1175,\n",
              "                       0.5232,  0.0088]))])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Blockchain"
      ],
      "metadata": {
        "id": "0-Oon_BRtDfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important parameters: \n",
        "\n",
        "*   Nonce: to check for difficulty\n",
        "*   Data: data to store in block (one or more transactions)\n",
        "* Previous Hash: Hash of previous block\n",
        "* Timestamp: time the block is created\n",
        "* Block Number: order of block in chain\n",
        "\n"
      ],
      "metadata": {
        "id": "MXNVQiKOtexw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import hashlib\n",
        "class Block:\n",
        "    blockNo = 0\n",
        "    data = None\n",
        "    next = None\n",
        "    current_hash = None\n",
        "    nonce = 0\n",
        "    previous_hash = 0x0\n",
        "    timestamp = datetime.datetime.now()\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def hash(self):\n",
        "        h = hashlib.sha256()\n",
        "        h.update(\n",
        "          str(self.nonce).encode('utf-8') +\n",
        "          str(self.data).encode('utf-8') +\n",
        "          str(self.previous_hash).encode('utf-8') +\n",
        "          str(self.timestamp).encode('utf-8') +\n",
        "          str(self.blockNo).encode('utf-8')\n",
        "        )\n",
        "        return h.hexdigest()\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"\\n--------------Block Hash: \" + str(self.hash()) + \"\\nBlockNo: \" + str(self.blockNo) + \"\\nBlock Data: \" + str(self.data) + \"\\nNonce: \" + str(self.nonce) + \"\\nPrevious Block Hash: \" + str(self.previous_hash) +  \"\\n--------------\" \n"
      ],
      "metadata": {
        "id": "vHI4w6SVsSRK"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Blockchain:\n",
        "    difficulty = 1 # smaller = easier\n",
        "    maxNonce = 2**32\n",
        "    target = 2 ** (256-difficulty)\n",
        "    def __init__(self):\n",
        "        self.chain = []\n",
        "        self.mine(Block(\"Genesis\"))\n",
        "\n",
        "    def add(self, block):\n",
        "        self.chain.append(block)\n",
        "\n",
        "    def mine(self, block):\n",
        "        block.previous_hash = self.last_block.hash() if len(self.chain) > 0 else \"00000000000000000000000000000000\"\n",
        "        block.blockNo = self.last_block.blockNo + 1 if len(self.chain) > 0 else 0\n",
        "        for n in range(self.maxNonce):\n",
        "            if int(block.hash(), 16) <= self.target:\n",
        "              if block.hash().startswith('000'):\n",
        "                print(\"Block {} - Qualified: {}\".format(block.blockNo, block.hash()))\n",
        "                self.add(block)\n",
        "                break\n",
        "            block.nonce += 1\n",
        "    def modify_block(self, blockNo, injected_data): \n",
        "        target_block = self.chain[blockNo]\n",
        "        target_block.data = injected_data\n",
        "        return target_block.__str__()\n",
        "    def validate_chain(self):\n",
        "      for i, block in enumerate(self.chain):\n",
        "        if block.blockNo > 0:\n",
        "          print(\"\\nPrevious_Hash: \" + block.previous_hash)\n",
        "          print('Hash of Previous Block: ' + self.chain[i-1].hash())\n",
        "          if block.previous_hash != self.chain[i-1].hash():\n",
        "            print('Block {} is tampered!'.format(block.blockNo - 1))\n",
        "            return False\n",
        "      print(\"Blockchain is correct!\")\n",
        "      return True\n",
        "\n",
        "    @property\n",
        "    def last_block(self):\n",
        "        return self.chain[-1] if len(self.chain) > 0 else Block(\"Genesis\")\n",
        "    def __str__(self):\n",
        "        for bl in self.chain:\n",
        "          print(bl)\n",
        "        return '==========================END OF CHAIN============================'"
      ],
      "metadata": {
        "id": "qLE93_4fCqHG"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = []\n",
        "for layer_name in model_layers:\n",
        "  raw_data.append({\n",
        "      \"layer\": layer_name,\n",
        "      'weight' : model_weights[layer_name + '.weight'],\n",
        "      'bias': model_weights[layer_name + '.bias'],\n",
        "\n",
        "  })"
      ],
      "metadata": {
        "id": "wTARorstC1KX"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blockchain = Blockchain()"
      ],
      "metadata": {
        "id": "g8IjNqYiCuVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b4a244-48f4-4b77-d980-a0e86c74f3ef"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block 0 - Qualified: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in raw_data: \n",
        "  newBlock = Block(x)\n",
        "  blockchain.mine(newBlock)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz3Er7fGHWW9",
        "outputId": "eed70f33-1a71-4f24-fdd0-17425e114125"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block 1 - Qualified: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Block 2 - Qualified: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Block 3 - Qualified: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Block 4 - Qualified: 000c7d81680ba960bc28b54930ce571c511bca021e1bef7efc4d487951494832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(blockchain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0XReAdgCy9x",
        "outputId": "cc1a716d-3b2d-49fc-ce4a-0ed19b356184"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------Block Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "BlockNo: 0\n",
            "Block Data: Genesis\n",
            "Nonce: 1176\n",
            "Previous Block Hash: 00000000000000000000000000000000\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "BlockNo: 1\n",
            "Block Data: {'layer': 'fc1', 'weight': tensor([[ 0.0329,  0.0086,  0.0243,  ...,  0.0497,  0.0563,  0.0528],\n",
            "        [-0.0129,  0.0104,  0.0365,  ...,  0.0194,  0.0207,  0.0246],\n",
            "        [ 0.0081,  0.0136, -0.0052,  ...,  0.0030,  0.0517,  0.0313],\n",
            "        ...,\n",
            "        [ 0.0393,  0.0300,  0.0377,  ...,  0.0255,  0.0073,  0.0581],\n",
            "        [ 0.0441,  0.0390,  0.0418,  ...,  0.0376, -0.0042,  0.0096],\n",
            "        [ 0.0226,  0.0080,  0.0011,  ..., -0.0116,  0.0461,  0.0215]]), 'bias': tensor([-5.0697e-02, -1.5882e-03, -4.5533e-02, -8.9822e-04, -7.9249e-02,\n",
            "         3.3151e-03, -3.6789e-02, -1.7230e-02, -5.2123e-02, -2.5209e-02,\n",
            "         8.5094e-03, -5.6987e-02, -2.2219e-02, -2.8807e-02, -1.7612e-02,\n",
            "         4.9885e-03, -1.4747e-03, -7.5809e-02,  1.5871e-02, -4.0564e-03,\n",
            "        -3.7250e-03, -4.6109e-02,  2.5242e-03,  4.4355e-03,  1.0314e-02,\n",
            "        -7.1663e-02,  9.1916e-03, -3.6697e-02, -3.8919e-02, -3.2340e-02,\n",
            "        -1.7095e-02, -2.2695e-02, -7.3756e-03, -3.2307e-03, -2.6671e-02,\n",
            "        -1.4188e-02, -5.8340e-03, -3.8018e-02, -3.0583e-02, -1.8098e-02,\n",
            "         2.1612e-02, -8.6132e-02, -2.3886e-02, -1.1493e-02, -8.3055e-03,\n",
            "        -1.7589e-03,  1.1987e-02, -4.2030e-02, -3.9615e-02,  4.4278e-03,\n",
            "        -1.7534e-02, -2.4694e-02, -2.1543e-02, -3.4609e-02,  2.3570e-02,\n",
            "         2.6285e-02, -1.3856e-02,  1.1432e-02, -2.7742e-02,  3.2082e-04,\n",
            "         4.6447e-03,  1.1198e-02, -1.5167e-02, -4.9473e-02, -4.2446e-02,\n",
            "         5.3062e-02, -6.3078e-02, -2.2603e-02, -1.0497e-02, -4.7284e-03,\n",
            "        -4.0333e-02,  4.8095e-03, -5.9835e-02,  5.7884e-03, -5.8095e-03,\n",
            "        -2.4915e-02, -1.1267e-02, -5.3225e-02,  1.0887e-02, -3.1268e-03,\n",
            "        -2.1667e-02, -5.2839e-02, -3.7480e-02, -2.9252e-02, -1.0288e-02,\n",
            "         9.7473e-03, -3.4331e-02, -2.6842e-02, -4.7752e-02, -4.4481e-03,\n",
            "        -5.0411e-02, -1.8064e-02, -2.4959e-02,  3.8707e-02, -2.3788e-02,\n",
            "        -3.0230e-02, -4.3937e-02, -3.9769e-02, -9.4580e-02,  4.1654e-02,\n",
            "        -3.5936e-02, -2.1148e-02,  1.7497e-02, -3.1961e-02, -2.3776e-02,\n",
            "        -3.7282e-02, -1.5092e-02,  9.8810e-03, -3.9213e-02, -3.9942e-02,\n",
            "        -5.6907e-02, -3.7442e-03, -9.5044e-02, -2.5293e-02, -2.5454e-02,\n",
            "        -4.7367e-02, -5.1332e-02, -2.0713e-03, -2.7323e-02,  5.7385e-03,\n",
            "        -1.9152e-02, -3.3860e-02, -4.8206e-02, -3.2334e-03, -5.0366e-02,\n",
            "        -3.5953e-02,  6.5205e-03, -2.6486e-02,  1.1088e-02, -2.8068e-02,\n",
            "        -7.4271e-02, -1.1911e-02,  1.2842e-02, -2.5225e-02, -3.1306e-02,\n",
            "        -1.9759e-02, -3.5803e-03,  2.0227e-03, -2.1660e-02,  1.1208e-02,\n",
            "        -2.4123e-02,  9.0310e-03, -5.1055e-02, -4.5396e-02, -2.6411e-02,\n",
            "         1.1292e-02,  1.4030e-02, -3.8358e-02, -3.2809e-02, -1.8572e-02,\n",
            "         4.8251e-02, -2.9928e-03, -7.2177e-02, -4.8035e-02,  7.6769e-03,\n",
            "        -6.5365e-02, -3.6413e-02, -1.1881e-02,  1.7021e-02, -1.1635e-02,\n",
            "        -6.0688e-02, -2.3924e-02, -4.9127e-02, -6.5620e-02, -4.3793e-02,\n",
            "        -4.4041e-02, -5.9561e-02, -2.9840e-02, -2.5970e-03, -4.9796e-02,\n",
            "        -1.1559e-02,  7.0239e-03, -3.5945e-02,  1.5993e-02, -4.1892e-02,\n",
            "        -6.8264e-02,  2.1650e-02, -4.1370e-02,  2.1973e-02, -1.5948e-02,\n",
            "        -1.0226e-01, -3.7496e-02,  1.7094e-02, -1.0982e-02,  1.5540e-02,\n",
            "        -5.0556e-02, -2.7001e-02, -2.0114e-02, -5.0169e-02, -2.9489e-02,\n",
            "        -3.9743e-02, -8.5380e-03, -1.8673e-02, -3.8129e-02, -2.1269e-02,\n",
            "        -2.5533e-02, -2.1255e-02, -1.3042e-02, -3.3605e-02, -1.3769e-02,\n",
            "        -2.9272e-02, -2.0493e-02,  6.1399e-03,  3.2051e-02, -2.2862e-02,\n",
            "        -4.3587e-02, -1.2302e-02, -6.0179e-03, -6.3411e-02, -1.3902e-04,\n",
            "         6.6006e-03, -6.3300e-02, -8.8990e-03, -4.0236e-03, -5.1070e-02,\n",
            "        -5.1127e-02, -3.9643e-02, -5.2284e-02, -4.6759e-02, -5.3112e-02,\n",
            "        -2.7392e-02, -2.9490e-02, -2.2758e-02, -9.5000e-03, -1.2496e-02,\n",
            "        -3.4707e-02, -1.4716e-02, -1.2888e-02, -1.2930e-03, -5.0056e-02,\n",
            "        -4.8036e-02, -3.2378e-02, -3.6429e-02, -3.8621e-02, -3.1510e-02,\n",
            "        -5.1300e-02,  1.4994e-02,  1.2208e-05, -1.4082e-02,  1.7620e-03,\n",
            "        -4.7165e-02, -3.7629e-02, -3.8766e-02,  9.4560e-03, -1.5576e-02,\n",
            "        -3.9815e-02,  1.1144e-02,  9.7832e-03, -1.2574e-02, -4.5413e-02,\n",
            "        -8.2680e-03, -2.0615e-02, -1.7477e-02, -4.7983e-02, -2.5950e-02,\n",
            "        -4.0306e-02])}\n",
            "Nonce: 2779\n",
            "Previous Block Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "BlockNo: 2\n",
            "Block Data: {'layer': 'fc2', 'weight': tensor([[ 0.0700,  0.0577, -0.0515,  ..., -0.0376, -0.0064, -0.0211],\n",
            "        [ 0.2691,  0.0488, -0.0146,  ...,  0.1431,  0.0142, -0.0360],\n",
            "        [ 0.1107,  0.0349,  0.0097,  ...,  0.0975, -0.0220,  0.0102],\n",
            "        ...,\n",
            "        [-0.0245,  0.0396, -0.0413,  ..., -0.0204, -0.0343,  0.0537],\n",
            "        [-0.0211,  0.0468, -0.0537,  ..., -0.1140,  0.0065,  0.0199],\n",
            "        [ 0.1608, -0.0083, -0.0337,  ...,  0.0963, -0.0206,  0.0148]]), 'bias': tensor([-0.0489,  0.1896,  0.1729, -0.1131, -0.1978,  0.0504, -0.0708, -0.1582,\n",
            "        -0.0030, -0.1288,  0.0108,  0.0125, -0.0415, -0.1031, -0.0630, -0.0025,\n",
            "        -0.1085, -0.0879, -0.0841,  0.3088,  0.1560,  0.0175, -0.2156, -0.1164,\n",
            "        -0.1923, -0.0915, -0.1100, -0.0354, -0.2318, -0.0061, -0.0592, -0.1969,\n",
            "        -0.0775, -0.1088, -0.1204, -0.1337, -0.2263,  0.1045, -0.1049, -0.1794,\n",
            "        -0.1485, -0.1131, -0.1346, -0.1471,  0.0449,  0.0613,  0.1513, -0.0190,\n",
            "        -0.0355, -0.1064,  0.2106, -0.1671,  0.0496,  0.0589, -0.1245, -0.1031,\n",
            "         0.0060, -0.0687, -0.1207, -0.0791,  0.0110, -0.1303,  0.0872, -0.0913,\n",
            "        -0.0502, -0.1575,  0.0946, -0.0620,  0.0189,  0.0400, -0.0242, -0.2191,\n",
            "        -0.1293, -0.1497,  0.1555,  0.2938, -0.0674, -0.3190, -0.0629, -0.1634,\n",
            "        -0.0147, -0.0193, -0.1928, -0.0061, -0.1173, -0.0514, -0.1626, -0.2278,\n",
            "        -0.0745, -0.0037, -0.0470, -0.0303, -0.1636, -0.1014,  0.1747, -0.0842,\n",
            "        -0.1578,  0.0232, -0.0125, -0.1983,  0.4642, -0.1431,  0.0178, -0.0420,\n",
            "        -0.0608, -0.0430, -0.0866,  0.0265, -0.0709,  0.0132,  0.0132, -0.1032,\n",
            "        -0.0352, -0.0149, -0.2466, -0.0685, -0.1978, -0.0966, -0.0275, -0.2409,\n",
            "         0.2949, -0.1386,  0.0520, -0.1878, -0.1932, -0.0528, -0.0524,  0.1045])}\n",
            "Nonce: 6875\n",
            "Previous Block Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "BlockNo: 3\n",
            "Block Data: {'layer': 'fc3', 'weight': tensor([[-0.0898,  0.0228, -0.0250,  ...,  0.0682, -0.1015, -0.0751],\n",
            "        [ 0.0142, -0.0617, -0.0568,  ..., -0.0338, -0.0558,  0.0405],\n",
            "        [-0.1508, -0.0901, -0.0380,  ...,  0.0528,  0.0925, -0.0676],\n",
            "        ...,\n",
            "        [ 0.0139,  0.0265, -0.1787,  ...,  0.0430,  0.0435, -0.0926],\n",
            "        [-0.0654, -0.0217, -0.1451,  ...,  0.0332, -0.0209, -0.1631],\n",
            "        [ 0.0609, -0.0105, -0.0566,  ...,  0.0403,  0.1513, -0.0428]]), 'bias': tensor([-0.1711, -0.1505, -0.1412,  0.0111, -0.0597,  0.1476, -0.0710, -0.0209,\n",
            "         0.1606,  0.2981,  0.1772, -0.2506, -0.0747, -0.2264, -0.2045, -0.3326,\n",
            "        -0.1356, -0.0518, -0.1744, -0.1427, -0.0377,  0.1834,  0.2696,  0.4100,\n",
            "        -0.2308, -0.2062, -0.0479,  0.0068, -0.1853,  0.1144, -0.1299,  0.1610,\n",
            "        -0.0101,  0.0754,  0.0926, -0.0319,  0.1107,  0.1191, -0.2281, -0.1523,\n",
            "        -0.2556, -0.1582, -0.0862, -0.0819, -0.0549,  0.1640, -0.1267, -0.0659,\n",
            "         0.0778, -0.0852, -0.0334,  0.2512, -0.0555,  0.2768,  0.0982,  0.3895,\n",
            "         0.1073, -0.1683,  0.0174, -0.0115,  0.2321, -0.3172, -0.1211,  0.0065])}\n",
            "Nonce: 4952\n",
            "Previous Block Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 000c7d81680ba960bc28b54930ce571c511bca021e1bef7efc4d487951494832\n",
            "BlockNo: 4\n",
            "Block Data: {'layer': 'fc4', 'weight': tensor([[-3.0591e-02,  3.4098e-02, -1.2472e-02, -8.9146e-03, -9.6389e-02,\n",
            "         -3.0413e-02, -2.2714e-02, -1.3556e-01,  6.6748e-02, -3.5200e-02,\n",
            "          1.7505e-01, -3.1370e-01,  1.0929e-01, -1.2965e-01, -2.6508e-01,\n",
            "         -4.6322e-03, -3.6083e-02,  1.6212e-01, -1.5626e-01,  9.0508e-03,\n",
            "          5.9090e-02, -1.5017e-01, -7.2761e-02,  1.0360e-01, -4.0878e-02,\n",
            "         -4.2697e-02, -2.6090e-01, -1.6544e-01, -2.2813e-01, -3.4041e-02,\n",
            "         -1.9108e-01, -2.0858e-01, -2.4329e-01,  2.5279e-02,  2.4480e-02,\n",
            "         -1.2921e-01,  6.6503e-03,  1.2826e-01, -1.9499e-01, -1.2286e-01,\n",
            "         -1.7484e-01,  2.2954e-02, -3.3802e-02,  1.6398e-01, -2.7393e-01,\n",
            "          4.4774e-02, -9.7249e-02, -2.8936e-02,  3.6314e-02,  1.2736e-01,\n",
            "         -8.5061e-02, -2.2160e-02, -4.3429e-03,  9.0347e-02, -4.5799e-02,\n",
            "         -2.9034e-01,  8.9424e-02, -1.3177e-01,  1.3366e-01, -1.0684e-01,\n",
            "          1.9650e-01,  2.1380e-02, -1.4263e-01, -1.2987e-01],\n",
            "        [ 8.0527e-02, -6.9936e-04, -1.8440e-01,  1.1717e-01, -3.7756e-01,\n",
            "         -6.7468e-02, -1.5667e-01, -2.0755e-01, -1.0310e-01,  7.1767e-02,\n",
            "         -2.0145e-01,  5.0998e-02,  8.0554e-02,  1.2831e-01, -2.6437e-01,\n",
            "         -3.8163e-01, -2.1519e-01, -1.3688e-01,  1.7053e-01, -9.2981e-03,\n",
            "         -4.9034e-01,  1.8303e-01, -6.3352e-02, -1.2537e-01, -9.2299e-02,\n",
            "         -4.9045e-02, -8.7175e-02,  1.0087e-01,  1.2594e-01, -5.7340e-02,\n",
            "          7.7662e-02,  1.2764e-01, -7.3948e-02,  9.9066e-02, -3.6424e-01,\n",
            "          1.6530e-01,  4.2991e-02, -3.7876e-04,  1.2653e-01, -9.9515e-02,\n",
            "         -1.6171e-01, -2.6207e-01,  1.2642e-01, -1.0301e-01, -3.8597e-02,\n",
            "         -2.5949e-01, -4.0102e-02, -1.6334e-01, -3.1535e-03,  9.5392e-02,\n",
            "          1.9991e-01, -2.1034e-01, -4.6928e-02,  2.9913e-03, -1.2064e-01,\n",
            "         -7.1262e-02, -2.4595e-01,  9.1223e-02,  6.6555e-03, -3.2185e-02,\n",
            "         -4.2523e-02, -1.1373e-01, -4.1103e-02, -2.2379e-02],\n",
            "        [-2.6639e-02, -4.9905e-02, -1.9280e-01, -8.7954e-02, -2.1338e-01,\n",
            "          1.7716e-01,  7.3641e-02, -8.6437e-02,  1.7046e-01, -1.2248e-01,\n",
            "         -7.8791e-02, -2.1608e-01, -4.4691e-02, -5.7541e-02,  6.5678e-02,\n",
            "         -1.5597e-01, -6.6167e-02,  1.4628e-01, -3.6590e-02, -7.6277e-02,\n",
            "          7.0731e-02,  1.2854e-01,  3.3084e-03, -2.1850e-01, -4.5549e-01,\n",
            "         -3.2332e-02,  1.7795e-02,  5.6002e-02, -1.4506e-01,  5.6319e-02,\n",
            "         -7.7656e-03, -2.1966e-01, -3.4202e-02, -5.8937e-02,  5.5518e-02,\n",
            "         -8.4144e-02, -8.6981e-02,  7.5757e-02,  1.1461e-01,  1.1005e-02,\n",
            "         -1.1787e-01, -1.6547e-01,  1.4386e-01, -7.4872e-02,  1.1260e-01,\n",
            "         -9.3629e-02,  4.8144e-02, -2.4308e-01,  1.8799e-02,  1.2744e-01,\n",
            "         -2.2816e-01,  4.7110e-02,  5.8897e-02,  9.6572e-02, -4.9287e-02,\n",
            "         -1.9062e-01, -3.4617e-03,  8.7256e-02,  1.7190e-01,  1.0175e-01,\n",
            "          9.3590e-02,  4.5341e-02,  2.4749e-02, -8.6945e-03],\n",
            "        [ 5.9198e-02, -1.4971e-01, -9.7188e-02, -1.2221e-01, -1.5573e-01,\n",
            "          1.5950e-01,  2.6218e-02,  8.2093e-03, -1.5829e-01, -2.3822e-01,\n",
            "          1.2463e-01, -1.1859e-01, -7.6052e-02,  1.9792e-02,  9.6583e-02,\n",
            "         -1.9772e-01, -6.2933e-02,  1.9615e-02,  1.4603e-01,  1.7161e-02,\n",
            "          3.7421e-02, -8.3916e-02,  9.4765e-02,  6.9403e-02, -1.7282e-01,\n",
            "         -4.0344e-03, -3.3327e-01, -8.5024e-02,  3.8942e-02, -5.6872e-02,\n",
            "         -9.1727e-02,  1.1133e-02, -1.5001e-01, -2.1141e-02, -1.0731e-01,\n",
            "         -9.3394e-02, -1.5909e-02,  7.1904e-02,  1.6437e-01, -5.1592e-02,\n",
            "         -2.1686e-01,  9.9757e-02, -2.0598e-02, -2.8799e-01,  1.4090e-01,\n",
            "         -1.1475e-02, -2.2539e-01, -6.3897e-02,  1.4890e-01,  6.4978e-02,\n",
            "         -5.7421e-02, -6.9976e-02,  7.4733e-02,  1.9975e-01, -1.3631e-01,\n",
            "          1.2692e-01,  2.9700e-02, -1.4718e-02,  5.1793e-03, -2.9027e-02,\n",
            "         -1.5312e-01,  2.0889e-02, -1.6939e-01, -4.4671e-02],\n",
            "        [ 1.3601e-02,  3.4387e-02, -1.3839e-01,  1.3523e-01, -2.2648e-01,\n",
            "         -1.1276e-01, -5.7338e-02, -6.2247e-02,  1.3348e-01, -5.2199e-03,\n",
            "          8.8016e-02, -5.2034e-02, -8.9455e-02,  9.6045e-03, -1.6267e-01,\n",
            "         -1.0997e-01, -1.5902e-01, -9.8831e-02,  3.3417e-02, -1.3838e-02,\n",
            "          6.3099e-02,  3.4767e-02, -1.9705e-01,  4.2852e-03, -2.5631e-01,\n",
            "          2.1715e-02,  1.4374e-02, -2.6716e-02,  3.3939e-03, -2.1987e-01,\n",
            "         -9.5788e-02,  1.6396e-01,  1.7821e-02,  1.0946e-02,  1.4986e-01,\n",
            "          9.2288e-02, -1.0144e-01, -1.8618e-02, -1.2044e-04, -1.2222e-01,\n",
            "         -5.6505e-02, -2.0812e-01, -2.6812e-02, -1.8149e-01,  1.0401e-01,\n",
            "         -5.4234e-02,  1.8465e-02,  9.2364e-02, -8.0603e-03,  4.0180e-02,\n",
            "         -3.0521e-02,  9.8548e-02, -2.2265e-01, -1.0132e-01,  1.0515e-01,\n",
            "          6.8693e-02, -1.8465e-01,  3.3156e-02, -5.4205e-02,  2.1594e-01,\n",
            "          8.0506e-02, -3.4505e-02, -1.5035e-01,  7.2493e-02],\n",
            "        [-1.5107e-02, -1.7190e-01, -2.5686e-02, -2.0609e-01,  2.4864e-02,\n",
            "          6.2660e-03, -1.1918e-01,  2.0434e-02, -9.6026e-02, -4.8028e-02,\n",
            "         -1.2094e-01, -1.0661e-01, -8.2729e-02,  4.1797e-02, -9.0162e-02,\n",
            "         -4.6264e-02,  1.8812e-01,  8.3817e-02,  1.1808e-01, -7.0366e-03,\n",
            "         -5.1755e-02, -4.5842e-02,  8.8472e-02,  7.0996e-03, -1.5127e-01,\n",
            "          5.1642e-03, -1.2410e-01, -8.3846e-02,  1.4713e-03, -2.3384e-02,\n",
            "          9.8134e-02,  2.3282e-02,  1.3950e-01, -1.6195e-01,  5.5275e-02,\n",
            "         -1.8728e-02,  1.5886e-01,  6.4935e-02, -1.1813e-01, -1.1567e-01,\n",
            "         -1.5507e-01,  1.0447e-01, -2.9090e-02,  4.4763e-03,  9.7352e-02,\n",
            "          1.1801e-01, -1.3295e-01,  4.4080e-02,  3.5852e-02, -9.3856e-02,\n",
            "         -2.5354e-03,  1.4111e-02,  8.6333e-04, -1.0574e-01, -7.3117e-02,\n",
            "          5.2291e-02, -7.2708e-03,  1.1661e-01, -7.5096e-02, -1.6445e-01,\n",
            "         -9.4599e-02, -1.4393e-01,  9.2639e-02, -1.0104e-01],\n",
            "        [-9.2999e-02,  3.2939e-02,  7.7569e-02,  1.2329e-01,  6.8271e-02,\n",
            "         -5.7074e-02, -9.7534e-02,  1.0594e-01, -1.8849e-01,  1.0334e-01,\n",
            "          1.4596e-01, -1.2874e-01,  1.8499e-02, -2.5217e-01, -3.7181e-01,\n",
            "         -8.4419e-02,  2.5565e-02, -8.0157e-02, -4.5190e-02,  4.6831e-03,\n",
            "          8.4701e-03, -2.4271e-02, -1.3587e-01,  1.8156e-01, -2.2558e-01,\n",
            "         -3.1215e-02, -3.8632e-01, -2.0433e-01, -2.0086e-01, -1.9205e-01,\n",
            "         -2.1231e-02, -1.4768e-01,  1.3509e-01,  7.8970e-02, -2.7377e-02,\n",
            "         -3.4304e-02,  1.5141e-01, -1.8696e-01, -9.3842e-02,  8.0565e-02,\n",
            "         -2.5625e-01, -5.1263e-02,  1.6240e-01, -1.0645e-01, -3.5994e-02,\n",
            "         -4.1154e-02,  1.9525e-02,  5.6315e-02,  1.8552e-01, -1.0291e-01,\n",
            "         -4.7442e-03,  2.8336e-02, -5.3458e-02, -2.9615e-01, -7.4837e-02,\n",
            "         -1.4042e-01, -4.0359e-01, -1.5856e-02, -2.2115e-01,  4.3629e-03,\n",
            "          7.6001e-02, -1.6410e-01, -5.1871e-02, -8.2789e-02],\n",
            "        [-1.8239e-03,  3.5877e-02, -4.2871e-02,  9.6933e-02, -6.5738e-02,\n",
            "         -9.5464e-02, -2.2584e-01, -2.1874e-02, -1.3169e-01, -1.0763e-01,\n",
            "         -2.9869e-01, -2.4803e-01, -1.0345e-01,  9.4159e-02,  1.2660e-01,\n",
            "          7.4724e-02, -1.7667e-01, -6.6567e-02,  1.2672e-01, -4.3086e-02,\n",
            "         -2.6427e-01,  5.4197e-02, -1.8951e-01, -1.4216e-01,  5.9037e-04,\n",
            "          3.8746e-02,  1.7537e-02,  1.9705e-01, -2.0985e-01, -9.0419e-02,\n",
            "         -1.9331e-01, -2.6807e-02, -7.3848e-02, -2.4975e-01,  3.3268e-02,\n",
            "         -8.3329e-02, -9.7251e-02,  2.0017e-02,  2.1676e-01, -1.8951e-01,\n",
            "         -3.0675e-02,  1.5512e-02,  2.8178e-02,  1.7990e-01, -3.5415e-02,\n",
            "         -1.8663e-01,  7.4498e-02,  3.1793e-02,  9.6635e-02,  1.7503e-02,\n",
            "         -6.1472e-02, -1.0570e-01,  4.2936e-02,  7.0300e-02, -8.3744e-02,\n",
            "          4.0475e-02,  1.2125e-01, -2.5267e-01,  1.1248e-01,  1.2021e-01,\n",
            "         -2.5559e-01, -1.4190e-01, -2.0342e-02,  1.4038e-01],\n",
            "        [-1.0926e-01,  3.6893e-03, -6.8264e-03, -3.8456e-02, -1.7640e-01,\n",
            "          4.7644e-02, -1.5130e-01, -2.5377e-02, -1.0458e-01,  1.5831e-01,\n",
            "         -1.4367e-01, -2.2789e-01,  5.8957e-03, -1.2621e-01, -1.1740e-01,\n",
            "         -1.6444e-01, -7.8225e-02, -1.3360e-01, -4.0109e-02,  3.9534e-02,\n",
            "         -4.8940e-03,  5.0944e-02,  1.0072e-01,  8.4909e-02, -2.0891e-02,\n",
            "          6.8689e-02, -1.2404e-01,  4.1738e-02, -1.9037e-01, -7.3585e-02,\n",
            "          1.0875e-01, -1.8278e-02, -4.9892e-02,  1.3167e-01, -7.3981e-02,\n",
            "          4.9814e-02,  9.5502e-02,  8.7666e-02, -1.1627e-03,  2.6633e-02,\n",
            "         -9.4880e-01, -1.6348e-01, -2.1192e-01, -4.6418e-02, -2.0423e-01,\n",
            "          9.1853e-02, -5.0921e-02, -1.3586e-01,  6.1529e-02, -1.6755e-01,\n",
            "          1.2155e-01,  5.5066e-02, -1.0048e-01,  1.8947e-01,  1.1460e-01,\n",
            "          1.1254e-01, -3.1178e-03, -3.0175e-03, -1.0087e-01, -8.0817e-03,\n",
            "          6.3748e-03, -2.3625e-02, -2.9221e-02, -9.4227e-02],\n",
            "        [-8.8030e-02,  4.4791e-02, -1.4275e-01,  1.2185e-01, -9.9455e-02,\n",
            "         -1.4812e-01, -2.3699e-01, -7.5080e-02,  1.3385e-01, -9.7905e-02,\n",
            "          4.7397e-02, -2.7456e-01, -1.4125e-01,  3.6336e-02, -1.3590e-01,\n",
            "         -8.5423e-02, -5.4281e-02,  1.8237e-01,  5.1911e-02, -1.2305e-01,\n",
            "         -1.6228e-01, -1.9630e-01, -1.1666e-01,  8.8990e-02, -1.9312e-01,\n",
            "          7.4491e-03,  1.0965e-01,  3.9147e-02,  4.1901e-02, -3.0227e-01,\n",
            "         -2.1925e-01,  1.9131e-01, -7.1291e-04, -4.1714e-02,  1.2805e-01,\n",
            "          6.8660e-02,  3.2590e-02,  2.1558e-02, -6.8939e-02, -2.2284e-01,\n",
            "         -1.5666e-01,  3.4934e-02, -1.5571e-01, -7.0096e-02,  2.9952e-02,\n",
            "          5.6766e-02,  2.0466e-02, -1.6385e-02, -2.1642e-01,  1.2343e-01,\n",
            "          4.2198e-02,  1.4266e-01, -8.6312e-02,  3.5222e-02, -2.8075e-02,\n",
            "          1.3317e-01,  1.9045e-01, -7.6952e-02,  1.2839e-02, -2.2569e-02,\n",
            "         -8.7107e-02, -3.2407e-04,  8.0567e-02,  1.5460e-01]]), 'bias': tensor([-0.0511, -0.2006, -0.0133, -0.0142,  0.1217, -0.0243, -0.1196, -0.1175,\n",
            "         0.5232,  0.0088])}\n",
            "Nonce: 3870\n",
            "Previous Block Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "--------------\n",
            "==========================END OF CHAIN============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Validation one time before tampering\n",
        "'''\n",
        "blockchain.validate_chain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4g7S4bYLRcR",
        "outputId": "bb45b123-51a9-407e-8ca4-0dafca6dcea6"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Hash of Previous Block: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Blockchain is correct!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attack"
      ],
      "metadata": {
        "id": "Gu-B8Te1Ihb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "No-damage Attack\n",
        "'''\n",
        "from copy import deepcopy\n",
        "targeted_block_id = 3 #layer 3 - fc3\n",
        "original_data = deepcopy(blockchain.chain[targeted_block_id].data)\n",
        "\n",
        "targeted_data = deepcopy(blockchain.chain[targeted_block_id].data)\n",
        "print('Original weight: ' )\n",
        "print(targeted_data['weight'])\n",
        "\n",
        "targeted_data['weight'][0][0] = 0\n",
        "print('\\nModified weight: ')\n",
        "print(targeted_data['weight'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8pYwfs6Kn1q",
        "outputId": "66126e05-3b5b-4dbb-f2f6-bf17759bb780"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weight: \n",
            "tensor([[-0.0898,  0.0228, -0.0250,  ...,  0.0682, -0.1015, -0.0751],\n",
            "        [ 0.0142, -0.0617, -0.0568,  ..., -0.0338, -0.0558,  0.0405],\n",
            "        [-0.1508, -0.0901, -0.0380,  ...,  0.0528,  0.0925, -0.0676],\n",
            "        ...,\n",
            "        [ 0.0139,  0.0265, -0.1787,  ...,  0.0430,  0.0435, -0.0926],\n",
            "        [-0.0654, -0.0217, -0.1451,  ...,  0.0332, -0.0209, -0.1631],\n",
            "        [ 0.0609, -0.0105, -0.0566,  ...,  0.0403,  0.1513, -0.0428]])\n",
            "\n",
            "Modified weight: \n",
            "tensor([[ 0.0000,  0.0228, -0.0250,  ...,  0.0682, -0.1015, -0.0751],\n",
            "        [ 0.0142, -0.0617, -0.0568,  ..., -0.0338, -0.0558,  0.0405],\n",
            "        [-0.1508, -0.0901, -0.0380,  ...,  0.0528,  0.0925, -0.0676],\n",
            "        ...,\n",
            "        [ 0.0139,  0.0265, -0.1787,  ...,  0.0430,  0.0435, -0.0926],\n",
            "        [-0.0654, -0.0217, -0.1451,  ...,  0.0332, -0.0209, -0.1631],\n",
            "        [ 0.0609, -0.0105, -0.0566,  ...,  0.0403,  0.1513, -0.0428]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Large Attack\n",
        "'''\n",
        "from copy import deepcopy\n",
        "targeted_block_id = 3\n",
        "original_data = deepcopy(blockchain.chain[targeted_block_id].data)\n",
        "\n",
        "targeted_data = deepcopy(blockchain.chain[targeted_block_id].data)\n",
        "print('Original weight: ' )\n",
        "print(targeted_data['weight'])\n",
        "\n",
        "targeted_data['weight'] = torch.rand(targeted_data['weight'].shape)\n",
        "print('\\nModified weight: ')\n",
        "print(targeted_data['weight'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1BQGKCBJe2n",
        "outputId": "3bfb4286-58fa-4c5f-dcd1-57a9eeab3ae1"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weight: \n",
            "tensor([[-0.0898,  0.0228, -0.0250,  ...,  0.0682, -0.1015, -0.0751],\n",
            "        [ 0.0142, -0.0617, -0.0568,  ..., -0.0338, -0.0558,  0.0405],\n",
            "        [-0.1508, -0.0901, -0.0380,  ...,  0.0528,  0.0925, -0.0676],\n",
            "        ...,\n",
            "        [ 0.0139,  0.0265, -0.1787,  ...,  0.0430,  0.0435, -0.0926],\n",
            "        [-0.0654, -0.0217, -0.1451,  ...,  0.0332, -0.0209, -0.1631],\n",
            "        [ 0.0609, -0.0105, -0.0566,  ...,  0.0403,  0.1513, -0.0428]])\n",
            "\n",
            "Modified weight: \n",
            "tensor([[0.3874, 0.3308, 0.9480,  ..., 0.5935, 0.3152, 0.7308],\n",
            "        [0.2112, 0.8330, 0.6243,  ..., 0.8735, 0.0884, 0.6197],\n",
            "        [0.6987, 0.5406, 0.6702,  ..., 0.9145, 0.0107, 0.0134],\n",
            "        ...,\n",
            "        [0.4107, 0.5313, 0.2373,  ..., 0.8513, 0.0068, 0.9602],\n",
            "        [0.7672, 0.6073, 0.4661,  ..., 0.7781, 0.3702, 0.9556],\n",
            "        [0.4003, 0.2200, 0.7532,  ..., 0.1002, 0.9396, 0.9293]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(blockchain.modify_block(targeted_block_id, targeted_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRNBvIhSINJ3",
        "outputId": "ead51755-7954-4eaa-91eb-a0275ef55d6f"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------Block Hash: 794c2363550d0409905ae9cb1872ca197883a6ca1ffe55ce86ea186a1e207f9e\n",
            "BlockNo: 3\n",
            "Block Data: {'layer': 'fc3', 'weight': tensor([[0.3874, 0.3308, 0.9480,  ..., 0.5935, 0.3152, 0.7308],\n",
            "        [0.2112, 0.8330, 0.6243,  ..., 0.8735, 0.0884, 0.6197],\n",
            "        [0.6987, 0.5406, 0.6702,  ..., 0.9145, 0.0107, 0.0134],\n",
            "        ...,\n",
            "        [0.4107, 0.5313, 0.2373,  ..., 0.8513, 0.0068, 0.9602],\n",
            "        [0.7672, 0.6073, 0.4661,  ..., 0.7781, 0.3702, 0.9556],\n",
            "        [0.4003, 0.2200, 0.7532,  ..., 0.1002, 0.9396, 0.9293]]), 'bias': tensor([-0.1711, -0.1505, -0.1412,  0.0111, -0.0597,  0.1476, -0.0710, -0.0209,\n",
            "         0.1606,  0.2981,  0.1772, -0.2506, -0.0747, -0.2264, -0.2045, -0.3326,\n",
            "        -0.1356, -0.0518, -0.1744, -0.1427, -0.0377,  0.1834,  0.2696,  0.4100,\n",
            "        -0.2308, -0.2062, -0.0479,  0.0068, -0.1853,  0.1144, -0.1299,  0.1610,\n",
            "        -0.0101,  0.0754,  0.0926, -0.0319,  0.1107,  0.1191, -0.2281, -0.1523,\n",
            "        -0.2556, -0.1582, -0.0862, -0.0819, -0.0549,  0.1640, -0.1267, -0.0659,\n",
            "         0.0778, -0.0852, -0.0334,  0.2512, -0.0555,  0.2768,  0.0982,  0.3895,\n",
            "         0.1073, -0.1683,  0.0174, -0.0115,  0.2321, -0.3172, -0.1211,  0.0065])}\n",
            "Nonce: 4952\n",
            "Previous Block Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "--------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Validate one time AFTER tampering\n",
        "'''\n",
        "blockchain.validate_chain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE8da1_a__wo",
        "outputId": "6dd1ee3b-a9e9-4f7d-f5d9-704587d06ea9"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Hash of Previous Block: 794c2363550d0409905ae9cb1872ca197883a6ca1ffe55ce86ea186a1e207f9e\n",
            "Block 3 is tampered!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(blockchain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cy-dX7LWKbg",
        "outputId": "e3eadb75-2ef5-4451-939a-7b237fd0b2b5"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------Block Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "BlockNo: 0\n",
            "Block Data: Genesis\n",
            "Nonce: 1176\n",
            "Previous Block Hash: 00000000000000000000000000000000\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "BlockNo: 1\n",
            "Block Data: {'layer': 'fc1', 'weight': tensor([[ 0.0329,  0.0086,  0.0243,  ...,  0.0497,  0.0563,  0.0528],\n",
            "        [-0.0129,  0.0104,  0.0365,  ...,  0.0194,  0.0207,  0.0246],\n",
            "        [ 0.0081,  0.0136, -0.0052,  ...,  0.0030,  0.0517,  0.0313],\n",
            "        ...,\n",
            "        [ 0.0393,  0.0300,  0.0377,  ...,  0.0255,  0.0073,  0.0581],\n",
            "        [ 0.0441,  0.0390,  0.0418,  ...,  0.0376, -0.0042,  0.0096],\n",
            "        [ 0.0226,  0.0080,  0.0011,  ..., -0.0116,  0.0461,  0.0215]]), 'bias': tensor([-5.0697e-02, -1.5882e-03, -4.5533e-02, -8.9822e-04, -7.9249e-02,\n",
            "         3.3151e-03, -3.6789e-02, -1.7230e-02, -5.2123e-02, -2.5209e-02,\n",
            "         8.5094e-03, -5.6987e-02, -2.2219e-02, -2.8807e-02, -1.7612e-02,\n",
            "         4.9885e-03, -1.4747e-03, -7.5809e-02,  1.5871e-02, -4.0564e-03,\n",
            "        -3.7250e-03, -4.6109e-02,  2.5242e-03,  4.4355e-03,  1.0314e-02,\n",
            "        -7.1663e-02,  9.1916e-03, -3.6697e-02, -3.8919e-02, -3.2340e-02,\n",
            "        -1.7095e-02, -2.2695e-02, -7.3756e-03, -3.2307e-03, -2.6671e-02,\n",
            "        -1.4188e-02, -5.8340e-03, -3.8018e-02, -3.0583e-02, -1.8098e-02,\n",
            "         2.1612e-02, -8.6132e-02, -2.3886e-02, -1.1493e-02, -8.3055e-03,\n",
            "        -1.7589e-03,  1.1987e-02, -4.2030e-02, -3.9615e-02,  4.4278e-03,\n",
            "        -1.7534e-02, -2.4694e-02, -2.1543e-02, -3.4609e-02,  2.3570e-02,\n",
            "         2.6285e-02, -1.3856e-02,  1.1432e-02, -2.7742e-02,  3.2082e-04,\n",
            "         4.6447e-03,  1.1198e-02, -1.5167e-02, -4.9473e-02, -4.2446e-02,\n",
            "         5.3062e-02, -6.3078e-02, -2.2603e-02, -1.0497e-02, -4.7284e-03,\n",
            "        -4.0333e-02,  4.8095e-03, -5.9835e-02,  5.7884e-03, -5.8095e-03,\n",
            "        -2.4915e-02, -1.1267e-02, -5.3225e-02,  1.0887e-02, -3.1268e-03,\n",
            "        -2.1667e-02, -5.2839e-02, -3.7480e-02, -2.9252e-02, -1.0288e-02,\n",
            "         9.7473e-03, -3.4331e-02, -2.6842e-02, -4.7752e-02, -4.4481e-03,\n",
            "        -5.0411e-02, -1.8064e-02, -2.4959e-02,  3.8707e-02, -2.3788e-02,\n",
            "        -3.0230e-02, -4.3937e-02, -3.9769e-02, -9.4580e-02,  4.1654e-02,\n",
            "        -3.5936e-02, -2.1148e-02,  1.7497e-02, -3.1961e-02, -2.3776e-02,\n",
            "        -3.7282e-02, -1.5092e-02,  9.8810e-03, -3.9213e-02, -3.9942e-02,\n",
            "        -5.6907e-02, -3.7442e-03, -9.5044e-02, -2.5293e-02, -2.5454e-02,\n",
            "        -4.7367e-02, -5.1332e-02, -2.0713e-03, -2.7323e-02,  5.7385e-03,\n",
            "        -1.9152e-02, -3.3860e-02, -4.8206e-02, -3.2334e-03, -5.0366e-02,\n",
            "        -3.5953e-02,  6.5205e-03, -2.6486e-02,  1.1088e-02, -2.8068e-02,\n",
            "        -7.4271e-02, -1.1911e-02,  1.2842e-02, -2.5225e-02, -3.1306e-02,\n",
            "        -1.9759e-02, -3.5803e-03,  2.0227e-03, -2.1660e-02,  1.1208e-02,\n",
            "        -2.4123e-02,  9.0310e-03, -5.1055e-02, -4.5396e-02, -2.6411e-02,\n",
            "         1.1292e-02,  1.4030e-02, -3.8358e-02, -3.2809e-02, -1.8572e-02,\n",
            "         4.8251e-02, -2.9928e-03, -7.2177e-02, -4.8035e-02,  7.6769e-03,\n",
            "        -6.5365e-02, -3.6413e-02, -1.1881e-02,  1.7021e-02, -1.1635e-02,\n",
            "        -6.0688e-02, -2.3924e-02, -4.9127e-02, -6.5620e-02, -4.3793e-02,\n",
            "        -4.4041e-02, -5.9561e-02, -2.9840e-02, -2.5970e-03, -4.9796e-02,\n",
            "        -1.1559e-02,  7.0239e-03, -3.5945e-02,  1.5993e-02, -4.1892e-02,\n",
            "        -6.8264e-02,  2.1650e-02, -4.1370e-02,  2.1973e-02, -1.5948e-02,\n",
            "        -1.0226e-01, -3.7496e-02,  1.7094e-02, -1.0982e-02,  1.5540e-02,\n",
            "        -5.0556e-02, -2.7001e-02, -2.0114e-02, -5.0169e-02, -2.9489e-02,\n",
            "        -3.9743e-02, -8.5380e-03, -1.8673e-02, -3.8129e-02, -2.1269e-02,\n",
            "        -2.5533e-02, -2.1255e-02, -1.3042e-02, -3.3605e-02, -1.3769e-02,\n",
            "        -2.9272e-02, -2.0493e-02,  6.1399e-03,  3.2051e-02, -2.2862e-02,\n",
            "        -4.3587e-02, -1.2302e-02, -6.0179e-03, -6.3411e-02, -1.3902e-04,\n",
            "         6.6006e-03, -6.3300e-02, -8.8990e-03, -4.0236e-03, -5.1070e-02,\n",
            "        -5.1127e-02, -3.9643e-02, -5.2284e-02, -4.6759e-02, -5.3112e-02,\n",
            "        -2.7392e-02, -2.9490e-02, -2.2758e-02, -9.5000e-03, -1.2496e-02,\n",
            "        -3.4707e-02, -1.4716e-02, -1.2888e-02, -1.2930e-03, -5.0056e-02,\n",
            "        -4.8036e-02, -3.2378e-02, -3.6429e-02, -3.8621e-02, -3.1510e-02,\n",
            "        -5.1300e-02,  1.4994e-02,  1.2208e-05, -1.4082e-02,  1.7620e-03,\n",
            "        -4.7165e-02, -3.7629e-02, -3.8766e-02,  9.4560e-03, -1.5576e-02,\n",
            "        -3.9815e-02,  1.1144e-02,  9.7832e-03, -1.2574e-02, -4.5413e-02,\n",
            "        -8.2680e-03, -2.0615e-02, -1.7477e-02, -4.7983e-02, -2.5950e-02,\n",
            "        -4.0306e-02])}\n",
            "Nonce: 2779\n",
            "Previous Block Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "BlockNo: 2\n",
            "Block Data: {'layer': 'fc2', 'weight': tensor([[ 0.0700,  0.0577, -0.0515,  ..., -0.0376, -0.0064, -0.0211],\n",
            "        [ 0.2691,  0.0488, -0.0146,  ...,  0.1431,  0.0142, -0.0360],\n",
            "        [ 0.1107,  0.0349,  0.0097,  ...,  0.0975, -0.0220,  0.0102],\n",
            "        ...,\n",
            "        [-0.0245,  0.0396, -0.0413,  ..., -0.0204, -0.0343,  0.0537],\n",
            "        [-0.0211,  0.0468, -0.0537,  ..., -0.1140,  0.0065,  0.0199],\n",
            "        [ 0.1608, -0.0083, -0.0337,  ...,  0.0963, -0.0206,  0.0148]]), 'bias': tensor([-0.0489,  0.1896,  0.1729, -0.1131, -0.1978,  0.0504, -0.0708, -0.1582,\n",
            "        -0.0030, -0.1288,  0.0108,  0.0125, -0.0415, -0.1031, -0.0630, -0.0025,\n",
            "        -0.1085, -0.0879, -0.0841,  0.3088,  0.1560,  0.0175, -0.2156, -0.1164,\n",
            "        -0.1923, -0.0915, -0.1100, -0.0354, -0.2318, -0.0061, -0.0592, -0.1969,\n",
            "        -0.0775, -0.1088, -0.1204, -0.1337, -0.2263,  0.1045, -0.1049, -0.1794,\n",
            "        -0.1485, -0.1131, -0.1346, -0.1471,  0.0449,  0.0613,  0.1513, -0.0190,\n",
            "        -0.0355, -0.1064,  0.2106, -0.1671,  0.0496,  0.0589, -0.1245, -0.1031,\n",
            "         0.0060, -0.0687, -0.1207, -0.0791,  0.0110, -0.1303,  0.0872, -0.0913,\n",
            "        -0.0502, -0.1575,  0.0946, -0.0620,  0.0189,  0.0400, -0.0242, -0.2191,\n",
            "        -0.1293, -0.1497,  0.1555,  0.2938, -0.0674, -0.3190, -0.0629, -0.1634,\n",
            "        -0.0147, -0.0193, -0.1928, -0.0061, -0.1173, -0.0514, -0.1626, -0.2278,\n",
            "        -0.0745, -0.0037, -0.0470, -0.0303, -0.1636, -0.1014,  0.1747, -0.0842,\n",
            "        -0.1578,  0.0232, -0.0125, -0.1983,  0.4642, -0.1431,  0.0178, -0.0420,\n",
            "        -0.0608, -0.0430, -0.0866,  0.0265, -0.0709,  0.0132,  0.0132, -0.1032,\n",
            "        -0.0352, -0.0149, -0.2466, -0.0685, -0.1978, -0.0966, -0.0275, -0.2409,\n",
            "         0.2949, -0.1386,  0.0520, -0.1878, -0.1932, -0.0528, -0.0524,  0.1045])}\n",
            "Nonce: 6875\n",
            "Previous Block Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 794c2363550d0409905ae9cb1872ca197883a6ca1ffe55ce86ea186a1e207f9e\n",
            "BlockNo: 3\n",
            "Block Data: {'layer': 'fc3', 'weight': tensor([[0.3874, 0.3308, 0.9480,  ..., 0.5935, 0.3152, 0.7308],\n",
            "        [0.2112, 0.8330, 0.6243,  ..., 0.8735, 0.0884, 0.6197],\n",
            "        [0.6987, 0.5406, 0.6702,  ..., 0.9145, 0.0107, 0.0134],\n",
            "        ...,\n",
            "        [0.4107, 0.5313, 0.2373,  ..., 0.8513, 0.0068, 0.9602],\n",
            "        [0.7672, 0.6073, 0.4661,  ..., 0.7781, 0.3702, 0.9556],\n",
            "        [0.4003, 0.2200, 0.7532,  ..., 0.1002, 0.9396, 0.9293]]), 'bias': tensor([-0.1711, -0.1505, -0.1412,  0.0111, -0.0597,  0.1476, -0.0710, -0.0209,\n",
            "         0.1606,  0.2981,  0.1772, -0.2506, -0.0747, -0.2264, -0.2045, -0.3326,\n",
            "        -0.1356, -0.0518, -0.1744, -0.1427, -0.0377,  0.1834,  0.2696,  0.4100,\n",
            "        -0.2308, -0.2062, -0.0479,  0.0068, -0.1853,  0.1144, -0.1299,  0.1610,\n",
            "        -0.0101,  0.0754,  0.0926, -0.0319,  0.1107,  0.1191, -0.2281, -0.1523,\n",
            "        -0.2556, -0.1582, -0.0862, -0.0819, -0.0549,  0.1640, -0.1267, -0.0659,\n",
            "         0.0778, -0.0852, -0.0334,  0.2512, -0.0555,  0.2768,  0.0982,  0.3895,\n",
            "         0.1073, -0.1683,  0.0174, -0.0115,  0.2321, -0.3172, -0.1211,  0.0065])}\n",
            "Nonce: 4952\n",
            "Previous Block Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 000c7d81680ba960bc28b54930ce571c511bca021e1bef7efc4d487951494832\n",
            "BlockNo: 4\n",
            "Block Data: {'layer': 'fc4', 'weight': tensor([[-3.0591e-02,  3.4098e-02, -1.2472e-02, -8.9146e-03, -9.6389e-02,\n",
            "         -3.0413e-02, -2.2714e-02, -1.3556e-01,  6.6748e-02, -3.5200e-02,\n",
            "          1.7505e-01, -3.1370e-01,  1.0929e-01, -1.2965e-01, -2.6508e-01,\n",
            "         -4.6322e-03, -3.6083e-02,  1.6212e-01, -1.5626e-01,  9.0508e-03,\n",
            "          5.9090e-02, -1.5017e-01, -7.2761e-02,  1.0360e-01, -4.0878e-02,\n",
            "         -4.2697e-02, -2.6090e-01, -1.6544e-01, -2.2813e-01, -3.4041e-02,\n",
            "         -1.9108e-01, -2.0858e-01, -2.4329e-01,  2.5279e-02,  2.4480e-02,\n",
            "         -1.2921e-01,  6.6503e-03,  1.2826e-01, -1.9499e-01, -1.2286e-01,\n",
            "         -1.7484e-01,  2.2954e-02, -3.3802e-02,  1.6398e-01, -2.7393e-01,\n",
            "          4.4774e-02, -9.7249e-02, -2.8936e-02,  3.6314e-02,  1.2736e-01,\n",
            "         -8.5061e-02, -2.2160e-02, -4.3429e-03,  9.0347e-02, -4.5799e-02,\n",
            "         -2.9034e-01,  8.9424e-02, -1.3177e-01,  1.3366e-01, -1.0684e-01,\n",
            "          1.9650e-01,  2.1380e-02, -1.4263e-01, -1.2987e-01],\n",
            "        [ 8.0527e-02, -6.9936e-04, -1.8440e-01,  1.1717e-01, -3.7756e-01,\n",
            "         -6.7468e-02, -1.5667e-01, -2.0755e-01, -1.0310e-01,  7.1767e-02,\n",
            "         -2.0145e-01,  5.0998e-02,  8.0554e-02,  1.2831e-01, -2.6437e-01,\n",
            "         -3.8163e-01, -2.1519e-01, -1.3688e-01,  1.7053e-01, -9.2981e-03,\n",
            "         -4.9034e-01,  1.8303e-01, -6.3352e-02, -1.2537e-01, -9.2299e-02,\n",
            "         -4.9045e-02, -8.7175e-02,  1.0087e-01,  1.2594e-01, -5.7340e-02,\n",
            "          7.7662e-02,  1.2764e-01, -7.3948e-02,  9.9066e-02, -3.6424e-01,\n",
            "          1.6530e-01,  4.2991e-02, -3.7876e-04,  1.2653e-01, -9.9515e-02,\n",
            "         -1.6171e-01, -2.6207e-01,  1.2642e-01, -1.0301e-01, -3.8597e-02,\n",
            "         -2.5949e-01, -4.0102e-02, -1.6334e-01, -3.1535e-03,  9.5392e-02,\n",
            "          1.9991e-01, -2.1034e-01, -4.6928e-02,  2.9913e-03, -1.2064e-01,\n",
            "         -7.1262e-02, -2.4595e-01,  9.1223e-02,  6.6555e-03, -3.2185e-02,\n",
            "         -4.2523e-02, -1.1373e-01, -4.1103e-02, -2.2379e-02],\n",
            "        [-2.6639e-02, -4.9905e-02, -1.9280e-01, -8.7954e-02, -2.1338e-01,\n",
            "          1.7716e-01,  7.3641e-02, -8.6437e-02,  1.7046e-01, -1.2248e-01,\n",
            "         -7.8791e-02, -2.1608e-01, -4.4691e-02, -5.7541e-02,  6.5678e-02,\n",
            "         -1.5597e-01, -6.6167e-02,  1.4628e-01, -3.6590e-02, -7.6277e-02,\n",
            "          7.0731e-02,  1.2854e-01,  3.3084e-03, -2.1850e-01, -4.5549e-01,\n",
            "         -3.2332e-02,  1.7795e-02,  5.6002e-02, -1.4506e-01,  5.6319e-02,\n",
            "         -7.7656e-03, -2.1966e-01, -3.4202e-02, -5.8937e-02,  5.5518e-02,\n",
            "         -8.4144e-02, -8.6981e-02,  7.5757e-02,  1.1461e-01,  1.1005e-02,\n",
            "         -1.1787e-01, -1.6547e-01,  1.4386e-01, -7.4872e-02,  1.1260e-01,\n",
            "         -9.3629e-02,  4.8144e-02, -2.4308e-01,  1.8799e-02,  1.2744e-01,\n",
            "         -2.2816e-01,  4.7110e-02,  5.8897e-02,  9.6572e-02, -4.9287e-02,\n",
            "         -1.9062e-01, -3.4617e-03,  8.7256e-02,  1.7190e-01,  1.0175e-01,\n",
            "          9.3590e-02,  4.5341e-02,  2.4749e-02, -8.6945e-03],\n",
            "        [ 5.9198e-02, -1.4971e-01, -9.7188e-02, -1.2221e-01, -1.5573e-01,\n",
            "          1.5950e-01,  2.6218e-02,  8.2093e-03, -1.5829e-01, -2.3822e-01,\n",
            "          1.2463e-01, -1.1859e-01, -7.6052e-02,  1.9792e-02,  9.6583e-02,\n",
            "         -1.9772e-01, -6.2933e-02,  1.9615e-02,  1.4603e-01,  1.7161e-02,\n",
            "          3.7421e-02, -8.3916e-02,  9.4765e-02,  6.9403e-02, -1.7282e-01,\n",
            "         -4.0344e-03, -3.3327e-01, -8.5024e-02,  3.8942e-02, -5.6872e-02,\n",
            "         -9.1727e-02,  1.1133e-02, -1.5001e-01, -2.1141e-02, -1.0731e-01,\n",
            "         -9.3394e-02, -1.5909e-02,  7.1904e-02,  1.6437e-01, -5.1592e-02,\n",
            "         -2.1686e-01,  9.9757e-02, -2.0598e-02, -2.8799e-01,  1.4090e-01,\n",
            "         -1.1475e-02, -2.2539e-01, -6.3897e-02,  1.4890e-01,  6.4978e-02,\n",
            "         -5.7421e-02, -6.9976e-02,  7.4733e-02,  1.9975e-01, -1.3631e-01,\n",
            "          1.2692e-01,  2.9700e-02, -1.4718e-02,  5.1793e-03, -2.9027e-02,\n",
            "         -1.5312e-01,  2.0889e-02, -1.6939e-01, -4.4671e-02],\n",
            "        [ 1.3601e-02,  3.4387e-02, -1.3839e-01,  1.3523e-01, -2.2648e-01,\n",
            "         -1.1276e-01, -5.7338e-02, -6.2247e-02,  1.3348e-01, -5.2199e-03,\n",
            "          8.8016e-02, -5.2034e-02, -8.9455e-02,  9.6045e-03, -1.6267e-01,\n",
            "         -1.0997e-01, -1.5902e-01, -9.8831e-02,  3.3417e-02, -1.3838e-02,\n",
            "          6.3099e-02,  3.4767e-02, -1.9705e-01,  4.2852e-03, -2.5631e-01,\n",
            "          2.1715e-02,  1.4374e-02, -2.6716e-02,  3.3939e-03, -2.1987e-01,\n",
            "         -9.5788e-02,  1.6396e-01,  1.7821e-02,  1.0946e-02,  1.4986e-01,\n",
            "          9.2288e-02, -1.0144e-01, -1.8618e-02, -1.2044e-04, -1.2222e-01,\n",
            "         -5.6505e-02, -2.0812e-01, -2.6812e-02, -1.8149e-01,  1.0401e-01,\n",
            "         -5.4234e-02,  1.8465e-02,  9.2364e-02, -8.0603e-03,  4.0180e-02,\n",
            "         -3.0521e-02,  9.8548e-02, -2.2265e-01, -1.0132e-01,  1.0515e-01,\n",
            "          6.8693e-02, -1.8465e-01,  3.3156e-02, -5.4205e-02,  2.1594e-01,\n",
            "          8.0506e-02, -3.4505e-02, -1.5035e-01,  7.2493e-02],\n",
            "        [-1.5107e-02, -1.7190e-01, -2.5686e-02, -2.0609e-01,  2.4864e-02,\n",
            "          6.2660e-03, -1.1918e-01,  2.0434e-02, -9.6026e-02, -4.8028e-02,\n",
            "         -1.2094e-01, -1.0661e-01, -8.2729e-02,  4.1797e-02, -9.0162e-02,\n",
            "         -4.6264e-02,  1.8812e-01,  8.3817e-02,  1.1808e-01, -7.0366e-03,\n",
            "         -5.1755e-02, -4.5842e-02,  8.8472e-02,  7.0996e-03, -1.5127e-01,\n",
            "          5.1642e-03, -1.2410e-01, -8.3846e-02,  1.4713e-03, -2.3384e-02,\n",
            "          9.8134e-02,  2.3282e-02,  1.3950e-01, -1.6195e-01,  5.5275e-02,\n",
            "         -1.8728e-02,  1.5886e-01,  6.4935e-02, -1.1813e-01, -1.1567e-01,\n",
            "         -1.5507e-01,  1.0447e-01, -2.9090e-02,  4.4763e-03,  9.7352e-02,\n",
            "          1.1801e-01, -1.3295e-01,  4.4080e-02,  3.5852e-02, -9.3856e-02,\n",
            "         -2.5354e-03,  1.4111e-02,  8.6333e-04, -1.0574e-01, -7.3117e-02,\n",
            "          5.2291e-02, -7.2708e-03,  1.1661e-01, -7.5096e-02, -1.6445e-01,\n",
            "         -9.4599e-02, -1.4393e-01,  9.2639e-02, -1.0104e-01],\n",
            "        [-9.2999e-02,  3.2939e-02,  7.7569e-02,  1.2329e-01,  6.8271e-02,\n",
            "         -5.7074e-02, -9.7534e-02,  1.0594e-01, -1.8849e-01,  1.0334e-01,\n",
            "          1.4596e-01, -1.2874e-01,  1.8499e-02, -2.5217e-01, -3.7181e-01,\n",
            "         -8.4419e-02,  2.5565e-02, -8.0157e-02, -4.5190e-02,  4.6831e-03,\n",
            "          8.4701e-03, -2.4271e-02, -1.3587e-01,  1.8156e-01, -2.2558e-01,\n",
            "         -3.1215e-02, -3.8632e-01, -2.0433e-01, -2.0086e-01, -1.9205e-01,\n",
            "         -2.1231e-02, -1.4768e-01,  1.3509e-01,  7.8970e-02, -2.7377e-02,\n",
            "         -3.4304e-02,  1.5141e-01, -1.8696e-01, -9.3842e-02,  8.0565e-02,\n",
            "         -2.5625e-01, -5.1263e-02,  1.6240e-01, -1.0645e-01, -3.5994e-02,\n",
            "         -4.1154e-02,  1.9525e-02,  5.6315e-02,  1.8552e-01, -1.0291e-01,\n",
            "         -4.7442e-03,  2.8336e-02, -5.3458e-02, -2.9615e-01, -7.4837e-02,\n",
            "         -1.4042e-01, -4.0359e-01, -1.5856e-02, -2.2115e-01,  4.3629e-03,\n",
            "          7.6001e-02, -1.6410e-01, -5.1871e-02, -8.2789e-02],\n",
            "        [-1.8239e-03,  3.5877e-02, -4.2871e-02,  9.6933e-02, -6.5738e-02,\n",
            "         -9.5464e-02, -2.2584e-01, -2.1874e-02, -1.3169e-01, -1.0763e-01,\n",
            "         -2.9869e-01, -2.4803e-01, -1.0345e-01,  9.4159e-02,  1.2660e-01,\n",
            "          7.4724e-02, -1.7667e-01, -6.6567e-02,  1.2672e-01, -4.3086e-02,\n",
            "         -2.6427e-01,  5.4197e-02, -1.8951e-01, -1.4216e-01,  5.9037e-04,\n",
            "          3.8746e-02,  1.7537e-02,  1.9705e-01, -2.0985e-01, -9.0419e-02,\n",
            "         -1.9331e-01, -2.6807e-02, -7.3848e-02, -2.4975e-01,  3.3268e-02,\n",
            "         -8.3329e-02, -9.7251e-02,  2.0017e-02,  2.1676e-01, -1.8951e-01,\n",
            "         -3.0675e-02,  1.5512e-02,  2.8178e-02,  1.7990e-01, -3.5415e-02,\n",
            "         -1.8663e-01,  7.4498e-02,  3.1793e-02,  9.6635e-02,  1.7503e-02,\n",
            "         -6.1472e-02, -1.0570e-01,  4.2936e-02,  7.0300e-02, -8.3744e-02,\n",
            "          4.0475e-02,  1.2125e-01, -2.5267e-01,  1.1248e-01,  1.2021e-01,\n",
            "         -2.5559e-01, -1.4190e-01, -2.0342e-02,  1.4038e-01],\n",
            "        [-1.0926e-01,  3.6893e-03, -6.8264e-03, -3.8456e-02, -1.7640e-01,\n",
            "          4.7644e-02, -1.5130e-01, -2.5377e-02, -1.0458e-01,  1.5831e-01,\n",
            "         -1.4367e-01, -2.2789e-01,  5.8957e-03, -1.2621e-01, -1.1740e-01,\n",
            "         -1.6444e-01, -7.8225e-02, -1.3360e-01, -4.0109e-02,  3.9534e-02,\n",
            "         -4.8940e-03,  5.0944e-02,  1.0072e-01,  8.4909e-02, -2.0891e-02,\n",
            "          6.8689e-02, -1.2404e-01,  4.1738e-02, -1.9037e-01, -7.3585e-02,\n",
            "          1.0875e-01, -1.8278e-02, -4.9892e-02,  1.3167e-01, -7.3981e-02,\n",
            "          4.9814e-02,  9.5502e-02,  8.7666e-02, -1.1627e-03,  2.6633e-02,\n",
            "         -9.4880e-01, -1.6348e-01, -2.1192e-01, -4.6418e-02, -2.0423e-01,\n",
            "          9.1853e-02, -5.0921e-02, -1.3586e-01,  6.1529e-02, -1.6755e-01,\n",
            "          1.2155e-01,  5.5066e-02, -1.0048e-01,  1.8947e-01,  1.1460e-01,\n",
            "          1.1254e-01, -3.1178e-03, -3.0175e-03, -1.0087e-01, -8.0817e-03,\n",
            "          6.3748e-03, -2.3625e-02, -2.9221e-02, -9.4227e-02],\n",
            "        [-8.8030e-02,  4.4791e-02, -1.4275e-01,  1.2185e-01, -9.9455e-02,\n",
            "         -1.4812e-01, -2.3699e-01, -7.5080e-02,  1.3385e-01, -9.7905e-02,\n",
            "          4.7397e-02, -2.7456e-01, -1.4125e-01,  3.6336e-02, -1.3590e-01,\n",
            "         -8.5423e-02, -5.4281e-02,  1.8237e-01,  5.1911e-02, -1.2305e-01,\n",
            "         -1.6228e-01, -1.9630e-01, -1.1666e-01,  8.8990e-02, -1.9312e-01,\n",
            "          7.4491e-03,  1.0965e-01,  3.9147e-02,  4.1901e-02, -3.0227e-01,\n",
            "         -2.1925e-01,  1.9131e-01, -7.1291e-04, -4.1714e-02,  1.2805e-01,\n",
            "          6.8660e-02,  3.2590e-02,  2.1558e-02, -6.8939e-02, -2.2284e-01,\n",
            "         -1.5666e-01,  3.4934e-02, -1.5571e-01, -7.0096e-02,  2.9952e-02,\n",
            "          5.6766e-02,  2.0466e-02, -1.6385e-02, -2.1642e-01,  1.2343e-01,\n",
            "          4.2198e-02,  1.4266e-01, -8.6312e-02,  3.5222e-02, -2.8075e-02,\n",
            "          1.3317e-01,  1.9045e-01, -7.6952e-02,  1.2839e-02, -2.2569e-02,\n",
            "         -8.7107e-02, -3.2407e-04,  8.0567e-02,  1.5460e-01]]), 'bias': tensor([-0.0511, -0.2006, -0.0133, -0.0142,  0.1217, -0.0243, -0.1196, -0.1175,\n",
            "         0.5232,  0.0088])}\n",
            "Nonce: 3870\n",
            "Previous Block Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "--------------\n",
            "==========================END OF CHAIN============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remine (Student's exercise)\n",
        "So, block 3 was detected as invalid thanks to the `validate()` method. However, the attacker could simply re-mine the network from Block 3 to pass all the difficulty tests, which therefore will create a corrupted but totally valid blockchain. "
      ],
      "metadata": {
        "id": "oKDL6jA2aBBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's remine the entire blockchain to the acceptable state."
      ],
      "metadata": {
        "id": "27X2cAHlFVia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_blockchain = Blockchain()\n",
        "'''\n",
        "first, copy the correct blocks (healthy blocks before the corrupted one) from the corrupted blockchain\n",
        "'''\n",
        "\n",
        "newBlock = Block(blockchain.chain[1].data)\n",
        "new_blockchain.mine(newBlock)\n",
        "newBlock = Block(blockchain.chain[2].data)\n",
        "new_blockchain.mine(newBlock)\n",
        "print(new_blockchain)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cl7lGxVFUph",
        "outputId": "175bcab6-359e-4853-fbb9-1780e5b42c72"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block 0 - Qualified: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Block 1 - Qualified: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Block 2 - Qualified: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "--------------Block Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "BlockNo: 0\n",
            "Block Data: Genesis\n",
            "Nonce: 1176\n",
            "Previous Block Hash: 00000000000000000000000000000000\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "BlockNo: 1\n",
            "Block Data: {'layer': 'fc1', 'weight': tensor([[ 0.0329,  0.0086,  0.0243,  ...,  0.0497,  0.0563,  0.0528],\n",
            "        [-0.0129,  0.0104,  0.0365,  ...,  0.0194,  0.0207,  0.0246],\n",
            "        [ 0.0081,  0.0136, -0.0052,  ...,  0.0030,  0.0517,  0.0313],\n",
            "        ...,\n",
            "        [ 0.0393,  0.0300,  0.0377,  ...,  0.0255,  0.0073,  0.0581],\n",
            "        [ 0.0441,  0.0390,  0.0418,  ...,  0.0376, -0.0042,  0.0096],\n",
            "        [ 0.0226,  0.0080,  0.0011,  ..., -0.0116,  0.0461,  0.0215]]), 'bias': tensor([-5.0697e-02, -1.5882e-03, -4.5533e-02, -8.9822e-04, -7.9249e-02,\n",
            "         3.3151e-03, -3.6789e-02, -1.7230e-02, -5.2123e-02, -2.5209e-02,\n",
            "         8.5094e-03, -5.6987e-02, -2.2219e-02, -2.8807e-02, -1.7612e-02,\n",
            "         4.9885e-03, -1.4747e-03, -7.5809e-02,  1.5871e-02, -4.0564e-03,\n",
            "        -3.7250e-03, -4.6109e-02,  2.5242e-03,  4.4355e-03,  1.0314e-02,\n",
            "        -7.1663e-02,  9.1916e-03, -3.6697e-02, -3.8919e-02, -3.2340e-02,\n",
            "        -1.7095e-02, -2.2695e-02, -7.3756e-03, -3.2307e-03, -2.6671e-02,\n",
            "        -1.4188e-02, -5.8340e-03, -3.8018e-02, -3.0583e-02, -1.8098e-02,\n",
            "         2.1612e-02, -8.6132e-02, -2.3886e-02, -1.1493e-02, -8.3055e-03,\n",
            "        -1.7589e-03,  1.1987e-02, -4.2030e-02, -3.9615e-02,  4.4278e-03,\n",
            "        -1.7534e-02, -2.4694e-02, -2.1543e-02, -3.4609e-02,  2.3570e-02,\n",
            "         2.6285e-02, -1.3856e-02,  1.1432e-02, -2.7742e-02,  3.2082e-04,\n",
            "         4.6447e-03,  1.1198e-02, -1.5167e-02, -4.9473e-02, -4.2446e-02,\n",
            "         5.3062e-02, -6.3078e-02, -2.2603e-02, -1.0497e-02, -4.7284e-03,\n",
            "        -4.0333e-02,  4.8095e-03, -5.9835e-02,  5.7884e-03, -5.8095e-03,\n",
            "        -2.4915e-02, -1.1267e-02, -5.3225e-02,  1.0887e-02, -3.1268e-03,\n",
            "        -2.1667e-02, -5.2839e-02, -3.7480e-02, -2.9252e-02, -1.0288e-02,\n",
            "         9.7473e-03, -3.4331e-02, -2.6842e-02, -4.7752e-02, -4.4481e-03,\n",
            "        -5.0411e-02, -1.8064e-02, -2.4959e-02,  3.8707e-02, -2.3788e-02,\n",
            "        -3.0230e-02, -4.3937e-02, -3.9769e-02, -9.4580e-02,  4.1654e-02,\n",
            "        -3.5936e-02, -2.1148e-02,  1.7497e-02, -3.1961e-02, -2.3776e-02,\n",
            "        -3.7282e-02, -1.5092e-02,  9.8810e-03, -3.9213e-02, -3.9942e-02,\n",
            "        -5.6907e-02, -3.7442e-03, -9.5044e-02, -2.5293e-02, -2.5454e-02,\n",
            "        -4.7367e-02, -5.1332e-02, -2.0713e-03, -2.7323e-02,  5.7385e-03,\n",
            "        -1.9152e-02, -3.3860e-02, -4.8206e-02, -3.2334e-03, -5.0366e-02,\n",
            "        -3.5953e-02,  6.5205e-03, -2.6486e-02,  1.1088e-02, -2.8068e-02,\n",
            "        -7.4271e-02, -1.1911e-02,  1.2842e-02, -2.5225e-02, -3.1306e-02,\n",
            "        -1.9759e-02, -3.5803e-03,  2.0227e-03, -2.1660e-02,  1.1208e-02,\n",
            "        -2.4123e-02,  9.0310e-03, -5.1055e-02, -4.5396e-02, -2.6411e-02,\n",
            "         1.1292e-02,  1.4030e-02, -3.8358e-02, -3.2809e-02, -1.8572e-02,\n",
            "         4.8251e-02, -2.9928e-03, -7.2177e-02, -4.8035e-02,  7.6769e-03,\n",
            "        -6.5365e-02, -3.6413e-02, -1.1881e-02,  1.7021e-02, -1.1635e-02,\n",
            "        -6.0688e-02, -2.3924e-02, -4.9127e-02, -6.5620e-02, -4.3793e-02,\n",
            "        -4.4041e-02, -5.9561e-02, -2.9840e-02, -2.5970e-03, -4.9796e-02,\n",
            "        -1.1559e-02,  7.0239e-03, -3.5945e-02,  1.5993e-02, -4.1892e-02,\n",
            "        -6.8264e-02,  2.1650e-02, -4.1370e-02,  2.1973e-02, -1.5948e-02,\n",
            "        -1.0226e-01, -3.7496e-02,  1.7094e-02, -1.0982e-02,  1.5540e-02,\n",
            "        -5.0556e-02, -2.7001e-02, -2.0114e-02, -5.0169e-02, -2.9489e-02,\n",
            "        -3.9743e-02, -8.5380e-03, -1.8673e-02, -3.8129e-02, -2.1269e-02,\n",
            "        -2.5533e-02, -2.1255e-02, -1.3042e-02, -3.3605e-02, -1.3769e-02,\n",
            "        -2.9272e-02, -2.0493e-02,  6.1399e-03,  3.2051e-02, -2.2862e-02,\n",
            "        -4.3587e-02, -1.2302e-02, -6.0179e-03, -6.3411e-02, -1.3902e-04,\n",
            "         6.6006e-03, -6.3300e-02, -8.8990e-03, -4.0236e-03, -5.1070e-02,\n",
            "        -5.1127e-02, -3.9643e-02, -5.2284e-02, -4.6759e-02, -5.3112e-02,\n",
            "        -2.7392e-02, -2.9490e-02, -2.2758e-02, -9.5000e-03, -1.2496e-02,\n",
            "        -3.4707e-02, -1.4716e-02, -1.2888e-02, -1.2930e-03, -5.0056e-02,\n",
            "        -4.8036e-02, -3.2378e-02, -3.6429e-02, -3.8621e-02, -3.1510e-02,\n",
            "        -5.1300e-02,  1.4994e-02,  1.2208e-05, -1.4082e-02,  1.7620e-03,\n",
            "        -4.7165e-02, -3.7629e-02, -3.8766e-02,  9.4560e-03, -1.5576e-02,\n",
            "        -3.9815e-02,  1.1144e-02,  9.7832e-03, -1.2574e-02, -4.5413e-02,\n",
            "        -8.2680e-03, -2.0615e-02, -1.7477e-02, -4.7983e-02, -2.5950e-02,\n",
            "        -4.0306e-02])}\n",
            "Nonce: 2779\n",
            "Previous Block Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "BlockNo: 2\n",
            "Block Data: {'layer': 'fc2', 'weight': tensor([[ 0.0700,  0.0577, -0.0515,  ..., -0.0376, -0.0064, -0.0211],\n",
            "        [ 0.2691,  0.0488, -0.0146,  ...,  0.1431,  0.0142, -0.0360],\n",
            "        [ 0.1107,  0.0349,  0.0097,  ...,  0.0975, -0.0220,  0.0102],\n",
            "        ...,\n",
            "        [-0.0245,  0.0396, -0.0413,  ..., -0.0204, -0.0343,  0.0537],\n",
            "        [-0.0211,  0.0468, -0.0537,  ..., -0.1140,  0.0065,  0.0199],\n",
            "        [ 0.1608, -0.0083, -0.0337,  ...,  0.0963, -0.0206,  0.0148]]), 'bias': tensor([-0.0489,  0.1896,  0.1729, -0.1131, -0.1978,  0.0504, -0.0708, -0.1582,\n",
            "        -0.0030, -0.1288,  0.0108,  0.0125, -0.0415, -0.1031, -0.0630, -0.0025,\n",
            "        -0.1085, -0.0879, -0.0841,  0.3088,  0.1560,  0.0175, -0.2156, -0.1164,\n",
            "        -0.1923, -0.0915, -0.1100, -0.0354, -0.2318, -0.0061, -0.0592, -0.1969,\n",
            "        -0.0775, -0.1088, -0.1204, -0.1337, -0.2263,  0.1045, -0.1049, -0.1794,\n",
            "        -0.1485, -0.1131, -0.1346, -0.1471,  0.0449,  0.0613,  0.1513, -0.0190,\n",
            "        -0.0355, -0.1064,  0.2106, -0.1671,  0.0496,  0.0589, -0.1245, -0.1031,\n",
            "         0.0060, -0.0687, -0.1207, -0.0791,  0.0110, -0.1303,  0.0872, -0.0913,\n",
            "        -0.0502, -0.1575,  0.0946, -0.0620,  0.0189,  0.0400, -0.0242, -0.2191,\n",
            "        -0.1293, -0.1497,  0.1555,  0.2938, -0.0674, -0.3190, -0.0629, -0.1634,\n",
            "        -0.0147, -0.0193, -0.1928, -0.0061, -0.1173, -0.0514, -0.1626, -0.2278,\n",
            "        -0.0745, -0.0037, -0.0470, -0.0303, -0.1636, -0.1014,  0.1747, -0.0842,\n",
            "        -0.1578,  0.0232, -0.0125, -0.1983,  0.4642, -0.1431,  0.0178, -0.0420,\n",
            "        -0.0608, -0.0430, -0.0866,  0.0265, -0.0709,  0.0132,  0.0132, -0.1032,\n",
            "        -0.0352, -0.0149, -0.2466, -0.0685, -0.1978, -0.0966, -0.0275, -0.2409,\n",
            "         0.2949, -0.1386,  0.0520, -0.1878, -0.1932, -0.0528, -0.0524,  0.1045])}\n",
            "Nonce: 6875\n",
            "Previous Block Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "--------------\n",
            "==========================END OF CHAIN============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "next, for the rest of the blockchain (remaining blocks), mine new blocks using the data from corrupted blockchain\n",
        "'''\n",
        "for remaining_block in blockchain.chain[targeted_block_id:]:\n",
        "  newBlock = Block(remaining_block)\n",
        "  new_blockchain.mine(newBlock)\n"
      ],
      "metadata": {
        "id": "o40PYmQ-GBmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e144f90-c6be-4026-e788-e027ca37d18d"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block 3 - Qualified: 000241271c00302230e59b3c2d101e500662c121f9007e7c75c284aacc7f4cde\n",
            "Block 4 - Qualified: 0004c50a9b07a08fec571f561bdcbaa64a5397ac19cb6f255273362f9a3bb698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I corrupted block #3 so I need to remine the last 2 blocks, `3` and `4`. \n",
        "```\n",
        "Block 3 - Qualified: 0008356eb442d99a61af3c2cb084fc8c10deccd570fbbd6ff8dc2c5101f0ed26\n",
        "Block 4 - Qualified: 000c8572dea5751c62f11b8d385db058f9be5105170ee6fbe5d4ae88b21dfc33\n",
        "```"
      ],
      "metadata": {
        "id": "FycrpMSAKULl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Validate after re-mining\n",
        "'''\n",
        "new_blockchain.validate_chain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLkQIitxGbB_",
        "outputId": "33721acf-7f64-458a-a290-7870ca906841"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 000241271c00302230e59b3c2d101e500662c121f9007e7c75c284aacc7f4cde\n",
            "Hash of Previous Block: 000241271c00302230e59b3c2d101e500662c121f9007e7c75c284aacc7f4cde\n",
            "Blockchain is correct!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison: \n",
        "\n",
        "Original Blockchain:\n",
        "```\n",
        "\n",
        "Previous_Hash: 00069904f6a0203da5e999d81fb2950033e0a2ca3b6f0c62dcf505ebc5a3ac5e\n",
        "Hash of Previous Block: 00069904f6a0203da5e999d81fb2950033e0a2ca3b6f0c62dcf505ebc5a3ac5e\n",
        "\n",
        "Previous_Hash: 00034f0cfbebb1eef3d1388b28d1f9bf636075695127fab2b0efab18cc82c454\n",
        "Hash of Previous Block: 00034f0cfbebb1eef3d1388b28d1f9bf636075695127fab2b0efab18cc82c454\n",
        "\n",
        "Previous_Hash: 000b2f693ec9803211acda48fb48722d12d7629afabb0bfba0344a565411938a\n",
        "Hash of Previous Block: 000b2f693ec9803211acda48fb48722d12d7629afabb0bfba0344a565411938a\n",
        "\n",
        "Previous_Hash: 000a37025f722d2e603687b47453811c1a3bca2d2a8c37819f5ea7df3fa9ab2d\n",
        "Hash of Previous Block: 000a37025f722d2e603687b47453811c1a3bca2d2a8c37819f5ea7df3fa9ab2d\n",
        "Blockchain is correct!\n",
        "True\n",
        "\n",
        "```\n",
        "\n",
        "Corrupted Blockchain:\n",
        "\n",
        "```\n",
        "Previous_Hash: 00069904f6a0203da5e999d81fb2950033e0a2ca3b6f0c62dcf505ebc5a3ac5e\n",
        "Hash of Previous Block: 00069904f6a0203da5e999d81fb2950033e0a2ca3b6f0c62dcf505ebc5a3ac5e\n",
        "\n",
        "Previous_Hash: 00034f0cfbebb1eef3d1388b28d1f9bf636075695127fab2b0efab18cc82c454\n",
        "Hash of Previous Block: 00034f0cfbebb1eef3d1388b28d1f9bf636075695127fab2b0efab18cc82c454\n",
        "\n",
        "Previous_Hash: 000b2f693ec9803211acda48fb48722d12d7629afabb0bfba0344a565411938a\n",
        "Hash of Previous Block: 000b2f693ec9803211acda48fb48722d12d7629afabb0bfba0344a565411938a\n",
        "\n",
        "Previous_Hash: 000a37025f722d2e603687b47453811c1a3bca2d2a8c37819f5ea7df3fa9ab2d\n",
        "Hash of Previous Block: e220ea395f49b3fb417160f973b504c2c8d05933e2f26567b1740ece779f3fe5\n",
        "Block 3 is tampered!\n",
        "False\n",
        "```\n",
        "\n",
        "Corrupted Blockchain (Re-hashed):\n",
        "\n",
        "```\n",
        "Previous_Hash: 00074f9f5c14b884c5faa8f5779cabfa0c32092be789b370d6c9439d15026ac0\n",
        "\n",
        "Previous_Hash: 00069904f6a0203da5e999d81fb2950033e0a2ca3b6f0c62dcf505ebc5a3ac5e\n",
        "Hash of Previous Block: 00069904f6a0203da5e999d81fb2950033e0a2ca3b6f0c62dcf505ebc5a3ac5e\n",
        "\n",
        "Previous_Hash: 00034f0cfbebb1eef3d1388b28d1f9bf636075695127fab2b0efab18cc82c454\n",
        "Hash of Previous Block: 00034f0cfbebb1eef3d1388b28d1f9bf636075695127fab2b0efab18cc82c454\n",
        "\n",
        "Previous_Hash: 000b2f693ec9803211acda48fb48722d12d7629afabb0bfba0344a565411938a\n",
        "Hash of Previous Block: 000b2f693ec9803211acda48fb48722d12d7629afabb0bfba0344a565411938a\n",
        "\n",
        "Previous_Hash: 000b42a97c835056c1b40cf2c3f4026d1cff18077c7f1fbe9ce5b00ed8982139\n",
        "Hash of Previous Block: 000b42a97c835056c1b40cf2c3f4026d1cff18077c7f1fbe9ce5b00ed8982139\n",
        "Blockchain is correct!\n",
        "True\n",
        "```"
      ],
      "metadata": {
        "id": "zGaRiDKjGsVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a decentralized network, consensus will prevent this from happening."
      ],
      "metadata": {
        "id": "Gmn5xHlwIZVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student Exercise: Implement P2P Simulation and Consensus with 3 or more peers.\n",
        "Choose an attack for one of the peers.\n",
        "\n",
        "Context: one client will have a corrupted blockchain (one or more blocks are defective but hashes pass all difficulties). \n",
        "\n",
        "Afterwards, the blockchain will be validated not only in terms of hashes, but also in terms of consistency throughout the network. If hashes do not check out across the peers, use consensus to recover the blockchain to the correct state.\n",
        "\n",
        "Requirements: \n",
        "* Use 3 or more peers\n",
        "* Use your own model\n",
        "* Use the 51\\% or 2/3 rule for consensus."
      ],
      "metadata": {
        "id": "iTTpgfp-X3fB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blockchain_1 = Blockchain()\n",
        "blockchain_2 = Blockchain()\n",
        "blockchain_3 = Blockchain()\n",
        "\n",
        "for x in raw_data: \n",
        "  newBlock = Block(x)\n",
        "  blockchain_1.mine(newBlock)\n",
        "  blockchain_2.mine(newBlock)\n",
        "  blockchain_3.mine(newBlock)\n",
        "\n",
        "print(\"Peer 1 \")\n",
        "print(blockchain_1)\n",
        "\n",
        "print(\"Peer 2\")\n",
        "print(blockchain_2)\n",
        "\n",
        "print(\"Peer 3\")\n",
        "print(blockchain_3)"
      ],
      "metadata": {
        "id": "Yw2OBrtAL79Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77599a64-425e-481c-c6e6-28206de6ae7c"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block 0 - Qualified: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Block 0 - Qualified: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Block 0 - Qualified: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Block 1 - Qualified: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Block 1 - Qualified: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Block 1 - Qualified: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Block 2 - Qualified: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Block 2 - Qualified: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Block 2 - Qualified: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Block 3 - Qualified: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Block 3 - Qualified: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Block 3 - Qualified: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Block 4 - Qualified: 000c7d81680ba960bc28b54930ce571c511bca021e1bef7efc4d487951494832\n",
            "Block 4 - Qualified: 000c7d81680ba960bc28b54930ce571c511bca021e1bef7efc4d487951494832\n",
            "Block 4 - Qualified: 000c7d81680ba960bc28b54930ce571c511bca021e1bef7efc4d487951494832\n",
            "Peer 1 \n",
            "\n",
            "--------------Block Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "BlockNo: 0\n",
            "Block Data: Genesis\n",
            "Nonce: 1176\n",
            "Previous Block Hash: 00000000000000000000000000000000\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "BlockNo: 1\n",
            "Block Data: {'layer': 'fc1', 'weight': tensor([[ 0.0329,  0.0086,  0.0243,  ...,  0.0497,  0.0563,  0.0528],\n",
            "        [-0.0129,  0.0104,  0.0365,  ...,  0.0194,  0.0207,  0.0246],\n",
            "        [ 0.0081,  0.0136, -0.0052,  ...,  0.0030,  0.0517,  0.0313],\n",
            "        ...,\n",
            "        [ 0.0393,  0.0300,  0.0377,  ...,  0.0255,  0.0073,  0.0581],\n",
            "        [ 0.0441,  0.0390,  0.0418,  ...,  0.0376, -0.0042,  0.0096],\n",
            "        [ 0.0226,  0.0080,  0.0011,  ..., -0.0116,  0.0461,  0.0215]]), 'bias': tensor([-5.0697e-02, -1.5882e-03, -4.5533e-02, -8.9822e-04, -7.9249e-02,\n",
            "         3.3151e-03, -3.6789e-02, -1.7230e-02, -5.2123e-02, -2.5209e-02,\n",
            "         8.5094e-03, -5.6987e-02, -2.2219e-02, -2.8807e-02, -1.7612e-02,\n",
            "         4.9885e-03, -1.4747e-03, -7.5809e-02,  1.5871e-02, -4.0564e-03,\n",
            "        -3.7250e-03, -4.6109e-02,  2.5242e-03,  4.4355e-03,  1.0314e-02,\n",
            "        -7.1663e-02,  9.1916e-03, -3.6697e-02, -3.8919e-02, -3.2340e-02,\n",
            "        -1.7095e-02, -2.2695e-02, -7.3756e-03, -3.2307e-03, -2.6671e-02,\n",
            "        -1.4188e-02, -5.8340e-03, -3.8018e-02, -3.0583e-02, -1.8098e-02,\n",
            "         2.1612e-02, -8.6132e-02, -2.3886e-02, -1.1493e-02, -8.3055e-03,\n",
            "        -1.7589e-03,  1.1987e-02, -4.2030e-02, -3.9615e-02,  4.4278e-03,\n",
            "        -1.7534e-02, -2.4694e-02, -2.1543e-02, -3.4609e-02,  2.3570e-02,\n",
            "         2.6285e-02, -1.3856e-02,  1.1432e-02, -2.7742e-02,  3.2082e-04,\n",
            "         4.6447e-03,  1.1198e-02, -1.5167e-02, -4.9473e-02, -4.2446e-02,\n",
            "         5.3062e-02, -6.3078e-02, -2.2603e-02, -1.0497e-02, -4.7284e-03,\n",
            "        -4.0333e-02,  4.8095e-03, -5.9835e-02,  5.7884e-03, -5.8095e-03,\n",
            "        -2.4915e-02, -1.1267e-02, -5.3225e-02,  1.0887e-02, -3.1268e-03,\n",
            "        -2.1667e-02, -5.2839e-02, -3.7480e-02, -2.9252e-02, -1.0288e-02,\n",
            "         9.7473e-03, -3.4331e-02, -2.6842e-02, -4.7752e-02, -4.4481e-03,\n",
            "        -5.0411e-02, -1.8064e-02, -2.4959e-02,  3.8707e-02, -2.3788e-02,\n",
            "        -3.0230e-02, -4.3937e-02, -3.9769e-02, -9.4580e-02,  4.1654e-02,\n",
            "        -3.5936e-02, -2.1148e-02,  1.7497e-02, -3.1961e-02, -2.3776e-02,\n",
            "        -3.7282e-02, -1.5092e-02,  9.8810e-03, -3.9213e-02, -3.9942e-02,\n",
            "        -5.6907e-02, -3.7442e-03, -9.5044e-02, -2.5293e-02, -2.5454e-02,\n",
            "        -4.7367e-02, -5.1332e-02, -2.0713e-03, -2.7323e-02,  5.7385e-03,\n",
            "        -1.9152e-02, -3.3860e-02, -4.8206e-02, -3.2334e-03, -5.0366e-02,\n",
            "        -3.5953e-02,  6.5205e-03, -2.6486e-02,  1.1088e-02, -2.8068e-02,\n",
            "        -7.4271e-02, -1.1911e-02,  1.2842e-02, -2.5225e-02, -3.1306e-02,\n",
            "        -1.9759e-02, -3.5803e-03,  2.0227e-03, -2.1660e-02,  1.1208e-02,\n",
            "        -2.4123e-02,  9.0310e-03, -5.1055e-02, -4.5396e-02, -2.6411e-02,\n",
            "         1.1292e-02,  1.4030e-02, -3.8358e-02, -3.2809e-02, -1.8572e-02,\n",
            "         4.8251e-02, -2.9928e-03, -7.2177e-02, -4.8035e-02,  7.6769e-03,\n",
            "        -6.5365e-02, -3.6413e-02, -1.1881e-02,  1.7021e-02, -1.1635e-02,\n",
            "        -6.0688e-02, -2.3924e-02, -4.9127e-02, -6.5620e-02, -4.3793e-02,\n",
            "        -4.4041e-02, -5.9561e-02, -2.9840e-02, -2.5970e-03, -4.9796e-02,\n",
            "        -1.1559e-02,  7.0239e-03, -3.5945e-02,  1.5993e-02, -4.1892e-02,\n",
            "        -6.8264e-02,  2.1650e-02, -4.1370e-02,  2.1973e-02, -1.5948e-02,\n",
            "        -1.0226e-01, -3.7496e-02,  1.7094e-02, -1.0982e-02,  1.5540e-02,\n",
            "        -5.0556e-02, -2.7001e-02, -2.0114e-02, -5.0169e-02, -2.9489e-02,\n",
            "        -3.9743e-02, -8.5380e-03, -1.8673e-02, -3.8129e-02, -2.1269e-02,\n",
            "        -2.5533e-02, -2.1255e-02, -1.3042e-02, -3.3605e-02, -1.3769e-02,\n",
            "        -2.9272e-02, -2.0493e-02,  6.1399e-03,  3.2051e-02, -2.2862e-02,\n",
            "        -4.3587e-02, -1.2302e-02, -6.0179e-03, -6.3411e-02, -1.3902e-04,\n",
            "         6.6006e-03, -6.3300e-02, -8.8990e-03, -4.0236e-03, -5.1070e-02,\n",
            "        -5.1127e-02, -3.9643e-02, -5.2284e-02, -4.6759e-02, -5.3112e-02,\n",
            "        -2.7392e-02, -2.9490e-02, -2.2758e-02, -9.5000e-03, -1.2496e-02,\n",
            "        -3.4707e-02, -1.4716e-02, -1.2888e-02, -1.2930e-03, -5.0056e-02,\n",
            "        -4.8036e-02, -3.2378e-02, -3.6429e-02, -3.8621e-02, -3.1510e-02,\n",
            "        -5.1300e-02,  1.4994e-02,  1.2208e-05, -1.4082e-02,  1.7620e-03,\n",
            "        -4.7165e-02, -3.7629e-02, -3.8766e-02,  9.4560e-03, -1.5576e-02,\n",
            "        -3.9815e-02,  1.1144e-02,  9.7832e-03, -1.2574e-02, -4.5413e-02,\n",
            "        -8.2680e-03, -2.0615e-02, -1.7477e-02, -4.7983e-02, -2.5950e-02,\n",
            "        -4.0306e-02])}\n",
            "Nonce: 2779\n",
            "Previous Block Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "BlockNo: 2\n",
            "Block Data: {'layer': 'fc2', 'weight': tensor([[ 0.0700,  0.0577, -0.0515,  ..., -0.0376, -0.0064, -0.0211],\n",
            "        [ 0.2691,  0.0488, -0.0146,  ...,  0.1431,  0.0142, -0.0360],\n",
            "        [ 0.1107,  0.0349,  0.0097,  ...,  0.0975, -0.0220,  0.0102],\n",
            "        ...,\n",
            "        [-0.0245,  0.0396, -0.0413,  ..., -0.0204, -0.0343,  0.0537],\n",
            "        [-0.0211,  0.0468, -0.0537,  ..., -0.1140,  0.0065,  0.0199],\n",
            "        [ 0.1608, -0.0083, -0.0337,  ...,  0.0963, -0.0206,  0.0148]]), 'bias': tensor([-0.0489,  0.1896,  0.1729, -0.1131, -0.1978,  0.0504, -0.0708, -0.1582,\n",
            "        -0.0030, -0.1288,  0.0108,  0.0125, -0.0415, -0.1031, -0.0630, -0.0025,\n",
            "        -0.1085, -0.0879, -0.0841,  0.3088,  0.1560,  0.0175, -0.2156, -0.1164,\n",
            "        -0.1923, -0.0915, -0.1100, -0.0354, -0.2318, -0.0061, -0.0592, -0.1969,\n",
            "        -0.0775, -0.1088, -0.1204, -0.1337, -0.2263,  0.1045, -0.1049, -0.1794,\n",
            "        -0.1485, -0.1131, -0.1346, -0.1471,  0.0449,  0.0613,  0.1513, -0.0190,\n",
            "        -0.0355, -0.1064,  0.2106, -0.1671,  0.0496,  0.0589, -0.1245, -0.1031,\n",
            "         0.0060, -0.0687, -0.1207, -0.0791,  0.0110, -0.1303,  0.0872, -0.0913,\n",
            "        -0.0502, -0.1575,  0.0946, -0.0620,  0.0189,  0.0400, -0.0242, -0.2191,\n",
            "        -0.1293, -0.1497,  0.1555,  0.2938, -0.0674, -0.3190, -0.0629, -0.1634,\n",
            "        -0.0147, -0.0193, -0.1928, -0.0061, -0.1173, -0.0514, -0.1626, -0.2278,\n",
            "        -0.0745, -0.0037, -0.0470, -0.0303, -0.1636, -0.1014,  0.1747, -0.0842,\n",
            "        -0.1578,  0.0232, -0.0125, -0.1983,  0.4642, -0.1431,  0.0178, -0.0420,\n",
            "        -0.0608, -0.0430, -0.0866,  0.0265, -0.0709,  0.0132,  0.0132, -0.1032,\n",
            "        -0.0352, -0.0149, -0.2466, -0.0685, -0.1978, -0.0966, -0.0275, -0.2409,\n",
            "         0.2949, -0.1386,  0.0520, -0.1878, -0.1932, -0.0528, -0.0524,  0.1045])}\n",
            "Nonce: 6875\n",
            "Previous Block Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "BlockNo: 3\n",
            "Block Data: {'layer': 'fc3', 'weight': tensor([[-0.0898,  0.0228, -0.0250,  ...,  0.0682, -0.1015, -0.0751],\n",
            "        [ 0.0142, -0.0617, -0.0568,  ..., -0.0338, -0.0558,  0.0405],\n",
            "        [-0.1508, -0.0901, -0.0380,  ...,  0.0528,  0.0925, -0.0676],\n",
            "        ...,\n",
            "        [ 0.0139,  0.0265, -0.1787,  ...,  0.0430,  0.0435, -0.0926],\n",
            "        [-0.0654, -0.0217, -0.1451,  ...,  0.0332, -0.0209, -0.1631],\n",
            "        [ 0.0609, -0.0105, -0.0566,  ...,  0.0403,  0.1513, -0.0428]]), 'bias': tensor([-0.1711, -0.1505, -0.1412,  0.0111, -0.0597,  0.1476, -0.0710, -0.0209,\n",
            "         0.1606,  0.2981,  0.1772, -0.2506, -0.0747, -0.2264, -0.2045, -0.3326,\n",
            "        -0.1356, -0.0518, -0.1744, -0.1427, -0.0377,  0.1834,  0.2696,  0.4100,\n",
            "        -0.2308, -0.2062, -0.0479,  0.0068, -0.1853,  0.1144, -0.1299,  0.1610,\n",
            "        -0.0101,  0.0754,  0.0926, -0.0319,  0.1107,  0.1191, -0.2281, -0.1523,\n",
            "        -0.2556, -0.1582, -0.0862, -0.0819, -0.0549,  0.1640, -0.1267, -0.0659,\n",
            "         0.0778, -0.0852, -0.0334,  0.2512, -0.0555,  0.2768,  0.0982,  0.3895,\n",
            "         0.1073, -0.1683,  0.0174, -0.0115,  0.2321, -0.3172, -0.1211,  0.0065])}\n",
            "Nonce: 4952\n",
            "Previous Block Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 000c7d81680ba960bc28b54930ce571c511bca021e1bef7efc4d487951494832\n",
            "BlockNo: 4\n",
            "Block Data: {'layer': 'fc4', 'weight': tensor([[-3.0591e-02,  3.4098e-02, -1.2472e-02, -8.9146e-03, -9.6389e-02,\n",
            "         -3.0413e-02, -2.2714e-02, -1.3556e-01,  6.6748e-02, -3.5200e-02,\n",
            "          1.7505e-01, -3.1370e-01,  1.0929e-01, -1.2965e-01, -2.6508e-01,\n",
            "         -4.6322e-03, -3.6083e-02,  1.6212e-01, -1.5626e-01,  9.0508e-03,\n",
            "          5.9090e-02, -1.5017e-01, -7.2761e-02,  1.0360e-01, -4.0878e-02,\n",
            "         -4.2697e-02, -2.6090e-01, -1.6544e-01, -2.2813e-01, -3.4041e-02,\n",
            "         -1.9108e-01, -2.0858e-01, -2.4329e-01,  2.5279e-02,  2.4480e-02,\n",
            "         -1.2921e-01,  6.6503e-03,  1.2826e-01, -1.9499e-01, -1.2286e-01,\n",
            "         -1.7484e-01,  2.2954e-02, -3.3802e-02,  1.6398e-01, -2.7393e-01,\n",
            "          4.4774e-02, -9.7249e-02, -2.8936e-02,  3.6314e-02,  1.2736e-01,\n",
            "         -8.5061e-02, -2.2160e-02, -4.3429e-03,  9.0347e-02, -4.5799e-02,\n",
            "         -2.9034e-01,  8.9424e-02, -1.3177e-01,  1.3366e-01, -1.0684e-01,\n",
            "          1.9650e-01,  2.1380e-02, -1.4263e-01, -1.2987e-01],\n",
            "        [ 8.0527e-02, -6.9936e-04, -1.8440e-01,  1.1717e-01, -3.7756e-01,\n",
            "         -6.7468e-02, -1.5667e-01, -2.0755e-01, -1.0310e-01,  7.1767e-02,\n",
            "         -2.0145e-01,  5.0998e-02,  8.0554e-02,  1.2831e-01, -2.6437e-01,\n",
            "         -3.8163e-01, -2.1519e-01, -1.3688e-01,  1.7053e-01, -9.2981e-03,\n",
            "         -4.9034e-01,  1.8303e-01, -6.3352e-02, -1.2537e-01, -9.2299e-02,\n",
            "         -4.9045e-02, -8.7175e-02,  1.0087e-01,  1.2594e-01, -5.7340e-02,\n",
            "          7.7662e-02,  1.2764e-01, -7.3948e-02,  9.9066e-02, -3.6424e-01,\n",
            "          1.6530e-01,  4.2991e-02, -3.7876e-04,  1.2653e-01, -9.9515e-02,\n",
            "         -1.6171e-01, -2.6207e-01,  1.2642e-01, -1.0301e-01, -3.8597e-02,\n",
            "         -2.5949e-01, -4.0102e-02, -1.6334e-01, -3.1535e-03,  9.5392e-02,\n",
            "          1.9991e-01, -2.1034e-01, -4.6928e-02,  2.9913e-03, -1.2064e-01,\n",
            "         -7.1262e-02, -2.4595e-01,  9.1223e-02,  6.6555e-03, -3.2185e-02,\n",
            "         -4.2523e-02, -1.1373e-01, -4.1103e-02, -2.2379e-02],\n",
            "        [-2.6639e-02, -4.9905e-02, -1.9280e-01, -8.7954e-02, -2.1338e-01,\n",
            "          1.7716e-01,  7.3641e-02, -8.6437e-02,  1.7046e-01, -1.2248e-01,\n",
            "         -7.8791e-02, -2.1608e-01, -4.4691e-02, -5.7541e-02,  6.5678e-02,\n",
            "         -1.5597e-01, -6.6167e-02,  1.4628e-01, -3.6590e-02, -7.6277e-02,\n",
            "          7.0731e-02,  1.2854e-01,  3.3084e-03, -2.1850e-01, -4.5549e-01,\n",
            "         -3.2332e-02,  1.7795e-02,  5.6002e-02, -1.4506e-01,  5.6319e-02,\n",
            "         -7.7656e-03, -2.1966e-01, -3.4202e-02, -5.8937e-02,  5.5518e-02,\n",
            "         -8.4144e-02, -8.6981e-02,  7.5757e-02,  1.1461e-01,  1.1005e-02,\n",
            "         -1.1787e-01, -1.6547e-01,  1.4386e-01, -7.4872e-02,  1.1260e-01,\n",
            "         -9.3629e-02,  4.8144e-02, -2.4308e-01,  1.8799e-02,  1.2744e-01,\n",
            "         -2.2816e-01,  4.7110e-02,  5.8897e-02,  9.6572e-02, -4.9287e-02,\n",
            "         -1.9062e-01, -3.4617e-03,  8.7256e-02,  1.7190e-01,  1.0175e-01,\n",
            "          9.3590e-02,  4.5341e-02,  2.4749e-02, -8.6945e-03],\n",
            "        [ 5.9198e-02, -1.4971e-01, -9.7188e-02, -1.2221e-01, -1.5573e-01,\n",
            "          1.5950e-01,  2.6218e-02,  8.2093e-03, -1.5829e-01, -2.3822e-01,\n",
            "          1.2463e-01, -1.1859e-01, -7.6052e-02,  1.9792e-02,  9.6583e-02,\n",
            "         -1.9772e-01, -6.2933e-02,  1.9615e-02,  1.4603e-01,  1.7161e-02,\n",
            "          3.7421e-02, -8.3916e-02,  9.4765e-02,  6.9403e-02, -1.7282e-01,\n",
            "         -4.0344e-03, -3.3327e-01, -8.5024e-02,  3.8942e-02, -5.6872e-02,\n",
            "         -9.1727e-02,  1.1133e-02, -1.5001e-01, -2.1141e-02, -1.0731e-01,\n",
            "         -9.3394e-02, -1.5909e-02,  7.1904e-02,  1.6437e-01, -5.1592e-02,\n",
            "         -2.1686e-01,  9.9757e-02, -2.0598e-02, -2.8799e-01,  1.4090e-01,\n",
            "         -1.1475e-02, -2.2539e-01, -6.3897e-02,  1.4890e-01,  6.4978e-02,\n",
            "         -5.7421e-02, -6.9976e-02,  7.4733e-02,  1.9975e-01, -1.3631e-01,\n",
            "          1.2692e-01,  2.9700e-02, -1.4718e-02,  5.1793e-03, -2.9027e-02,\n",
            "         -1.5312e-01,  2.0889e-02, -1.6939e-01, -4.4671e-02],\n",
            "        [ 1.3601e-02,  3.4387e-02, -1.3839e-01,  1.3523e-01, -2.2648e-01,\n",
            "         -1.1276e-01, -5.7338e-02, -6.2247e-02,  1.3348e-01, -5.2199e-03,\n",
            "          8.8016e-02, -5.2034e-02, -8.9455e-02,  9.6045e-03, -1.6267e-01,\n",
            "         -1.0997e-01, -1.5902e-01, -9.8831e-02,  3.3417e-02, -1.3838e-02,\n",
            "          6.3099e-02,  3.4767e-02, -1.9705e-01,  4.2852e-03, -2.5631e-01,\n",
            "          2.1715e-02,  1.4374e-02, -2.6716e-02,  3.3939e-03, -2.1987e-01,\n",
            "         -9.5788e-02,  1.6396e-01,  1.7821e-02,  1.0946e-02,  1.4986e-01,\n",
            "          9.2288e-02, -1.0144e-01, -1.8618e-02, -1.2044e-04, -1.2222e-01,\n",
            "         -5.6505e-02, -2.0812e-01, -2.6812e-02, -1.8149e-01,  1.0401e-01,\n",
            "         -5.4234e-02,  1.8465e-02,  9.2364e-02, -8.0603e-03,  4.0180e-02,\n",
            "         -3.0521e-02,  9.8548e-02, -2.2265e-01, -1.0132e-01,  1.0515e-01,\n",
            "          6.8693e-02, -1.8465e-01,  3.3156e-02, -5.4205e-02,  2.1594e-01,\n",
            "          8.0506e-02, -3.4505e-02, -1.5035e-01,  7.2493e-02],\n",
            "        [-1.5107e-02, -1.7190e-01, -2.5686e-02, -2.0609e-01,  2.4864e-02,\n",
            "          6.2660e-03, -1.1918e-01,  2.0434e-02, -9.6026e-02, -4.8028e-02,\n",
            "         -1.2094e-01, -1.0661e-01, -8.2729e-02,  4.1797e-02, -9.0162e-02,\n",
            "         -4.6264e-02,  1.8812e-01,  8.3817e-02,  1.1808e-01, -7.0366e-03,\n",
            "         -5.1755e-02, -4.5842e-02,  8.8472e-02,  7.0996e-03, -1.5127e-01,\n",
            "          5.1642e-03, -1.2410e-01, -8.3846e-02,  1.4713e-03, -2.3384e-02,\n",
            "          9.8134e-02,  2.3282e-02,  1.3950e-01, -1.6195e-01,  5.5275e-02,\n",
            "         -1.8728e-02,  1.5886e-01,  6.4935e-02, -1.1813e-01, -1.1567e-01,\n",
            "         -1.5507e-01,  1.0447e-01, -2.9090e-02,  4.4763e-03,  9.7352e-02,\n",
            "          1.1801e-01, -1.3295e-01,  4.4080e-02,  3.5852e-02, -9.3856e-02,\n",
            "         -2.5354e-03,  1.4111e-02,  8.6333e-04, -1.0574e-01, -7.3117e-02,\n",
            "          5.2291e-02, -7.2708e-03,  1.1661e-01, -7.5096e-02, -1.6445e-01,\n",
            "         -9.4599e-02, -1.4393e-01,  9.2639e-02, -1.0104e-01],\n",
            "        [-9.2999e-02,  3.2939e-02,  7.7569e-02,  1.2329e-01,  6.8271e-02,\n",
            "         -5.7074e-02, -9.7534e-02,  1.0594e-01, -1.8849e-01,  1.0334e-01,\n",
            "          1.4596e-01, -1.2874e-01,  1.8499e-02, -2.5217e-01, -3.7181e-01,\n",
            "         -8.4419e-02,  2.5565e-02, -8.0157e-02, -4.5190e-02,  4.6831e-03,\n",
            "          8.4701e-03, -2.4271e-02, -1.3587e-01,  1.8156e-01, -2.2558e-01,\n",
            "         -3.1215e-02, -3.8632e-01, -2.0433e-01, -2.0086e-01, -1.9205e-01,\n",
            "         -2.1231e-02, -1.4768e-01,  1.3509e-01,  7.8970e-02, -2.7377e-02,\n",
            "         -3.4304e-02,  1.5141e-01, -1.8696e-01, -9.3842e-02,  8.0565e-02,\n",
            "         -2.5625e-01, -5.1263e-02,  1.6240e-01, -1.0645e-01, -3.5994e-02,\n",
            "         -4.1154e-02,  1.9525e-02,  5.6315e-02,  1.8552e-01, -1.0291e-01,\n",
            "         -4.7442e-03,  2.8336e-02, -5.3458e-02, -2.9615e-01, -7.4837e-02,\n",
            "         -1.4042e-01, -4.0359e-01, -1.5856e-02, -2.2115e-01,  4.3629e-03,\n",
            "          7.6001e-02, -1.6410e-01, -5.1871e-02, -8.2789e-02],\n",
            "        [-1.8239e-03,  3.5877e-02, -4.2871e-02,  9.6933e-02, -6.5738e-02,\n",
            "         -9.5464e-02, -2.2584e-01, -2.1874e-02, -1.3169e-01, -1.0763e-01,\n",
            "         -2.9869e-01, -2.4803e-01, -1.0345e-01,  9.4159e-02,  1.2660e-01,\n",
            "          7.4724e-02, -1.7667e-01, -6.6567e-02,  1.2672e-01, -4.3086e-02,\n",
            "         -2.6427e-01,  5.4197e-02, -1.8951e-01, -1.4216e-01,  5.9037e-04,\n",
            "          3.8746e-02,  1.7537e-02,  1.9705e-01, -2.0985e-01, -9.0419e-02,\n",
            "         -1.9331e-01, -2.6807e-02, -7.3848e-02, -2.4975e-01,  3.3268e-02,\n",
            "         -8.3329e-02, -9.7251e-02,  2.0017e-02,  2.1676e-01, -1.8951e-01,\n",
            "         -3.0675e-02,  1.5512e-02,  2.8178e-02,  1.7990e-01, -3.5415e-02,\n",
            "         -1.8663e-01,  7.4498e-02,  3.1793e-02,  9.6635e-02,  1.7503e-02,\n",
            "         -6.1472e-02, -1.0570e-01,  4.2936e-02,  7.0300e-02, -8.3744e-02,\n",
            "          4.0475e-02,  1.2125e-01, -2.5267e-01,  1.1248e-01,  1.2021e-01,\n",
            "         -2.5559e-01, -1.4190e-01, -2.0342e-02,  1.4038e-01],\n",
            "        [-1.0926e-01,  3.6893e-03, -6.8264e-03, -3.8456e-02, -1.7640e-01,\n",
            "          4.7644e-02, -1.5130e-01, -2.5377e-02, -1.0458e-01,  1.5831e-01,\n",
            "         -1.4367e-01, -2.2789e-01,  5.8957e-03, -1.2621e-01, -1.1740e-01,\n",
            "         -1.6444e-01, -7.8225e-02, -1.3360e-01, -4.0109e-02,  3.9534e-02,\n",
            "         -4.8940e-03,  5.0944e-02,  1.0072e-01,  8.4909e-02, -2.0891e-02,\n",
            "          6.8689e-02, -1.2404e-01,  4.1738e-02, -1.9037e-01, -7.3585e-02,\n",
            "          1.0875e-01, -1.8278e-02, -4.9892e-02,  1.3167e-01, -7.3981e-02,\n",
            "          4.9814e-02,  9.5502e-02,  8.7666e-02, -1.1627e-03,  2.6633e-02,\n",
            "         -9.4880e-01, -1.6348e-01, -2.1192e-01, -4.6418e-02, -2.0423e-01,\n",
            "          9.1853e-02, -5.0921e-02, -1.3586e-01,  6.1529e-02, -1.6755e-01,\n",
            "          1.2155e-01,  5.5066e-02, -1.0048e-01,  1.8947e-01,  1.1460e-01,\n",
            "          1.1254e-01, -3.1178e-03, -3.0175e-03, -1.0087e-01, -8.0817e-03,\n",
            "          6.3748e-03, -2.3625e-02, -2.9221e-02, -9.4227e-02],\n",
            "        [-8.8030e-02,  4.4791e-02, -1.4275e-01,  1.2185e-01, -9.9455e-02,\n",
            "         -1.4812e-01, -2.3699e-01, -7.5080e-02,  1.3385e-01, -9.7905e-02,\n",
            "          4.7397e-02, -2.7456e-01, -1.4125e-01,  3.6336e-02, -1.3590e-01,\n",
            "         -8.5423e-02, -5.4281e-02,  1.8237e-01,  5.1911e-02, -1.2305e-01,\n",
            "         -1.6228e-01, -1.9630e-01, -1.1666e-01,  8.8990e-02, -1.9312e-01,\n",
            "          7.4491e-03,  1.0965e-01,  3.9147e-02,  4.1901e-02, -3.0227e-01,\n",
            "         -2.1925e-01,  1.9131e-01, -7.1291e-04, -4.1714e-02,  1.2805e-01,\n",
            "          6.8660e-02,  3.2590e-02,  2.1558e-02, -6.8939e-02, -2.2284e-01,\n",
            "         -1.5666e-01,  3.4934e-02, -1.5571e-01, -7.0096e-02,  2.9952e-02,\n",
            "          5.6766e-02,  2.0466e-02, -1.6385e-02, -2.1642e-01,  1.2343e-01,\n",
            "          4.2198e-02,  1.4266e-01, -8.6312e-02,  3.5222e-02, -2.8075e-02,\n",
            "          1.3317e-01,  1.9045e-01, -7.6952e-02,  1.2839e-02, -2.2569e-02,\n",
            "         -8.7107e-02, -3.2407e-04,  8.0567e-02,  1.5460e-01]]), 'bias': tensor([-0.0511, -0.2006, -0.0133, -0.0142,  0.1217, -0.0243, -0.1196, -0.1175,\n",
            "         0.5232,  0.0088])}\n",
            "Nonce: 3870\n",
            "Previous Block Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "--------------\n",
            "==========================END OF CHAIN============================\n",
            "Peer 2\n",
            "\n",
            "--------------Block Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "BlockNo: 0\n",
            "Block Data: Genesis\n",
            "Nonce: 1176\n",
            "Previous Block Hash: 00000000000000000000000000000000\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "BlockNo: 1\n",
            "Block Data: {'layer': 'fc1', 'weight': tensor([[ 0.0329,  0.0086,  0.0243,  ...,  0.0497,  0.0563,  0.0528],\n",
            "        [-0.0129,  0.0104,  0.0365,  ...,  0.0194,  0.0207,  0.0246],\n",
            "        [ 0.0081,  0.0136, -0.0052,  ...,  0.0030,  0.0517,  0.0313],\n",
            "        ...,\n",
            "        [ 0.0393,  0.0300,  0.0377,  ...,  0.0255,  0.0073,  0.0581],\n",
            "        [ 0.0441,  0.0390,  0.0418,  ...,  0.0376, -0.0042,  0.0096],\n",
            "        [ 0.0226,  0.0080,  0.0011,  ..., -0.0116,  0.0461,  0.0215]]), 'bias': tensor([-5.0697e-02, -1.5882e-03, -4.5533e-02, -8.9822e-04, -7.9249e-02,\n",
            "         3.3151e-03, -3.6789e-02, -1.7230e-02, -5.2123e-02, -2.5209e-02,\n",
            "         8.5094e-03, -5.6987e-02, -2.2219e-02, -2.8807e-02, -1.7612e-02,\n",
            "         4.9885e-03, -1.4747e-03, -7.5809e-02,  1.5871e-02, -4.0564e-03,\n",
            "        -3.7250e-03, -4.6109e-02,  2.5242e-03,  4.4355e-03,  1.0314e-02,\n",
            "        -7.1663e-02,  9.1916e-03, -3.6697e-02, -3.8919e-02, -3.2340e-02,\n",
            "        -1.7095e-02, -2.2695e-02, -7.3756e-03, -3.2307e-03, -2.6671e-02,\n",
            "        -1.4188e-02, -5.8340e-03, -3.8018e-02, -3.0583e-02, -1.8098e-02,\n",
            "         2.1612e-02, -8.6132e-02, -2.3886e-02, -1.1493e-02, -8.3055e-03,\n",
            "        -1.7589e-03,  1.1987e-02, -4.2030e-02, -3.9615e-02,  4.4278e-03,\n",
            "        -1.7534e-02, -2.4694e-02, -2.1543e-02, -3.4609e-02,  2.3570e-02,\n",
            "         2.6285e-02, -1.3856e-02,  1.1432e-02, -2.7742e-02,  3.2082e-04,\n",
            "         4.6447e-03,  1.1198e-02, -1.5167e-02, -4.9473e-02, -4.2446e-02,\n",
            "         5.3062e-02, -6.3078e-02, -2.2603e-02, -1.0497e-02, -4.7284e-03,\n",
            "        -4.0333e-02,  4.8095e-03, -5.9835e-02,  5.7884e-03, -5.8095e-03,\n",
            "        -2.4915e-02, -1.1267e-02, -5.3225e-02,  1.0887e-02, -3.1268e-03,\n",
            "        -2.1667e-02, -5.2839e-02, -3.7480e-02, -2.9252e-02, -1.0288e-02,\n",
            "         9.7473e-03, -3.4331e-02, -2.6842e-02, -4.7752e-02, -4.4481e-03,\n",
            "        -5.0411e-02, -1.8064e-02, -2.4959e-02,  3.8707e-02, -2.3788e-02,\n",
            "        -3.0230e-02, -4.3937e-02, -3.9769e-02, -9.4580e-02,  4.1654e-02,\n",
            "        -3.5936e-02, -2.1148e-02,  1.7497e-02, -3.1961e-02, -2.3776e-02,\n",
            "        -3.7282e-02, -1.5092e-02,  9.8810e-03, -3.9213e-02, -3.9942e-02,\n",
            "        -5.6907e-02, -3.7442e-03, -9.5044e-02, -2.5293e-02, -2.5454e-02,\n",
            "        -4.7367e-02, -5.1332e-02, -2.0713e-03, -2.7323e-02,  5.7385e-03,\n",
            "        -1.9152e-02, -3.3860e-02, -4.8206e-02, -3.2334e-03, -5.0366e-02,\n",
            "        -3.5953e-02,  6.5205e-03, -2.6486e-02,  1.1088e-02, -2.8068e-02,\n",
            "        -7.4271e-02, -1.1911e-02,  1.2842e-02, -2.5225e-02, -3.1306e-02,\n",
            "        -1.9759e-02, -3.5803e-03,  2.0227e-03, -2.1660e-02,  1.1208e-02,\n",
            "        -2.4123e-02,  9.0310e-03, -5.1055e-02, -4.5396e-02, -2.6411e-02,\n",
            "         1.1292e-02,  1.4030e-02, -3.8358e-02, -3.2809e-02, -1.8572e-02,\n",
            "         4.8251e-02, -2.9928e-03, -7.2177e-02, -4.8035e-02,  7.6769e-03,\n",
            "        -6.5365e-02, -3.6413e-02, -1.1881e-02,  1.7021e-02, -1.1635e-02,\n",
            "        -6.0688e-02, -2.3924e-02, -4.9127e-02, -6.5620e-02, -4.3793e-02,\n",
            "        -4.4041e-02, -5.9561e-02, -2.9840e-02, -2.5970e-03, -4.9796e-02,\n",
            "        -1.1559e-02,  7.0239e-03, -3.5945e-02,  1.5993e-02, -4.1892e-02,\n",
            "        -6.8264e-02,  2.1650e-02, -4.1370e-02,  2.1973e-02, -1.5948e-02,\n",
            "        -1.0226e-01, -3.7496e-02,  1.7094e-02, -1.0982e-02,  1.5540e-02,\n",
            "        -5.0556e-02, -2.7001e-02, -2.0114e-02, -5.0169e-02, -2.9489e-02,\n",
            "        -3.9743e-02, -8.5380e-03, -1.8673e-02, -3.8129e-02, -2.1269e-02,\n",
            "        -2.5533e-02, -2.1255e-02, -1.3042e-02, -3.3605e-02, -1.3769e-02,\n",
            "        -2.9272e-02, -2.0493e-02,  6.1399e-03,  3.2051e-02, -2.2862e-02,\n",
            "        -4.3587e-02, -1.2302e-02, -6.0179e-03, -6.3411e-02, -1.3902e-04,\n",
            "         6.6006e-03, -6.3300e-02, -8.8990e-03, -4.0236e-03, -5.1070e-02,\n",
            "        -5.1127e-02, -3.9643e-02, -5.2284e-02, -4.6759e-02, -5.3112e-02,\n",
            "        -2.7392e-02, -2.9490e-02, -2.2758e-02, -9.5000e-03, -1.2496e-02,\n",
            "        -3.4707e-02, -1.4716e-02, -1.2888e-02, -1.2930e-03, -5.0056e-02,\n",
            "        -4.8036e-02, -3.2378e-02, -3.6429e-02, -3.8621e-02, -3.1510e-02,\n",
            "        -5.1300e-02,  1.4994e-02,  1.2208e-05, -1.4082e-02,  1.7620e-03,\n",
            "        -4.7165e-02, -3.7629e-02, -3.8766e-02,  9.4560e-03, -1.5576e-02,\n",
            "        -3.9815e-02,  1.1144e-02,  9.7832e-03, -1.2574e-02, -4.5413e-02,\n",
            "        -8.2680e-03, -2.0615e-02, -1.7477e-02, -4.7983e-02, -2.5950e-02,\n",
            "        -4.0306e-02])}\n",
            "Nonce: 2779\n",
            "Previous Block Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "BlockNo: 2\n",
            "Block Data: {'layer': 'fc2', 'weight': tensor([[ 0.0700,  0.0577, -0.0515,  ..., -0.0376, -0.0064, -0.0211],\n",
            "        [ 0.2691,  0.0488, -0.0146,  ...,  0.1431,  0.0142, -0.0360],\n",
            "        [ 0.1107,  0.0349,  0.0097,  ...,  0.0975, -0.0220,  0.0102],\n",
            "        ...,\n",
            "        [-0.0245,  0.0396, -0.0413,  ..., -0.0204, -0.0343,  0.0537],\n",
            "        [-0.0211,  0.0468, -0.0537,  ..., -0.1140,  0.0065,  0.0199],\n",
            "        [ 0.1608, -0.0083, -0.0337,  ...,  0.0963, -0.0206,  0.0148]]), 'bias': tensor([-0.0489,  0.1896,  0.1729, -0.1131, -0.1978,  0.0504, -0.0708, -0.1582,\n",
            "        -0.0030, -0.1288,  0.0108,  0.0125, -0.0415, -0.1031, -0.0630, -0.0025,\n",
            "        -0.1085, -0.0879, -0.0841,  0.3088,  0.1560,  0.0175, -0.2156, -0.1164,\n",
            "        -0.1923, -0.0915, -0.1100, -0.0354, -0.2318, -0.0061, -0.0592, -0.1969,\n",
            "        -0.0775, -0.1088, -0.1204, -0.1337, -0.2263,  0.1045, -0.1049, -0.1794,\n",
            "        -0.1485, -0.1131, -0.1346, -0.1471,  0.0449,  0.0613,  0.1513, -0.0190,\n",
            "        -0.0355, -0.1064,  0.2106, -0.1671,  0.0496,  0.0589, -0.1245, -0.1031,\n",
            "         0.0060, -0.0687, -0.1207, -0.0791,  0.0110, -0.1303,  0.0872, -0.0913,\n",
            "        -0.0502, -0.1575,  0.0946, -0.0620,  0.0189,  0.0400, -0.0242, -0.2191,\n",
            "        -0.1293, -0.1497,  0.1555,  0.2938, -0.0674, -0.3190, -0.0629, -0.1634,\n",
            "        -0.0147, -0.0193, -0.1928, -0.0061, -0.1173, -0.0514, -0.1626, -0.2278,\n",
            "        -0.0745, -0.0037, -0.0470, -0.0303, -0.1636, -0.1014,  0.1747, -0.0842,\n",
            "        -0.1578,  0.0232, -0.0125, -0.1983,  0.4642, -0.1431,  0.0178, -0.0420,\n",
            "        -0.0608, -0.0430, -0.0866,  0.0265, -0.0709,  0.0132,  0.0132, -0.1032,\n",
            "        -0.0352, -0.0149, -0.2466, -0.0685, -0.1978, -0.0966, -0.0275, -0.2409,\n",
            "         0.2949, -0.1386,  0.0520, -0.1878, -0.1932, -0.0528, -0.0524,  0.1045])}\n",
            "Nonce: 6875\n",
            "Previous Block Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "BlockNo: 3\n",
            "Block Data: {'layer': 'fc3', 'weight': tensor([[-0.0898,  0.0228, -0.0250,  ...,  0.0682, -0.1015, -0.0751],\n",
            "        [ 0.0142, -0.0617, -0.0568,  ..., -0.0338, -0.0558,  0.0405],\n",
            "        [-0.1508, -0.0901, -0.0380,  ...,  0.0528,  0.0925, -0.0676],\n",
            "        ...,\n",
            "        [ 0.0139,  0.0265, -0.1787,  ...,  0.0430,  0.0435, -0.0926],\n",
            "        [-0.0654, -0.0217, -0.1451,  ...,  0.0332, -0.0209, -0.1631],\n",
            "        [ 0.0609, -0.0105, -0.0566,  ...,  0.0403,  0.1513, -0.0428]]), 'bias': tensor([-0.1711, -0.1505, -0.1412,  0.0111, -0.0597,  0.1476, -0.0710, -0.0209,\n",
            "         0.1606,  0.2981,  0.1772, -0.2506, -0.0747, -0.2264, -0.2045, -0.3326,\n",
            "        -0.1356, -0.0518, -0.1744, -0.1427, -0.0377,  0.1834,  0.2696,  0.4100,\n",
            "        -0.2308, -0.2062, -0.0479,  0.0068, -0.1853,  0.1144, -0.1299,  0.1610,\n",
            "        -0.0101,  0.0754,  0.0926, -0.0319,  0.1107,  0.1191, -0.2281, -0.1523,\n",
            "        -0.2556, -0.1582, -0.0862, -0.0819, -0.0549,  0.1640, -0.1267, -0.0659,\n",
            "         0.0778, -0.0852, -0.0334,  0.2512, -0.0555,  0.2768,  0.0982,  0.3895,\n",
            "         0.1073, -0.1683,  0.0174, -0.0115,  0.2321, -0.3172, -0.1211,  0.0065])}\n",
            "Nonce: 4952\n",
            "Previous Block Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 000c7d81680ba960bc28b54930ce571c511bca021e1bef7efc4d487951494832\n",
            "BlockNo: 4\n",
            "Block Data: {'layer': 'fc4', 'weight': tensor([[-3.0591e-02,  3.4098e-02, -1.2472e-02, -8.9146e-03, -9.6389e-02,\n",
            "         -3.0413e-02, -2.2714e-02, -1.3556e-01,  6.6748e-02, -3.5200e-02,\n",
            "          1.7505e-01, -3.1370e-01,  1.0929e-01, -1.2965e-01, -2.6508e-01,\n",
            "         -4.6322e-03, -3.6083e-02,  1.6212e-01, -1.5626e-01,  9.0508e-03,\n",
            "          5.9090e-02, -1.5017e-01, -7.2761e-02,  1.0360e-01, -4.0878e-02,\n",
            "         -4.2697e-02, -2.6090e-01, -1.6544e-01, -2.2813e-01, -3.4041e-02,\n",
            "         -1.9108e-01, -2.0858e-01, -2.4329e-01,  2.5279e-02,  2.4480e-02,\n",
            "         -1.2921e-01,  6.6503e-03,  1.2826e-01, -1.9499e-01, -1.2286e-01,\n",
            "         -1.7484e-01,  2.2954e-02, -3.3802e-02,  1.6398e-01, -2.7393e-01,\n",
            "          4.4774e-02, -9.7249e-02, -2.8936e-02,  3.6314e-02,  1.2736e-01,\n",
            "         -8.5061e-02, -2.2160e-02, -4.3429e-03,  9.0347e-02, -4.5799e-02,\n",
            "         -2.9034e-01,  8.9424e-02, -1.3177e-01,  1.3366e-01, -1.0684e-01,\n",
            "          1.9650e-01,  2.1380e-02, -1.4263e-01, -1.2987e-01],\n",
            "        [ 8.0527e-02, -6.9936e-04, -1.8440e-01,  1.1717e-01, -3.7756e-01,\n",
            "         -6.7468e-02, -1.5667e-01, -2.0755e-01, -1.0310e-01,  7.1767e-02,\n",
            "         -2.0145e-01,  5.0998e-02,  8.0554e-02,  1.2831e-01, -2.6437e-01,\n",
            "         -3.8163e-01, -2.1519e-01, -1.3688e-01,  1.7053e-01, -9.2981e-03,\n",
            "         -4.9034e-01,  1.8303e-01, -6.3352e-02, -1.2537e-01, -9.2299e-02,\n",
            "         -4.9045e-02, -8.7175e-02,  1.0087e-01,  1.2594e-01, -5.7340e-02,\n",
            "          7.7662e-02,  1.2764e-01, -7.3948e-02,  9.9066e-02, -3.6424e-01,\n",
            "          1.6530e-01,  4.2991e-02, -3.7876e-04,  1.2653e-01, -9.9515e-02,\n",
            "         -1.6171e-01, -2.6207e-01,  1.2642e-01, -1.0301e-01, -3.8597e-02,\n",
            "         -2.5949e-01, -4.0102e-02, -1.6334e-01, -3.1535e-03,  9.5392e-02,\n",
            "          1.9991e-01, -2.1034e-01, -4.6928e-02,  2.9913e-03, -1.2064e-01,\n",
            "         -7.1262e-02, -2.4595e-01,  9.1223e-02,  6.6555e-03, -3.2185e-02,\n",
            "         -4.2523e-02, -1.1373e-01, -4.1103e-02, -2.2379e-02],\n",
            "        [-2.6639e-02, -4.9905e-02, -1.9280e-01, -8.7954e-02, -2.1338e-01,\n",
            "          1.7716e-01,  7.3641e-02, -8.6437e-02,  1.7046e-01, -1.2248e-01,\n",
            "         -7.8791e-02, -2.1608e-01, -4.4691e-02, -5.7541e-02,  6.5678e-02,\n",
            "         -1.5597e-01, -6.6167e-02,  1.4628e-01, -3.6590e-02, -7.6277e-02,\n",
            "          7.0731e-02,  1.2854e-01,  3.3084e-03, -2.1850e-01, -4.5549e-01,\n",
            "         -3.2332e-02,  1.7795e-02,  5.6002e-02, -1.4506e-01,  5.6319e-02,\n",
            "         -7.7656e-03, -2.1966e-01, -3.4202e-02, -5.8937e-02,  5.5518e-02,\n",
            "         -8.4144e-02, -8.6981e-02,  7.5757e-02,  1.1461e-01,  1.1005e-02,\n",
            "         -1.1787e-01, -1.6547e-01,  1.4386e-01, -7.4872e-02,  1.1260e-01,\n",
            "         -9.3629e-02,  4.8144e-02, -2.4308e-01,  1.8799e-02,  1.2744e-01,\n",
            "         -2.2816e-01,  4.7110e-02,  5.8897e-02,  9.6572e-02, -4.9287e-02,\n",
            "         -1.9062e-01, -3.4617e-03,  8.7256e-02,  1.7190e-01,  1.0175e-01,\n",
            "          9.3590e-02,  4.5341e-02,  2.4749e-02, -8.6945e-03],\n",
            "        [ 5.9198e-02, -1.4971e-01, -9.7188e-02, -1.2221e-01, -1.5573e-01,\n",
            "          1.5950e-01,  2.6218e-02,  8.2093e-03, -1.5829e-01, -2.3822e-01,\n",
            "          1.2463e-01, -1.1859e-01, -7.6052e-02,  1.9792e-02,  9.6583e-02,\n",
            "         -1.9772e-01, -6.2933e-02,  1.9615e-02,  1.4603e-01,  1.7161e-02,\n",
            "          3.7421e-02, -8.3916e-02,  9.4765e-02,  6.9403e-02, -1.7282e-01,\n",
            "         -4.0344e-03, -3.3327e-01, -8.5024e-02,  3.8942e-02, -5.6872e-02,\n",
            "         -9.1727e-02,  1.1133e-02, -1.5001e-01, -2.1141e-02, -1.0731e-01,\n",
            "         -9.3394e-02, -1.5909e-02,  7.1904e-02,  1.6437e-01, -5.1592e-02,\n",
            "         -2.1686e-01,  9.9757e-02, -2.0598e-02, -2.8799e-01,  1.4090e-01,\n",
            "         -1.1475e-02, -2.2539e-01, -6.3897e-02,  1.4890e-01,  6.4978e-02,\n",
            "         -5.7421e-02, -6.9976e-02,  7.4733e-02,  1.9975e-01, -1.3631e-01,\n",
            "          1.2692e-01,  2.9700e-02, -1.4718e-02,  5.1793e-03, -2.9027e-02,\n",
            "         -1.5312e-01,  2.0889e-02, -1.6939e-01, -4.4671e-02],\n",
            "        [ 1.3601e-02,  3.4387e-02, -1.3839e-01,  1.3523e-01, -2.2648e-01,\n",
            "         -1.1276e-01, -5.7338e-02, -6.2247e-02,  1.3348e-01, -5.2199e-03,\n",
            "          8.8016e-02, -5.2034e-02, -8.9455e-02,  9.6045e-03, -1.6267e-01,\n",
            "         -1.0997e-01, -1.5902e-01, -9.8831e-02,  3.3417e-02, -1.3838e-02,\n",
            "          6.3099e-02,  3.4767e-02, -1.9705e-01,  4.2852e-03, -2.5631e-01,\n",
            "          2.1715e-02,  1.4374e-02, -2.6716e-02,  3.3939e-03, -2.1987e-01,\n",
            "         -9.5788e-02,  1.6396e-01,  1.7821e-02,  1.0946e-02,  1.4986e-01,\n",
            "          9.2288e-02, -1.0144e-01, -1.8618e-02, -1.2044e-04, -1.2222e-01,\n",
            "         -5.6505e-02, -2.0812e-01, -2.6812e-02, -1.8149e-01,  1.0401e-01,\n",
            "         -5.4234e-02,  1.8465e-02,  9.2364e-02, -8.0603e-03,  4.0180e-02,\n",
            "         -3.0521e-02,  9.8548e-02, -2.2265e-01, -1.0132e-01,  1.0515e-01,\n",
            "          6.8693e-02, -1.8465e-01,  3.3156e-02, -5.4205e-02,  2.1594e-01,\n",
            "          8.0506e-02, -3.4505e-02, -1.5035e-01,  7.2493e-02],\n",
            "        [-1.5107e-02, -1.7190e-01, -2.5686e-02, -2.0609e-01,  2.4864e-02,\n",
            "          6.2660e-03, -1.1918e-01,  2.0434e-02, -9.6026e-02, -4.8028e-02,\n",
            "         -1.2094e-01, -1.0661e-01, -8.2729e-02,  4.1797e-02, -9.0162e-02,\n",
            "         -4.6264e-02,  1.8812e-01,  8.3817e-02,  1.1808e-01, -7.0366e-03,\n",
            "         -5.1755e-02, -4.5842e-02,  8.8472e-02,  7.0996e-03, -1.5127e-01,\n",
            "          5.1642e-03, -1.2410e-01, -8.3846e-02,  1.4713e-03, -2.3384e-02,\n",
            "          9.8134e-02,  2.3282e-02,  1.3950e-01, -1.6195e-01,  5.5275e-02,\n",
            "         -1.8728e-02,  1.5886e-01,  6.4935e-02, -1.1813e-01, -1.1567e-01,\n",
            "         -1.5507e-01,  1.0447e-01, -2.9090e-02,  4.4763e-03,  9.7352e-02,\n",
            "          1.1801e-01, -1.3295e-01,  4.4080e-02,  3.5852e-02, -9.3856e-02,\n",
            "         -2.5354e-03,  1.4111e-02,  8.6333e-04, -1.0574e-01, -7.3117e-02,\n",
            "          5.2291e-02, -7.2708e-03,  1.1661e-01, -7.5096e-02, -1.6445e-01,\n",
            "         -9.4599e-02, -1.4393e-01,  9.2639e-02, -1.0104e-01],\n",
            "        [-9.2999e-02,  3.2939e-02,  7.7569e-02,  1.2329e-01,  6.8271e-02,\n",
            "         -5.7074e-02, -9.7534e-02,  1.0594e-01, -1.8849e-01,  1.0334e-01,\n",
            "          1.4596e-01, -1.2874e-01,  1.8499e-02, -2.5217e-01, -3.7181e-01,\n",
            "         -8.4419e-02,  2.5565e-02, -8.0157e-02, -4.5190e-02,  4.6831e-03,\n",
            "          8.4701e-03, -2.4271e-02, -1.3587e-01,  1.8156e-01, -2.2558e-01,\n",
            "         -3.1215e-02, -3.8632e-01, -2.0433e-01, -2.0086e-01, -1.9205e-01,\n",
            "         -2.1231e-02, -1.4768e-01,  1.3509e-01,  7.8970e-02, -2.7377e-02,\n",
            "         -3.4304e-02,  1.5141e-01, -1.8696e-01, -9.3842e-02,  8.0565e-02,\n",
            "         -2.5625e-01, -5.1263e-02,  1.6240e-01, -1.0645e-01, -3.5994e-02,\n",
            "         -4.1154e-02,  1.9525e-02,  5.6315e-02,  1.8552e-01, -1.0291e-01,\n",
            "         -4.7442e-03,  2.8336e-02, -5.3458e-02, -2.9615e-01, -7.4837e-02,\n",
            "         -1.4042e-01, -4.0359e-01, -1.5856e-02, -2.2115e-01,  4.3629e-03,\n",
            "          7.6001e-02, -1.6410e-01, -5.1871e-02, -8.2789e-02],\n",
            "        [-1.8239e-03,  3.5877e-02, -4.2871e-02,  9.6933e-02, -6.5738e-02,\n",
            "         -9.5464e-02, -2.2584e-01, -2.1874e-02, -1.3169e-01, -1.0763e-01,\n",
            "         -2.9869e-01, -2.4803e-01, -1.0345e-01,  9.4159e-02,  1.2660e-01,\n",
            "          7.4724e-02, -1.7667e-01, -6.6567e-02,  1.2672e-01, -4.3086e-02,\n",
            "         -2.6427e-01,  5.4197e-02, -1.8951e-01, -1.4216e-01,  5.9037e-04,\n",
            "          3.8746e-02,  1.7537e-02,  1.9705e-01, -2.0985e-01, -9.0419e-02,\n",
            "         -1.9331e-01, -2.6807e-02, -7.3848e-02, -2.4975e-01,  3.3268e-02,\n",
            "         -8.3329e-02, -9.7251e-02,  2.0017e-02,  2.1676e-01, -1.8951e-01,\n",
            "         -3.0675e-02,  1.5512e-02,  2.8178e-02,  1.7990e-01, -3.5415e-02,\n",
            "         -1.8663e-01,  7.4498e-02,  3.1793e-02,  9.6635e-02,  1.7503e-02,\n",
            "         -6.1472e-02, -1.0570e-01,  4.2936e-02,  7.0300e-02, -8.3744e-02,\n",
            "          4.0475e-02,  1.2125e-01, -2.5267e-01,  1.1248e-01,  1.2021e-01,\n",
            "         -2.5559e-01, -1.4190e-01, -2.0342e-02,  1.4038e-01],\n",
            "        [-1.0926e-01,  3.6893e-03, -6.8264e-03, -3.8456e-02, -1.7640e-01,\n",
            "          4.7644e-02, -1.5130e-01, -2.5377e-02, -1.0458e-01,  1.5831e-01,\n",
            "         -1.4367e-01, -2.2789e-01,  5.8957e-03, -1.2621e-01, -1.1740e-01,\n",
            "         -1.6444e-01, -7.8225e-02, -1.3360e-01, -4.0109e-02,  3.9534e-02,\n",
            "         -4.8940e-03,  5.0944e-02,  1.0072e-01,  8.4909e-02, -2.0891e-02,\n",
            "          6.8689e-02, -1.2404e-01,  4.1738e-02, -1.9037e-01, -7.3585e-02,\n",
            "          1.0875e-01, -1.8278e-02, -4.9892e-02,  1.3167e-01, -7.3981e-02,\n",
            "          4.9814e-02,  9.5502e-02,  8.7666e-02, -1.1627e-03,  2.6633e-02,\n",
            "         -9.4880e-01, -1.6348e-01, -2.1192e-01, -4.6418e-02, -2.0423e-01,\n",
            "          9.1853e-02, -5.0921e-02, -1.3586e-01,  6.1529e-02, -1.6755e-01,\n",
            "          1.2155e-01,  5.5066e-02, -1.0048e-01,  1.8947e-01,  1.1460e-01,\n",
            "          1.1254e-01, -3.1178e-03, -3.0175e-03, -1.0087e-01, -8.0817e-03,\n",
            "          6.3748e-03, -2.3625e-02, -2.9221e-02, -9.4227e-02],\n",
            "        [-8.8030e-02,  4.4791e-02, -1.4275e-01,  1.2185e-01, -9.9455e-02,\n",
            "         -1.4812e-01, -2.3699e-01, -7.5080e-02,  1.3385e-01, -9.7905e-02,\n",
            "          4.7397e-02, -2.7456e-01, -1.4125e-01,  3.6336e-02, -1.3590e-01,\n",
            "         -8.5423e-02, -5.4281e-02,  1.8237e-01,  5.1911e-02, -1.2305e-01,\n",
            "         -1.6228e-01, -1.9630e-01, -1.1666e-01,  8.8990e-02, -1.9312e-01,\n",
            "          7.4491e-03,  1.0965e-01,  3.9147e-02,  4.1901e-02, -3.0227e-01,\n",
            "         -2.1925e-01,  1.9131e-01, -7.1291e-04, -4.1714e-02,  1.2805e-01,\n",
            "          6.8660e-02,  3.2590e-02,  2.1558e-02, -6.8939e-02, -2.2284e-01,\n",
            "         -1.5666e-01,  3.4934e-02, -1.5571e-01, -7.0096e-02,  2.9952e-02,\n",
            "          5.6766e-02,  2.0466e-02, -1.6385e-02, -2.1642e-01,  1.2343e-01,\n",
            "          4.2198e-02,  1.4266e-01, -8.6312e-02,  3.5222e-02, -2.8075e-02,\n",
            "          1.3317e-01,  1.9045e-01, -7.6952e-02,  1.2839e-02, -2.2569e-02,\n",
            "         -8.7107e-02, -3.2407e-04,  8.0567e-02,  1.5460e-01]]), 'bias': tensor([-0.0511, -0.2006, -0.0133, -0.0142,  0.1217, -0.0243, -0.1196, -0.1175,\n",
            "         0.5232,  0.0088])}\n",
            "Nonce: 3870\n",
            "Previous Block Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "--------------\n",
            "==========================END OF CHAIN============================\n",
            "Peer 3\n",
            "\n",
            "--------------Block Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "BlockNo: 0\n",
            "Block Data: Genesis\n",
            "Nonce: 1176\n",
            "Previous Block Hash: 00000000000000000000000000000000\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "BlockNo: 1\n",
            "Block Data: {'layer': 'fc1', 'weight': tensor([[ 0.0329,  0.0086,  0.0243,  ...,  0.0497,  0.0563,  0.0528],\n",
            "        [-0.0129,  0.0104,  0.0365,  ...,  0.0194,  0.0207,  0.0246],\n",
            "        [ 0.0081,  0.0136, -0.0052,  ...,  0.0030,  0.0517,  0.0313],\n",
            "        ...,\n",
            "        [ 0.0393,  0.0300,  0.0377,  ...,  0.0255,  0.0073,  0.0581],\n",
            "        [ 0.0441,  0.0390,  0.0418,  ...,  0.0376, -0.0042,  0.0096],\n",
            "        [ 0.0226,  0.0080,  0.0011,  ..., -0.0116,  0.0461,  0.0215]]), 'bias': tensor([-5.0697e-02, -1.5882e-03, -4.5533e-02, -8.9822e-04, -7.9249e-02,\n",
            "         3.3151e-03, -3.6789e-02, -1.7230e-02, -5.2123e-02, -2.5209e-02,\n",
            "         8.5094e-03, -5.6987e-02, -2.2219e-02, -2.8807e-02, -1.7612e-02,\n",
            "         4.9885e-03, -1.4747e-03, -7.5809e-02,  1.5871e-02, -4.0564e-03,\n",
            "        -3.7250e-03, -4.6109e-02,  2.5242e-03,  4.4355e-03,  1.0314e-02,\n",
            "        -7.1663e-02,  9.1916e-03, -3.6697e-02, -3.8919e-02, -3.2340e-02,\n",
            "        -1.7095e-02, -2.2695e-02, -7.3756e-03, -3.2307e-03, -2.6671e-02,\n",
            "        -1.4188e-02, -5.8340e-03, -3.8018e-02, -3.0583e-02, -1.8098e-02,\n",
            "         2.1612e-02, -8.6132e-02, -2.3886e-02, -1.1493e-02, -8.3055e-03,\n",
            "        -1.7589e-03,  1.1987e-02, -4.2030e-02, -3.9615e-02,  4.4278e-03,\n",
            "        -1.7534e-02, -2.4694e-02, -2.1543e-02, -3.4609e-02,  2.3570e-02,\n",
            "         2.6285e-02, -1.3856e-02,  1.1432e-02, -2.7742e-02,  3.2082e-04,\n",
            "         4.6447e-03,  1.1198e-02, -1.5167e-02, -4.9473e-02, -4.2446e-02,\n",
            "         5.3062e-02, -6.3078e-02, -2.2603e-02, -1.0497e-02, -4.7284e-03,\n",
            "        -4.0333e-02,  4.8095e-03, -5.9835e-02,  5.7884e-03, -5.8095e-03,\n",
            "        -2.4915e-02, -1.1267e-02, -5.3225e-02,  1.0887e-02, -3.1268e-03,\n",
            "        -2.1667e-02, -5.2839e-02, -3.7480e-02, -2.9252e-02, -1.0288e-02,\n",
            "         9.7473e-03, -3.4331e-02, -2.6842e-02, -4.7752e-02, -4.4481e-03,\n",
            "        -5.0411e-02, -1.8064e-02, -2.4959e-02,  3.8707e-02, -2.3788e-02,\n",
            "        -3.0230e-02, -4.3937e-02, -3.9769e-02, -9.4580e-02,  4.1654e-02,\n",
            "        -3.5936e-02, -2.1148e-02,  1.7497e-02, -3.1961e-02, -2.3776e-02,\n",
            "        -3.7282e-02, -1.5092e-02,  9.8810e-03, -3.9213e-02, -3.9942e-02,\n",
            "        -5.6907e-02, -3.7442e-03, -9.5044e-02, -2.5293e-02, -2.5454e-02,\n",
            "        -4.7367e-02, -5.1332e-02, -2.0713e-03, -2.7323e-02,  5.7385e-03,\n",
            "        -1.9152e-02, -3.3860e-02, -4.8206e-02, -3.2334e-03, -5.0366e-02,\n",
            "        -3.5953e-02,  6.5205e-03, -2.6486e-02,  1.1088e-02, -2.8068e-02,\n",
            "        -7.4271e-02, -1.1911e-02,  1.2842e-02, -2.5225e-02, -3.1306e-02,\n",
            "        -1.9759e-02, -3.5803e-03,  2.0227e-03, -2.1660e-02,  1.1208e-02,\n",
            "        -2.4123e-02,  9.0310e-03, -5.1055e-02, -4.5396e-02, -2.6411e-02,\n",
            "         1.1292e-02,  1.4030e-02, -3.8358e-02, -3.2809e-02, -1.8572e-02,\n",
            "         4.8251e-02, -2.9928e-03, -7.2177e-02, -4.8035e-02,  7.6769e-03,\n",
            "        -6.5365e-02, -3.6413e-02, -1.1881e-02,  1.7021e-02, -1.1635e-02,\n",
            "        -6.0688e-02, -2.3924e-02, -4.9127e-02, -6.5620e-02, -4.3793e-02,\n",
            "        -4.4041e-02, -5.9561e-02, -2.9840e-02, -2.5970e-03, -4.9796e-02,\n",
            "        -1.1559e-02,  7.0239e-03, -3.5945e-02,  1.5993e-02, -4.1892e-02,\n",
            "        -6.8264e-02,  2.1650e-02, -4.1370e-02,  2.1973e-02, -1.5948e-02,\n",
            "        -1.0226e-01, -3.7496e-02,  1.7094e-02, -1.0982e-02,  1.5540e-02,\n",
            "        -5.0556e-02, -2.7001e-02, -2.0114e-02, -5.0169e-02, -2.9489e-02,\n",
            "        -3.9743e-02, -8.5380e-03, -1.8673e-02, -3.8129e-02, -2.1269e-02,\n",
            "        -2.5533e-02, -2.1255e-02, -1.3042e-02, -3.3605e-02, -1.3769e-02,\n",
            "        -2.9272e-02, -2.0493e-02,  6.1399e-03,  3.2051e-02, -2.2862e-02,\n",
            "        -4.3587e-02, -1.2302e-02, -6.0179e-03, -6.3411e-02, -1.3902e-04,\n",
            "         6.6006e-03, -6.3300e-02, -8.8990e-03, -4.0236e-03, -5.1070e-02,\n",
            "        -5.1127e-02, -3.9643e-02, -5.2284e-02, -4.6759e-02, -5.3112e-02,\n",
            "        -2.7392e-02, -2.9490e-02, -2.2758e-02, -9.5000e-03, -1.2496e-02,\n",
            "        -3.4707e-02, -1.4716e-02, -1.2888e-02, -1.2930e-03, -5.0056e-02,\n",
            "        -4.8036e-02, -3.2378e-02, -3.6429e-02, -3.8621e-02, -3.1510e-02,\n",
            "        -5.1300e-02,  1.4994e-02,  1.2208e-05, -1.4082e-02,  1.7620e-03,\n",
            "        -4.7165e-02, -3.7629e-02, -3.8766e-02,  9.4560e-03, -1.5576e-02,\n",
            "        -3.9815e-02,  1.1144e-02,  9.7832e-03, -1.2574e-02, -4.5413e-02,\n",
            "        -8.2680e-03, -2.0615e-02, -1.7477e-02, -4.7983e-02, -2.5950e-02,\n",
            "        -4.0306e-02])}\n",
            "Nonce: 2779\n",
            "Previous Block Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "BlockNo: 2\n",
            "Block Data: {'layer': 'fc2', 'weight': tensor([[ 0.0700,  0.0577, -0.0515,  ..., -0.0376, -0.0064, -0.0211],\n",
            "        [ 0.2691,  0.0488, -0.0146,  ...,  0.1431,  0.0142, -0.0360],\n",
            "        [ 0.1107,  0.0349,  0.0097,  ...,  0.0975, -0.0220,  0.0102],\n",
            "        ...,\n",
            "        [-0.0245,  0.0396, -0.0413,  ..., -0.0204, -0.0343,  0.0537],\n",
            "        [-0.0211,  0.0468, -0.0537,  ..., -0.1140,  0.0065,  0.0199],\n",
            "        [ 0.1608, -0.0083, -0.0337,  ...,  0.0963, -0.0206,  0.0148]]), 'bias': tensor([-0.0489,  0.1896,  0.1729, -0.1131, -0.1978,  0.0504, -0.0708, -0.1582,\n",
            "        -0.0030, -0.1288,  0.0108,  0.0125, -0.0415, -0.1031, -0.0630, -0.0025,\n",
            "        -0.1085, -0.0879, -0.0841,  0.3088,  0.1560,  0.0175, -0.2156, -0.1164,\n",
            "        -0.1923, -0.0915, -0.1100, -0.0354, -0.2318, -0.0061, -0.0592, -0.1969,\n",
            "        -0.0775, -0.1088, -0.1204, -0.1337, -0.2263,  0.1045, -0.1049, -0.1794,\n",
            "        -0.1485, -0.1131, -0.1346, -0.1471,  0.0449,  0.0613,  0.1513, -0.0190,\n",
            "        -0.0355, -0.1064,  0.2106, -0.1671,  0.0496,  0.0589, -0.1245, -0.1031,\n",
            "         0.0060, -0.0687, -0.1207, -0.0791,  0.0110, -0.1303,  0.0872, -0.0913,\n",
            "        -0.0502, -0.1575,  0.0946, -0.0620,  0.0189,  0.0400, -0.0242, -0.2191,\n",
            "        -0.1293, -0.1497,  0.1555,  0.2938, -0.0674, -0.3190, -0.0629, -0.1634,\n",
            "        -0.0147, -0.0193, -0.1928, -0.0061, -0.1173, -0.0514, -0.1626, -0.2278,\n",
            "        -0.0745, -0.0037, -0.0470, -0.0303, -0.1636, -0.1014,  0.1747, -0.0842,\n",
            "        -0.1578,  0.0232, -0.0125, -0.1983,  0.4642, -0.1431,  0.0178, -0.0420,\n",
            "        -0.0608, -0.0430, -0.0866,  0.0265, -0.0709,  0.0132,  0.0132, -0.1032,\n",
            "        -0.0352, -0.0149, -0.2466, -0.0685, -0.1978, -0.0966, -0.0275, -0.2409,\n",
            "         0.2949, -0.1386,  0.0520, -0.1878, -0.1932, -0.0528, -0.0524,  0.1045])}\n",
            "Nonce: 6875\n",
            "Previous Block Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "BlockNo: 3\n",
            "Block Data: {'layer': 'fc3', 'weight': tensor([[-0.0898,  0.0228, -0.0250,  ...,  0.0682, -0.1015, -0.0751],\n",
            "        [ 0.0142, -0.0617, -0.0568,  ..., -0.0338, -0.0558,  0.0405],\n",
            "        [-0.1508, -0.0901, -0.0380,  ...,  0.0528,  0.0925, -0.0676],\n",
            "        ...,\n",
            "        [ 0.0139,  0.0265, -0.1787,  ...,  0.0430,  0.0435, -0.0926],\n",
            "        [-0.0654, -0.0217, -0.1451,  ...,  0.0332, -0.0209, -0.1631],\n",
            "        [ 0.0609, -0.0105, -0.0566,  ...,  0.0403,  0.1513, -0.0428]]), 'bias': tensor([-0.1711, -0.1505, -0.1412,  0.0111, -0.0597,  0.1476, -0.0710, -0.0209,\n",
            "         0.1606,  0.2981,  0.1772, -0.2506, -0.0747, -0.2264, -0.2045, -0.3326,\n",
            "        -0.1356, -0.0518, -0.1744, -0.1427, -0.0377,  0.1834,  0.2696,  0.4100,\n",
            "        -0.2308, -0.2062, -0.0479,  0.0068, -0.1853,  0.1144, -0.1299,  0.1610,\n",
            "        -0.0101,  0.0754,  0.0926, -0.0319,  0.1107,  0.1191, -0.2281, -0.1523,\n",
            "        -0.2556, -0.1582, -0.0862, -0.0819, -0.0549,  0.1640, -0.1267, -0.0659,\n",
            "         0.0778, -0.0852, -0.0334,  0.2512, -0.0555,  0.2768,  0.0982,  0.3895,\n",
            "         0.1073, -0.1683,  0.0174, -0.0115,  0.2321, -0.3172, -0.1211,  0.0065])}\n",
            "Nonce: 4952\n",
            "Previous Block Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 000c7d81680ba960bc28b54930ce571c511bca021e1bef7efc4d487951494832\n",
            "BlockNo: 4\n",
            "Block Data: {'layer': 'fc4', 'weight': tensor([[-3.0591e-02,  3.4098e-02, -1.2472e-02, -8.9146e-03, -9.6389e-02,\n",
            "         -3.0413e-02, -2.2714e-02, -1.3556e-01,  6.6748e-02, -3.5200e-02,\n",
            "          1.7505e-01, -3.1370e-01,  1.0929e-01, -1.2965e-01, -2.6508e-01,\n",
            "         -4.6322e-03, -3.6083e-02,  1.6212e-01, -1.5626e-01,  9.0508e-03,\n",
            "          5.9090e-02, -1.5017e-01, -7.2761e-02,  1.0360e-01, -4.0878e-02,\n",
            "         -4.2697e-02, -2.6090e-01, -1.6544e-01, -2.2813e-01, -3.4041e-02,\n",
            "         -1.9108e-01, -2.0858e-01, -2.4329e-01,  2.5279e-02,  2.4480e-02,\n",
            "         -1.2921e-01,  6.6503e-03,  1.2826e-01, -1.9499e-01, -1.2286e-01,\n",
            "         -1.7484e-01,  2.2954e-02, -3.3802e-02,  1.6398e-01, -2.7393e-01,\n",
            "          4.4774e-02, -9.7249e-02, -2.8936e-02,  3.6314e-02,  1.2736e-01,\n",
            "         -8.5061e-02, -2.2160e-02, -4.3429e-03,  9.0347e-02, -4.5799e-02,\n",
            "         -2.9034e-01,  8.9424e-02, -1.3177e-01,  1.3366e-01, -1.0684e-01,\n",
            "          1.9650e-01,  2.1380e-02, -1.4263e-01, -1.2987e-01],\n",
            "        [ 8.0527e-02, -6.9936e-04, -1.8440e-01,  1.1717e-01, -3.7756e-01,\n",
            "         -6.7468e-02, -1.5667e-01, -2.0755e-01, -1.0310e-01,  7.1767e-02,\n",
            "         -2.0145e-01,  5.0998e-02,  8.0554e-02,  1.2831e-01, -2.6437e-01,\n",
            "         -3.8163e-01, -2.1519e-01, -1.3688e-01,  1.7053e-01, -9.2981e-03,\n",
            "         -4.9034e-01,  1.8303e-01, -6.3352e-02, -1.2537e-01, -9.2299e-02,\n",
            "         -4.9045e-02, -8.7175e-02,  1.0087e-01,  1.2594e-01, -5.7340e-02,\n",
            "          7.7662e-02,  1.2764e-01, -7.3948e-02,  9.9066e-02, -3.6424e-01,\n",
            "          1.6530e-01,  4.2991e-02, -3.7876e-04,  1.2653e-01, -9.9515e-02,\n",
            "         -1.6171e-01, -2.6207e-01,  1.2642e-01, -1.0301e-01, -3.8597e-02,\n",
            "         -2.5949e-01, -4.0102e-02, -1.6334e-01, -3.1535e-03,  9.5392e-02,\n",
            "          1.9991e-01, -2.1034e-01, -4.6928e-02,  2.9913e-03, -1.2064e-01,\n",
            "         -7.1262e-02, -2.4595e-01,  9.1223e-02,  6.6555e-03, -3.2185e-02,\n",
            "         -4.2523e-02, -1.1373e-01, -4.1103e-02, -2.2379e-02],\n",
            "        [-2.6639e-02, -4.9905e-02, -1.9280e-01, -8.7954e-02, -2.1338e-01,\n",
            "          1.7716e-01,  7.3641e-02, -8.6437e-02,  1.7046e-01, -1.2248e-01,\n",
            "         -7.8791e-02, -2.1608e-01, -4.4691e-02, -5.7541e-02,  6.5678e-02,\n",
            "         -1.5597e-01, -6.6167e-02,  1.4628e-01, -3.6590e-02, -7.6277e-02,\n",
            "          7.0731e-02,  1.2854e-01,  3.3084e-03, -2.1850e-01, -4.5549e-01,\n",
            "         -3.2332e-02,  1.7795e-02,  5.6002e-02, -1.4506e-01,  5.6319e-02,\n",
            "         -7.7656e-03, -2.1966e-01, -3.4202e-02, -5.8937e-02,  5.5518e-02,\n",
            "         -8.4144e-02, -8.6981e-02,  7.5757e-02,  1.1461e-01,  1.1005e-02,\n",
            "         -1.1787e-01, -1.6547e-01,  1.4386e-01, -7.4872e-02,  1.1260e-01,\n",
            "         -9.3629e-02,  4.8144e-02, -2.4308e-01,  1.8799e-02,  1.2744e-01,\n",
            "         -2.2816e-01,  4.7110e-02,  5.8897e-02,  9.6572e-02, -4.9287e-02,\n",
            "         -1.9062e-01, -3.4617e-03,  8.7256e-02,  1.7190e-01,  1.0175e-01,\n",
            "          9.3590e-02,  4.5341e-02,  2.4749e-02, -8.6945e-03],\n",
            "        [ 5.9198e-02, -1.4971e-01, -9.7188e-02, -1.2221e-01, -1.5573e-01,\n",
            "          1.5950e-01,  2.6218e-02,  8.2093e-03, -1.5829e-01, -2.3822e-01,\n",
            "          1.2463e-01, -1.1859e-01, -7.6052e-02,  1.9792e-02,  9.6583e-02,\n",
            "         -1.9772e-01, -6.2933e-02,  1.9615e-02,  1.4603e-01,  1.7161e-02,\n",
            "          3.7421e-02, -8.3916e-02,  9.4765e-02,  6.9403e-02, -1.7282e-01,\n",
            "         -4.0344e-03, -3.3327e-01, -8.5024e-02,  3.8942e-02, -5.6872e-02,\n",
            "         -9.1727e-02,  1.1133e-02, -1.5001e-01, -2.1141e-02, -1.0731e-01,\n",
            "         -9.3394e-02, -1.5909e-02,  7.1904e-02,  1.6437e-01, -5.1592e-02,\n",
            "         -2.1686e-01,  9.9757e-02, -2.0598e-02, -2.8799e-01,  1.4090e-01,\n",
            "         -1.1475e-02, -2.2539e-01, -6.3897e-02,  1.4890e-01,  6.4978e-02,\n",
            "         -5.7421e-02, -6.9976e-02,  7.4733e-02,  1.9975e-01, -1.3631e-01,\n",
            "          1.2692e-01,  2.9700e-02, -1.4718e-02,  5.1793e-03, -2.9027e-02,\n",
            "         -1.5312e-01,  2.0889e-02, -1.6939e-01, -4.4671e-02],\n",
            "        [ 1.3601e-02,  3.4387e-02, -1.3839e-01,  1.3523e-01, -2.2648e-01,\n",
            "         -1.1276e-01, -5.7338e-02, -6.2247e-02,  1.3348e-01, -5.2199e-03,\n",
            "          8.8016e-02, -5.2034e-02, -8.9455e-02,  9.6045e-03, -1.6267e-01,\n",
            "         -1.0997e-01, -1.5902e-01, -9.8831e-02,  3.3417e-02, -1.3838e-02,\n",
            "          6.3099e-02,  3.4767e-02, -1.9705e-01,  4.2852e-03, -2.5631e-01,\n",
            "          2.1715e-02,  1.4374e-02, -2.6716e-02,  3.3939e-03, -2.1987e-01,\n",
            "         -9.5788e-02,  1.6396e-01,  1.7821e-02,  1.0946e-02,  1.4986e-01,\n",
            "          9.2288e-02, -1.0144e-01, -1.8618e-02, -1.2044e-04, -1.2222e-01,\n",
            "         -5.6505e-02, -2.0812e-01, -2.6812e-02, -1.8149e-01,  1.0401e-01,\n",
            "         -5.4234e-02,  1.8465e-02,  9.2364e-02, -8.0603e-03,  4.0180e-02,\n",
            "         -3.0521e-02,  9.8548e-02, -2.2265e-01, -1.0132e-01,  1.0515e-01,\n",
            "          6.8693e-02, -1.8465e-01,  3.3156e-02, -5.4205e-02,  2.1594e-01,\n",
            "          8.0506e-02, -3.4505e-02, -1.5035e-01,  7.2493e-02],\n",
            "        [-1.5107e-02, -1.7190e-01, -2.5686e-02, -2.0609e-01,  2.4864e-02,\n",
            "          6.2660e-03, -1.1918e-01,  2.0434e-02, -9.6026e-02, -4.8028e-02,\n",
            "         -1.2094e-01, -1.0661e-01, -8.2729e-02,  4.1797e-02, -9.0162e-02,\n",
            "         -4.6264e-02,  1.8812e-01,  8.3817e-02,  1.1808e-01, -7.0366e-03,\n",
            "         -5.1755e-02, -4.5842e-02,  8.8472e-02,  7.0996e-03, -1.5127e-01,\n",
            "          5.1642e-03, -1.2410e-01, -8.3846e-02,  1.4713e-03, -2.3384e-02,\n",
            "          9.8134e-02,  2.3282e-02,  1.3950e-01, -1.6195e-01,  5.5275e-02,\n",
            "         -1.8728e-02,  1.5886e-01,  6.4935e-02, -1.1813e-01, -1.1567e-01,\n",
            "         -1.5507e-01,  1.0447e-01, -2.9090e-02,  4.4763e-03,  9.7352e-02,\n",
            "          1.1801e-01, -1.3295e-01,  4.4080e-02,  3.5852e-02, -9.3856e-02,\n",
            "         -2.5354e-03,  1.4111e-02,  8.6333e-04, -1.0574e-01, -7.3117e-02,\n",
            "          5.2291e-02, -7.2708e-03,  1.1661e-01, -7.5096e-02, -1.6445e-01,\n",
            "         -9.4599e-02, -1.4393e-01,  9.2639e-02, -1.0104e-01],\n",
            "        [-9.2999e-02,  3.2939e-02,  7.7569e-02,  1.2329e-01,  6.8271e-02,\n",
            "         -5.7074e-02, -9.7534e-02,  1.0594e-01, -1.8849e-01,  1.0334e-01,\n",
            "          1.4596e-01, -1.2874e-01,  1.8499e-02, -2.5217e-01, -3.7181e-01,\n",
            "         -8.4419e-02,  2.5565e-02, -8.0157e-02, -4.5190e-02,  4.6831e-03,\n",
            "          8.4701e-03, -2.4271e-02, -1.3587e-01,  1.8156e-01, -2.2558e-01,\n",
            "         -3.1215e-02, -3.8632e-01, -2.0433e-01, -2.0086e-01, -1.9205e-01,\n",
            "         -2.1231e-02, -1.4768e-01,  1.3509e-01,  7.8970e-02, -2.7377e-02,\n",
            "         -3.4304e-02,  1.5141e-01, -1.8696e-01, -9.3842e-02,  8.0565e-02,\n",
            "         -2.5625e-01, -5.1263e-02,  1.6240e-01, -1.0645e-01, -3.5994e-02,\n",
            "         -4.1154e-02,  1.9525e-02,  5.6315e-02,  1.8552e-01, -1.0291e-01,\n",
            "         -4.7442e-03,  2.8336e-02, -5.3458e-02, -2.9615e-01, -7.4837e-02,\n",
            "         -1.4042e-01, -4.0359e-01, -1.5856e-02, -2.2115e-01,  4.3629e-03,\n",
            "          7.6001e-02, -1.6410e-01, -5.1871e-02, -8.2789e-02],\n",
            "        [-1.8239e-03,  3.5877e-02, -4.2871e-02,  9.6933e-02, -6.5738e-02,\n",
            "         -9.5464e-02, -2.2584e-01, -2.1874e-02, -1.3169e-01, -1.0763e-01,\n",
            "         -2.9869e-01, -2.4803e-01, -1.0345e-01,  9.4159e-02,  1.2660e-01,\n",
            "          7.4724e-02, -1.7667e-01, -6.6567e-02,  1.2672e-01, -4.3086e-02,\n",
            "         -2.6427e-01,  5.4197e-02, -1.8951e-01, -1.4216e-01,  5.9037e-04,\n",
            "          3.8746e-02,  1.7537e-02,  1.9705e-01, -2.0985e-01, -9.0419e-02,\n",
            "         -1.9331e-01, -2.6807e-02, -7.3848e-02, -2.4975e-01,  3.3268e-02,\n",
            "         -8.3329e-02, -9.7251e-02,  2.0017e-02,  2.1676e-01, -1.8951e-01,\n",
            "         -3.0675e-02,  1.5512e-02,  2.8178e-02,  1.7990e-01, -3.5415e-02,\n",
            "         -1.8663e-01,  7.4498e-02,  3.1793e-02,  9.6635e-02,  1.7503e-02,\n",
            "         -6.1472e-02, -1.0570e-01,  4.2936e-02,  7.0300e-02, -8.3744e-02,\n",
            "          4.0475e-02,  1.2125e-01, -2.5267e-01,  1.1248e-01,  1.2021e-01,\n",
            "         -2.5559e-01, -1.4190e-01, -2.0342e-02,  1.4038e-01],\n",
            "        [-1.0926e-01,  3.6893e-03, -6.8264e-03, -3.8456e-02, -1.7640e-01,\n",
            "          4.7644e-02, -1.5130e-01, -2.5377e-02, -1.0458e-01,  1.5831e-01,\n",
            "         -1.4367e-01, -2.2789e-01,  5.8957e-03, -1.2621e-01, -1.1740e-01,\n",
            "         -1.6444e-01, -7.8225e-02, -1.3360e-01, -4.0109e-02,  3.9534e-02,\n",
            "         -4.8940e-03,  5.0944e-02,  1.0072e-01,  8.4909e-02, -2.0891e-02,\n",
            "          6.8689e-02, -1.2404e-01,  4.1738e-02, -1.9037e-01, -7.3585e-02,\n",
            "          1.0875e-01, -1.8278e-02, -4.9892e-02,  1.3167e-01, -7.3981e-02,\n",
            "          4.9814e-02,  9.5502e-02,  8.7666e-02, -1.1627e-03,  2.6633e-02,\n",
            "         -9.4880e-01, -1.6348e-01, -2.1192e-01, -4.6418e-02, -2.0423e-01,\n",
            "          9.1853e-02, -5.0921e-02, -1.3586e-01,  6.1529e-02, -1.6755e-01,\n",
            "          1.2155e-01,  5.5066e-02, -1.0048e-01,  1.8947e-01,  1.1460e-01,\n",
            "          1.1254e-01, -3.1178e-03, -3.0175e-03, -1.0087e-01, -8.0817e-03,\n",
            "          6.3748e-03, -2.3625e-02, -2.9221e-02, -9.4227e-02],\n",
            "        [-8.8030e-02,  4.4791e-02, -1.4275e-01,  1.2185e-01, -9.9455e-02,\n",
            "         -1.4812e-01, -2.3699e-01, -7.5080e-02,  1.3385e-01, -9.7905e-02,\n",
            "          4.7397e-02, -2.7456e-01, -1.4125e-01,  3.6336e-02, -1.3590e-01,\n",
            "         -8.5423e-02, -5.4281e-02,  1.8237e-01,  5.1911e-02, -1.2305e-01,\n",
            "         -1.6228e-01, -1.9630e-01, -1.1666e-01,  8.8990e-02, -1.9312e-01,\n",
            "          7.4491e-03,  1.0965e-01,  3.9147e-02,  4.1901e-02, -3.0227e-01,\n",
            "         -2.1925e-01,  1.9131e-01, -7.1291e-04, -4.1714e-02,  1.2805e-01,\n",
            "          6.8660e-02,  3.2590e-02,  2.1558e-02, -6.8939e-02, -2.2284e-01,\n",
            "         -1.5666e-01,  3.4934e-02, -1.5571e-01, -7.0096e-02,  2.9952e-02,\n",
            "          5.6766e-02,  2.0466e-02, -1.6385e-02, -2.1642e-01,  1.2343e-01,\n",
            "          4.2198e-02,  1.4266e-01, -8.6312e-02,  3.5222e-02, -2.8075e-02,\n",
            "          1.3317e-01,  1.9045e-01, -7.6952e-02,  1.2839e-02, -2.2569e-02,\n",
            "         -8.7107e-02, -3.2407e-04,  8.0567e-02,  1.5460e-01]]), 'bias': tensor([-0.0511, -0.2006, -0.0133, -0.0142,  0.1217, -0.0243, -0.1196, -0.1175,\n",
            "         0.5232,  0.0088])}\n",
            "Nonce: 3870\n",
            "Previous Block Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "--------------\n",
            "==========================END OF CHAIN============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blockchain_1.validate_chain()\n",
        "blockchain_2.validate_chain()\n",
        "blockchain_3.validate_chain()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB0lCVsUMFYG",
        "outputId": "92c94839-d403-4ee6-bf84-1bc27adeb24f"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Hash of Previous Block: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Blockchain is correct!\n",
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Hash of Previous Block: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Blockchain is correct!\n",
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Hash of Previous Block: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Blockchain is correct!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attack on blockchain_1\n",
        "'''\n",
        "Large Attack\n",
        "'''\n",
        "from copy import deepcopy\n",
        "targeted_block_id = 3\n",
        "original_data = deepcopy(blockchain_1.chain[targeted_block_id].data)\n",
        "\n",
        "targeted_data = deepcopy(blockchain_1.chain[targeted_block_id].data)\n",
        "print('Original weight: ' )\n",
        "print(targeted_data['weight'])\n",
        "\n",
        "targeted_data['weight'] = torch.rand(targeted_data['weight'].shape)\n",
        "print('\\nModified weight: ')\n",
        "print(targeted_data['weight'])\n",
        "\n",
        "\n",
        "print(blockchain_1.modify_block(targeted_block_id, targeted_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cNd6RPTOYtw",
        "outputId": "66cf89f7-a610-4dc8-80a0-3276a4abbc64"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weight: \n",
            "tensor([[-0.0898,  0.0228, -0.0250,  ...,  0.0682, -0.1015, -0.0751],\n",
            "        [ 0.0142, -0.0617, -0.0568,  ..., -0.0338, -0.0558,  0.0405],\n",
            "        [-0.1508, -0.0901, -0.0380,  ...,  0.0528,  0.0925, -0.0676],\n",
            "        ...,\n",
            "        [ 0.0139,  0.0265, -0.1787,  ...,  0.0430,  0.0435, -0.0926],\n",
            "        [-0.0654, -0.0217, -0.1451,  ...,  0.0332, -0.0209, -0.1631],\n",
            "        [ 0.0609, -0.0105, -0.0566,  ...,  0.0403,  0.1513, -0.0428]])\n",
            "\n",
            "Modified weight: \n",
            "tensor([[0.4656, 0.2029, 0.5147,  ..., 0.1370, 0.2737, 0.7825],\n",
            "        [0.2189, 0.9766, 0.2079,  ..., 0.5263, 0.8683, 0.7288],\n",
            "        [0.8510, 0.2296, 0.0274,  ..., 0.6003, 0.1559, 0.6018],\n",
            "        ...,\n",
            "        [0.7982, 0.1002, 0.1200,  ..., 0.7223, 0.6316, 0.7632],\n",
            "        [0.7956, 0.2127, 0.4723,  ..., 0.2145, 0.3333, 0.5660],\n",
            "        [0.6309, 0.2385, 0.8584,  ..., 0.1319, 0.6289, 0.8281]])\n",
            "\n",
            "--------------Block Hash: 02b614196f85f7c13ec57dae3f6b7bcca149c48472336d01f37bb8a3c8904bb1\n",
            "BlockNo: 3\n",
            "Block Data: {'layer': 'fc3', 'weight': tensor([[0.4656, 0.2029, 0.5147,  ..., 0.1370, 0.2737, 0.7825],\n",
            "        [0.2189, 0.9766, 0.2079,  ..., 0.5263, 0.8683, 0.7288],\n",
            "        [0.8510, 0.2296, 0.0274,  ..., 0.6003, 0.1559, 0.6018],\n",
            "        ...,\n",
            "        [0.7982, 0.1002, 0.1200,  ..., 0.7223, 0.6316, 0.7632],\n",
            "        [0.7956, 0.2127, 0.4723,  ..., 0.2145, 0.3333, 0.5660],\n",
            "        [0.6309, 0.2385, 0.8584,  ..., 0.1319, 0.6289, 0.8281]]), 'bias': tensor([-0.1711, -0.1505, -0.1412,  0.0111, -0.0597,  0.1476, -0.0710, -0.0209,\n",
            "         0.1606,  0.2981,  0.1772, -0.2506, -0.0747, -0.2264, -0.2045, -0.3326,\n",
            "        -0.1356, -0.0518, -0.1744, -0.1427, -0.0377,  0.1834,  0.2696,  0.4100,\n",
            "        -0.2308, -0.2062, -0.0479,  0.0068, -0.1853,  0.1144, -0.1299,  0.1610,\n",
            "        -0.0101,  0.0754,  0.0926, -0.0319,  0.1107,  0.1191, -0.2281, -0.1523,\n",
            "        -0.2556, -0.1582, -0.0862, -0.0819, -0.0549,  0.1640, -0.1267, -0.0659,\n",
            "         0.0778, -0.0852, -0.0334,  0.2512, -0.0555,  0.2768,  0.0982,  0.3895,\n",
            "         0.1073, -0.1683,  0.0174, -0.0115,  0.2321, -0.3172, -0.1211,  0.0065])}\n",
            "Nonce: 4952\n",
            "Previous Block Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "--------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Validate one time AFTER tampering\n",
        "'''\n",
        "blockchain_1.validate_chain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsQ5u2StPUBO",
        "outputId": "69d27ccf-fe7b-4eb1-830d-8b749da953a0"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Hash of Previous Block: 02b614196f85f7c13ec57dae3f6b7bcca149c48472336d01f37bb8a3c8904bb1\n",
            "Block 3 is tampered!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remining\n",
        "\n",
        "new_blockchain_1 = Blockchain()\n",
        "'''\n",
        "first, copy the correct blocks (healthy blocks before the corrupted one) from the corrupted blockchain\n",
        "'''\n",
        "\n",
        "newBlock = Block(blockchain_1.chain[1].data)\n",
        "new_blockchain_1.mine(newBlock)\n",
        "newBlock = Block(blockchain_1.chain[2].data)\n",
        "new_blockchain_1.mine(newBlock)\n",
        "print(new_blockchain_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7ymx9_APkK2",
        "outputId": "713b1a63-a5b7-4ed8-da75-ad17e8bee11a"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block 0 - Qualified: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Block 1 - Qualified: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Block 2 - Qualified: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "--------------Block Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "BlockNo: 0\n",
            "Block Data: Genesis\n",
            "Nonce: 1176\n",
            "Previous Block Hash: 00000000000000000000000000000000\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "BlockNo: 1\n",
            "Block Data: {'layer': 'fc1', 'weight': tensor([[ 0.0329,  0.0086,  0.0243,  ...,  0.0497,  0.0563,  0.0528],\n",
            "        [-0.0129,  0.0104,  0.0365,  ...,  0.0194,  0.0207,  0.0246],\n",
            "        [ 0.0081,  0.0136, -0.0052,  ...,  0.0030,  0.0517,  0.0313],\n",
            "        ...,\n",
            "        [ 0.0393,  0.0300,  0.0377,  ...,  0.0255,  0.0073,  0.0581],\n",
            "        [ 0.0441,  0.0390,  0.0418,  ...,  0.0376, -0.0042,  0.0096],\n",
            "        [ 0.0226,  0.0080,  0.0011,  ..., -0.0116,  0.0461,  0.0215]]), 'bias': tensor([-5.0697e-02, -1.5882e-03, -4.5533e-02, -8.9822e-04, -7.9249e-02,\n",
            "         3.3151e-03, -3.6789e-02, -1.7230e-02, -5.2123e-02, -2.5209e-02,\n",
            "         8.5094e-03, -5.6987e-02, -2.2219e-02, -2.8807e-02, -1.7612e-02,\n",
            "         4.9885e-03, -1.4747e-03, -7.5809e-02,  1.5871e-02, -4.0564e-03,\n",
            "        -3.7250e-03, -4.6109e-02,  2.5242e-03,  4.4355e-03,  1.0314e-02,\n",
            "        -7.1663e-02,  9.1916e-03, -3.6697e-02, -3.8919e-02, -3.2340e-02,\n",
            "        -1.7095e-02, -2.2695e-02, -7.3756e-03, -3.2307e-03, -2.6671e-02,\n",
            "        -1.4188e-02, -5.8340e-03, -3.8018e-02, -3.0583e-02, -1.8098e-02,\n",
            "         2.1612e-02, -8.6132e-02, -2.3886e-02, -1.1493e-02, -8.3055e-03,\n",
            "        -1.7589e-03,  1.1987e-02, -4.2030e-02, -3.9615e-02,  4.4278e-03,\n",
            "        -1.7534e-02, -2.4694e-02, -2.1543e-02, -3.4609e-02,  2.3570e-02,\n",
            "         2.6285e-02, -1.3856e-02,  1.1432e-02, -2.7742e-02,  3.2082e-04,\n",
            "         4.6447e-03,  1.1198e-02, -1.5167e-02, -4.9473e-02, -4.2446e-02,\n",
            "         5.3062e-02, -6.3078e-02, -2.2603e-02, -1.0497e-02, -4.7284e-03,\n",
            "        -4.0333e-02,  4.8095e-03, -5.9835e-02,  5.7884e-03, -5.8095e-03,\n",
            "        -2.4915e-02, -1.1267e-02, -5.3225e-02,  1.0887e-02, -3.1268e-03,\n",
            "        -2.1667e-02, -5.2839e-02, -3.7480e-02, -2.9252e-02, -1.0288e-02,\n",
            "         9.7473e-03, -3.4331e-02, -2.6842e-02, -4.7752e-02, -4.4481e-03,\n",
            "        -5.0411e-02, -1.8064e-02, -2.4959e-02,  3.8707e-02, -2.3788e-02,\n",
            "        -3.0230e-02, -4.3937e-02, -3.9769e-02, -9.4580e-02,  4.1654e-02,\n",
            "        -3.5936e-02, -2.1148e-02,  1.7497e-02, -3.1961e-02, -2.3776e-02,\n",
            "        -3.7282e-02, -1.5092e-02,  9.8810e-03, -3.9213e-02, -3.9942e-02,\n",
            "        -5.6907e-02, -3.7442e-03, -9.5044e-02, -2.5293e-02, -2.5454e-02,\n",
            "        -4.7367e-02, -5.1332e-02, -2.0713e-03, -2.7323e-02,  5.7385e-03,\n",
            "        -1.9152e-02, -3.3860e-02, -4.8206e-02, -3.2334e-03, -5.0366e-02,\n",
            "        -3.5953e-02,  6.5205e-03, -2.6486e-02,  1.1088e-02, -2.8068e-02,\n",
            "        -7.4271e-02, -1.1911e-02,  1.2842e-02, -2.5225e-02, -3.1306e-02,\n",
            "        -1.9759e-02, -3.5803e-03,  2.0227e-03, -2.1660e-02,  1.1208e-02,\n",
            "        -2.4123e-02,  9.0310e-03, -5.1055e-02, -4.5396e-02, -2.6411e-02,\n",
            "         1.1292e-02,  1.4030e-02, -3.8358e-02, -3.2809e-02, -1.8572e-02,\n",
            "         4.8251e-02, -2.9928e-03, -7.2177e-02, -4.8035e-02,  7.6769e-03,\n",
            "        -6.5365e-02, -3.6413e-02, -1.1881e-02,  1.7021e-02, -1.1635e-02,\n",
            "        -6.0688e-02, -2.3924e-02, -4.9127e-02, -6.5620e-02, -4.3793e-02,\n",
            "        -4.4041e-02, -5.9561e-02, -2.9840e-02, -2.5970e-03, -4.9796e-02,\n",
            "        -1.1559e-02,  7.0239e-03, -3.5945e-02,  1.5993e-02, -4.1892e-02,\n",
            "        -6.8264e-02,  2.1650e-02, -4.1370e-02,  2.1973e-02, -1.5948e-02,\n",
            "        -1.0226e-01, -3.7496e-02,  1.7094e-02, -1.0982e-02,  1.5540e-02,\n",
            "        -5.0556e-02, -2.7001e-02, -2.0114e-02, -5.0169e-02, -2.9489e-02,\n",
            "        -3.9743e-02, -8.5380e-03, -1.8673e-02, -3.8129e-02, -2.1269e-02,\n",
            "        -2.5533e-02, -2.1255e-02, -1.3042e-02, -3.3605e-02, -1.3769e-02,\n",
            "        -2.9272e-02, -2.0493e-02,  6.1399e-03,  3.2051e-02, -2.2862e-02,\n",
            "        -4.3587e-02, -1.2302e-02, -6.0179e-03, -6.3411e-02, -1.3902e-04,\n",
            "         6.6006e-03, -6.3300e-02, -8.8990e-03, -4.0236e-03, -5.1070e-02,\n",
            "        -5.1127e-02, -3.9643e-02, -5.2284e-02, -4.6759e-02, -5.3112e-02,\n",
            "        -2.7392e-02, -2.9490e-02, -2.2758e-02, -9.5000e-03, -1.2496e-02,\n",
            "        -3.4707e-02, -1.4716e-02, -1.2888e-02, -1.2930e-03, -5.0056e-02,\n",
            "        -4.8036e-02, -3.2378e-02, -3.6429e-02, -3.8621e-02, -3.1510e-02,\n",
            "        -5.1300e-02,  1.4994e-02,  1.2208e-05, -1.4082e-02,  1.7620e-03,\n",
            "        -4.7165e-02, -3.7629e-02, -3.8766e-02,  9.4560e-03, -1.5576e-02,\n",
            "        -3.9815e-02,  1.1144e-02,  9.7832e-03, -1.2574e-02, -4.5413e-02,\n",
            "        -8.2680e-03, -2.0615e-02, -1.7477e-02, -4.7983e-02, -2.5950e-02,\n",
            "        -4.0306e-02])}\n",
            "Nonce: 2779\n",
            "Previous Block Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "--------------\n",
            "\n",
            "--------------Block Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "BlockNo: 2\n",
            "Block Data: {'layer': 'fc2', 'weight': tensor([[ 0.0700,  0.0577, -0.0515,  ..., -0.0376, -0.0064, -0.0211],\n",
            "        [ 0.2691,  0.0488, -0.0146,  ...,  0.1431,  0.0142, -0.0360],\n",
            "        [ 0.1107,  0.0349,  0.0097,  ...,  0.0975, -0.0220,  0.0102],\n",
            "        ...,\n",
            "        [-0.0245,  0.0396, -0.0413,  ..., -0.0204, -0.0343,  0.0537],\n",
            "        [-0.0211,  0.0468, -0.0537,  ..., -0.1140,  0.0065,  0.0199],\n",
            "        [ 0.1608, -0.0083, -0.0337,  ...,  0.0963, -0.0206,  0.0148]]), 'bias': tensor([-0.0489,  0.1896,  0.1729, -0.1131, -0.1978,  0.0504, -0.0708, -0.1582,\n",
            "        -0.0030, -0.1288,  0.0108,  0.0125, -0.0415, -0.1031, -0.0630, -0.0025,\n",
            "        -0.1085, -0.0879, -0.0841,  0.3088,  0.1560,  0.0175, -0.2156, -0.1164,\n",
            "        -0.1923, -0.0915, -0.1100, -0.0354, -0.2318, -0.0061, -0.0592, -0.1969,\n",
            "        -0.0775, -0.1088, -0.1204, -0.1337, -0.2263,  0.1045, -0.1049, -0.1794,\n",
            "        -0.1485, -0.1131, -0.1346, -0.1471,  0.0449,  0.0613,  0.1513, -0.0190,\n",
            "        -0.0355, -0.1064,  0.2106, -0.1671,  0.0496,  0.0589, -0.1245, -0.1031,\n",
            "         0.0060, -0.0687, -0.1207, -0.0791,  0.0110, -0.1303,  0.0872, -0.0913,\n",
            "        -0.0502, -0.1575,  0.0946, -0.0620,  0.0189,  0.0400, -0.0242, -0.2191,\n",
            "        -0.1293, -0.1497,  0.1555,  0.2938, -0.0674, -0.3190, -0.0629, -0.1634,\n",
            "        -0.0147, -0.0193, -0.1928, -0.0061, -0.1173, -0.0514, -0.1626, -0.2278,\n",
            "        -0.0745, -0.0037, -0.0470, -0.0303, -0.1636, -0.1014,  0.1747, -0.0842,\n",
            "        -0.1578,  0.0232, -0.0125, -0.1983,  0.4642, -0.1431,  0.0178, -0.0420,\n",
            "        -0.0608, -0.0430, -0.0866,  0.0265, -0.0709,  0.0132,  0.0132, -0.1032,\n",
            "        -0.0352, -0.0149, -0.2466, -0.0685, -0.1978, -0.0966, -0.0275, -0.2409,\n",
            "         0.2949, -0.1386,  0.0520, -0.1878, -0.1932, -0.0528, -0.0524,  0.1045])}\n",
            "Nonce: 6875\n",
            "Previous Block Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "--------------\n",
            "==========================END OF CHAIN============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "next, for the rest of the blockchain (remaining blocks), mine new blocks using the data from corrupted blockchain\n",
        "'''\n",
        "for remaining_block in blockchain_1.chain[targeted_block_id:]:\n",
        "  newBlock = Block(remaining_block)\n",
        "  new_blockchain_1.mine(newBlock)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CRbP4yEP1fB",
        "outputId": "f4bb2c27-4eca-42d2-c83b-c5586d472aa6"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block 3 - Qualified: 0009a579070bd5a15bf7dd5cadc6743245fd9c63660ddd5eb3815ad770cc492e\n",
            "Block 4 - Qualified: 0007cd36257959de4054e276d9fe23c365a69a8e0686c66774ac5338f6b1ab76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "polling = 0\n",
        "decision = new_blockchain_1.validate_chain()\n",
        "if decision:\n",
        "  polling = polling + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXylpl29Ryrb",
        "outputId": "8167e319-4a24-4a1c-86e5-d26a8c21fa1a"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 0009a579070bd5a15bf7dd5cadc6743245fd9c63660ddd5eb3815ad770cc492e\n",
            "Hash of Previous Block: 0009a579070bd5a15bf7dd5cadc6743245fd9c63660ddd5eb3815ad770cc492e\n",
            "Blockchain is correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3kec3zTIZ4hA"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jwAxpNcWR2UL"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5KE3ViUCWC0d"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "h8--omD5jtKG"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blockchain_copy_2 = blockchain_2 \n",
        "\n",
        "blockchain_copy_2.modify_block(targeted_block_id, targeted_data)\n",
        "\n",
        "decision_block2 = blockchain_copy_2.validate_chain()\n",
        "\n",
        "if  blockchain_copy_2.validate_chain():\n",
        "  polling = polling + 1\n",
        "\n",
        "print(\"res \", decision_block2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nubJ3wyTg47",
        "outputId": "14f60d67-58b9-4a0c-92dc-c0e40050a283"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Hash of Previous Block: 02b614196f85f7c13ec57dae3f6b7bcca149c48472336d01f37bb8a3c8904bb1\n",
            "Block 3 is tampered!\n",
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Hash of Previous Block: 02b614196f85f7c13ec57dae3f6b7bcca149c48472336d01f37bb8a3c8904bb1\n",
            "Block 3 is tampered!\n",
            "res  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blockchain_copy_3 = blockchain_3 \n",
        "blockchain_copy_3.modify_block(targeted_block_id, targeted_data)\n",
        "\n",
        "decision_block3 = blockchain_copy_3.validate_chain()\n",
        "if  blockchain_copy_3.validate_chain():\n",
        "  polling = polling + 1\n",
        "\n",
        "print(\"res \", decision_block3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdnsyudAV6Ox",
        "outputId": "299349e1-84c9-47c2-f248-83d5451f0307"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Hash of Previous Block: 02b614196f85f7c13ec57dae3f6b7bcca149c48472336d01f37bb8a3c8904bb1\n",
            "Block 3 is tampered!\n",
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Hash of Previous Block: 02b614196f85f7c13ec57dae3f6b7bcca149c48472336d01f37bb8a3c8904bb1\n",
            "Block 3 is tampered!\n",
            "res  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2GfAceT7WlHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numPeers = 3\n",
        "consensus_factor = polling/numPeers\n",
        "\n",
        "print(consensus_factor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVMXrtB3Wsx_",
        "outputId": "cc7d732f-4600-4c45-f1e2-0c8ec0c6b3a8"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blockchain_copy_1 = blockchain_1\n",
        "if consensus_factor < 0.51:\n",
        "  print(\"Correct defective block\")\n",
        "  blockchain_copy_3.modify_block(targeted_block_id, original_data)\n",
        "  blockchain_copy_2.modify_block(targeted_block_id, original_data)\n",
        "  blockchain_copy_1.modify_block(targeted_block_id, original_data)\n",
        "  blockchain_copy_3.validate_chain()\n",
        "  blockchain_copy_2.validate_chain()\n",
        "  blockchain_copy_1.validate_chain()\n",
        "else:\n",
        "  print(\"All is well!\")  \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMw8jjV_oN0u",
        "outputId": "6fe105b7-df5d-4228-cece-512bff32defc"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct defective block\n",
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Hash of Previous Block: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Blockchain is correct!\n",
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Hash of Previous Block: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Blockchain is correct!\n",
            "\n",
            "Previous_Hash: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "Hash of Previous Block: 00008617b0d4b8e5e1638e7ee688a5faf1e56ab43cca4ebb24d0f1f0917029d4\n",
            "\n",
            "Previous_Hash: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "Hash of Previous Block: 0009d7f082909aa7b0f04b68a7e65c85f5e271f08398403fd0301ae413e08326\n",
            "\n",
            "Previous_Hash: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "Hash of Previous Block: 0001d8da5c0913b23b5263cb3d4d7b06c70606554d6030a9ba32f286a69f68bb\n",
            "\n",
            "Previous_Hash: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Hash of Previous Block: 0009d8e76e342a61f09fd80be502c28ac358a8f8c04a275534665ba2a9b3558c\n",
            "Blockchain is correct!\n"
          ]
        }
      ]
    }
  ]
}